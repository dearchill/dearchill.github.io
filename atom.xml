<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>C&#39;est La Vie</title>
  
  <subtitle>Love or death</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-03-11T07:28:53.625Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>SonicYouth</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>发哨子的人</title>
    <link href="http://yoursite.com/2020/03/10/2020-03-10-fa-shao-zi-de-ren/"/>
    <id>http://yoursite.com/2020/03/10/2020-03-10-fa-shao-zi-de-ren/</id>
    <published>2020-03-09T16:00:00.000Z</published>
    <updated>2020-03-11T07:28:53.625Z</updated>
    
    <content type="html"><![CDATA[<hr><p>原文来自人物：<del><a href="原文链接">发哨子的人</a></del></p><h2 id="作者：人物记者"><a href="#作者：人物记者" class="headerlink" title="作者：人物记者"></a>作者：人物记者</h2><p><img src="https://i.loli.net/2020/03/10/mv2whpJHiLnUjzN.jpg" alt="IMG_7752.JPG"></p><p>2019 年 12 月 30 日，艾芬曾拿到过一份不明肺炎病人的病毒检测报告，她用红色圈出「SARS 冠状病毒」字样，当大学同学问起时，她将这份报告拍下来传给了这位同是医生的同学。当晚，这份报告传遍了武汉的医生圈，转发这份报告的人就包括那 8 位被警方训诫的医生。</p><p>这给艾芬带来了麻烦，作为传播的源头，她被医院纪委约谈，遭受了「前所未有的、严厉的斥责」，称她是作为专业人士在造谣。</p><p>此前的一些报道，艾芬被称为「又一个被训诫的女医生浮出水面」，也有人将她称为「吹哨人」，艾芬纠正了这个说法，她说自己不是吹哨人，是那个「发哨子的人」。</p><p>这是《人物》3 月刊封面《武汉医生》的第二篇报道。</p><p><strong>文｜</strong>龚菁琦</p><p><strong>编辑｜</strong>金石</p><p><strong>摄影｜</strong>尹夕远</p><p>接到武汉市中心医院急诊科主任艾芬同意采访的短信是 3 月 1 日凌晨 5 点，大约半小时后，3 月 1 日凌晨 5 点 32 分，她的同事、甲状腺乳腺外科主任江学庆因感染新冠肺炎去世。两天后，该院眼科副主任梅仲明过世，他和李文亮是同一科室。</p><p>截止 2020 年 3 月 9 日，武汉市中心医院已有 4 位医护人员因感染新冠肺炎去世——疫情发生以来，这家离华南海鲜市场只几公里的医院成为了武汉市职工感染人数最多的医院之一，据媒体报道医院超过 200 人被感染，其中包括三个副院长和多名职能部门主任，多个科室主任目前正在用 ECMO 维持。</p><p>死亡的阴影笼罩着这家武汉市最大的三甲医院，有医生告诉《人物》，在医院的大群里，几乎没有人说话，只在私下默默悼念、讨论。</p><p>悲剧原本有机会避免。2019 年 12 月 30 日，艾芬曾拿到过一份不明肺炎病人的病毒检测报告，她用红色圈出「SARS 冠状病毒」字样，当大学同学问起时，她将这份报告拍下来传给了这位同是医生的同学。当晚，这份报告传遍了武汉的医生圈，转发这份报告的人就包括那 8 位被警方训诫的医生。</p><p>这给艾芬带来了麻烦，作为传播的源头，她被医院纪委约谈，遭受了「前所未有的、严厉的斥责」，称她是作为专业人士在造谣。</p><p>3 月 2 日下午，艾芬在武汉市中心医院南京路院区接受了《人物》的专访。她一个人坐在急诊室办公室中，曾经一天接诊超过 1500 位患者的急诊科此时已恢复了安静，急诊大厅里只躺着一名流浪汉。</p><p>此前的一些报道，艾芬被称为「又一个被训诫的女医生浮出水面」，也有人将她称为「吹哨人」，艾芬纠正了这个说法，她说自己不是吹哨人，是那个「发哨子的人」。采访中，艾芬数次提起「后悔」这个词，她后悔当初被约谈后没有继续吹响哨声，特别是对于过世的同事，「早知道有今天，我管他批评不批评，『老子』到处说，是不是？」</p><p>关于武汉市中心医院和艾芬本人在过去的两个多月中到底经历了什么？以下，是艾芬的讲述——</p><p><img src="https://i.loli.net/2020/03/10/YmcMTVSks5g1LFo.jpg" alt="IMG_7753.JPG"></p><p>艾芬</p><p><strong>前所未有的训斥</strong></p><p>去年 12 月 16 日，我们南京路院区急诊科接诊了一位病人。莫名其妙高烧，一直用药都不好，体温动都不动一下。22 号就转到了呼吸科，做了纤维支气管镜取了肺泡灌洗液，送去外面做高通量测序，后来口头报出来是冠状病毒。当时，具体管床的同事在我耳边嚼了几遍：艾主任，那个人报的是冠状病毒。后来我们才知道那个病人是在华南海鲜做事的。</p><p>紧接着 12 月 27 日，南京路院区又来了一个病人，是我们科一位医生的侄儿，40 多岁，没有任何基础疾病，肺部一塌糊涂，血氧饱和只有 90%，在下面其他医院已经治疗了将近 10 天左右都没有任何好转，病人收到了呼吸科监护室住院。同样做了纤维支气管镜取了肺泡灌洗液送去检测。</p><p>12 月 30 日那天中午，我在同济医院工作的同学发了一张微信对话截图给我，截图上写着：「最近不要去华南啊，那里蛮多人高烧……」他问我是不是真的，当时，我正在电脑上看一个很典型的肺部感染患者的 CT，我就把 CT 录了一段 11 秒钟的视频传给他，告诉他这是上午来我们急诊的一个病人，也是华南海鲜市场的。</p><p>当天下午 4 点刚过，同事给我看了一份报告，上面写的是：SARS 冠状病毒、绿脓假单胞菌、46 种口腔 / 呼吸道定植菌。我仔细看了很多遍报告，下面的注释写着：SARS 冠状病毒是一种单股正链 RNA 病毒。该病毒主要传播方式为近距离飞沫传播或接触患者呼吸道分泌物，可引起的一种具有明显传染性，可累及多个脏器系统的特殊肺炎，也称非典型肺炎。</p><p>当时，我吓出了一身冷汗，这是一个很可怕的东西。病人收在呼吸科，按道理应该呼吸科上报这个情况，但是为了保险和重视起见，我还是立刻打电话上报给了医院公共卫生科和院感科。当时我们医院呼吸科主任正好从我门口过，他是参加过非典的人，我把他抓住，说，我们有个病人收到你们科室，发现了这个东西。他当时一看就说，那就麻烦了。我就知道这个事情麻烦了。</p><p>给医院打完电话，我也给我同学传了这份报告，特意在「SARS 冠状病毒、绿脓假单胞菌、46 种口腔 / 呼吸道定植菌」这一排字上画了个红圈，目的是提醒他注意、重视。我也把报告发在了科室医生群里面，提醒大家注意防范。</p><p>当天晚上，这个东西就传遍了，各处传的截屏都是我画红圈的那个照片，包括后来知道李文亮传在群里的也是那份。我心里当时就想可能坏事儿了。10 点 20，医院发来了信息，是转市卫健委的通知，大意就是关于不明原因肺炎，不要随意对外发布，避免引起群众恐慌，如果因为信息泄露引发恐慌，要追责。</p><p>我当时心里就很害怕，立刻把这条信息转给了我同学。过了大概一个小时，医院又来了一份通知，再次强调群内的相关消息不能外传。一天后，1 月 1 日晚上 11 点 46 分，医院监察科科长给我发了条消息，让我第二天早上过去一下。</p><p>那一晚上我都没有睡着，很担忧，翻来覆去地想，但又觉得凡事总有两面性，即便造成不良影响，但提醒武汉的医务人员注意防范也不一定是个坏事。第二天早上 8 点多一点，还没有等我交完班，催我过去的电话就打来了。</p><p>之后的约谈，我遭受了前所未有的、非常严厉的斥责。</p><p>当时，谈话的领导说，「我们出去开会都抬不起头，某某某主任批评我们医院那个艾芬，作为武汉市中心医院急诊科主任，你是专业人士，怎么能够没有原则没有组织纪律造谣生事？」这是原话。让我回去跟科室的 200 多号人一个个地口头传达到位，不能发微信、短信传达，只能当面聊或者打电话，不许说关于这个肺炎的任何事情，「连自己的老公都不能说」……</p><p>我整个人一下子就懵了，他不是批评你这个人工作不努力，而是好像整个武汉市发展的大好局面被我一个人破坏了。我当时有一种很绝望的感觉，我是一个平时认认真真、勤勤恳恳工作的人，我觉得自己做的事情都是按规矩来的，都是有道理的，我犯了什么错？我看到了这个报告，我也上报医院了，我和我的同学，同行之间对于某一个病人的情况进行交流，没有透露病人的任何私人信息，就相当于是医学生之间讨论一个病案，当你作为一个临床的医生，已经知道在病人身上发现了一种很重要的病毒，别的医生问起，你怎么可能不说呢？这是你当医生的本能，对不对？我做错什么了？我做了一个医生、一个人正常应该做的事情，换作是任何人我觉得都会这么做。</p><p>我当时的情绪也很激动，说，这个事是我做的，跟其余人都没有关系，你们干脆把我抓去坐牢吧。我说我现在这个状态不适合在这个岗位上继续工作了，想要休息一段时间。领导没有同意，说这个时候正是考验我的时候。</p><p>当天晚上回家，我记得蛮清楚，进门后就跟我老公讲，我要是出了什么事情，你就好好地把孩子带大。因为我的二宝还很小，才 1 岁多。他当时觉得莫名其妙，我没有跟他说自己被训话的事，1 月 20 号，钟南山说了人传人之后，我才跟他说那天发生了什么。那期间，我只是提醒家人不要去人多的地方，出门要戴口罩。</p><p><strong>外围科室</strong></p><p>很多人担心我也是那 8 个人之一被叫去训诫。实际上我没有被公安局训诫，后来有好朋友问我，你是不是吹哨人？我说我不是吹哨人，我是那个发哨子的人。</p><p>但那次约谈对我的打击很大，非常大。回来后我感觉整个人心都垮了，真的是强打着精神，认真做事，后来所有的人再来问我，我就不能回答了。</p><p>我能做的就是先让急诊科重视防护。我们急诊科 200 多人，从 1 月 1 号开始，我就叫大家加强防护，所有的人必须戴口罩、戴帽子、用手快消。记得有一天交班有个男护士没戴口罩，我马上就当场骂他「以后不戴口罩就不要来上班了」。</p><p>1 月 9 号，我下班时看见预检台一个病人对着大家咳，从那天后，我就要求他们必须给来看病的病人发口罩，一人发一个，这个时候不要节约钱，当时外面在说没有人传人，我又要在这里强调戴口罩加强防护，都是很矛盾的。</p><p>那段时间确实很压抑，非常痛苦。有医生提出来要把隔离衣穿外头，医院里开会说不让，说隔离衣穿外头会造成恐慌。我就让科室的人把隔离服穿白大褂里面，这是不符合规范的，很荒谬的。</p><p>我们眼睁睁地看着病人越来越多，传播区域的半径越来越大，先是华南海鲜市场附近可能跟它有关系，然后就传传传，半径越来越大。很多是家庭传染的，最先的 7 个人当中就有妈妈给儿子送饭得的病。有诊所的老板得病，也是来打针的病人传给他的，都是重得不得了。我就知道肯定有人传人。如果没有人传人，华南海鲜市场 1 月 1 日就关闭了，怎么病人会越来越多呢？</p><p>很多时候我都在想，如果他们当时不那样训斥我，心平气和地问一下这件事情的来龙去脉，再请别的呼吸科专家一起沟通一下，也许局面会好一些，我至少可以在医院内部多交流一下。如果是 1 月 1 号大家都这样引起警惕，就不会有那么多悲剧了。</p><p>1 月 3 号下午，在南京路院区，泌尿外科的医生们聚集在一起回顾老主任的工作历程，参会的胡卫峰医生今年 43 岁，现在正在抢救；1 月 8 号下午，南京路院区 22 楼，江学庆主任还组织了武汉市甲乳患者康复联欢会；1 月 11 号早上，科室跟我汇报急诊科抢救室护士胡紫薇感染，她应该是中心医院第一个被感染的护士，我第一时间给医务科科长打电话汇报，然后医院紧急开了会，会上指示把「两下肺感染，病毒性肺炎？」的报告改成「两肺散在感染」；1 月 16 号最后一次周会上，一位副院长还在说：「大家都要有一点医学常识，某些高年资的医生不要自己把自己搞得吓死人的。」另一位领导上台继续说：「没有人传人，可防可治可控。」一天后，1 月 17 号，江学庆住院，10 天后插管、上 ECMO。</p><p>中心医院的代价这么大，就是跟我们的医务人员没有信息透明化有关。你看倒下的人，急诊科和呼吸科的倒是没有那么重的，因为我们有防护意识，并且一生病就赶紧休息治疗。重的都是外围科室，李文亮是眼科的，江学庆是甲乳科的。</p><p>江学庆真的非常好的一个人，医术很高，全院的两个中国医师奖之一。而且我们还是邻居，我们一个单元，我住四十几楼，他住三十几楼，关系都很好，但是平时因为工作太忙，就只能开会、搞医院活动时候见见面。他是个工作狂，要么就在手术室，要么就在看门诊。谁也不会特意跑去跟他说，江主任，你要注意，戴口罩。他也没有时间和精力打听这些事，他肯定就大意了：「有什么关系？就是个肺炎。」这个是他们科室的人告诉我的。</p><p>如果这些医生都能够得到及时的提醒，或许就不会有这一天。所以，作为当事人的我非常后悔，早知道有今天，我管他批评不批评我，「老子」到处说，是不是？</p><p>虽然和李文亮同在一个医院，一直到去世之前我都不认得他，因为医院 4000 多号人太多了，平时也忙。他去世前的那天晚上，ICU 的主任跟我打电话借急诊科的心脏按压器，说李文亮要抢救，我一听这个消息大吃一惊，李文亮这个事整个过程我不了解，但是他的病情跟他受训斥之后心情不好有没有关系？这我要打个问号，因为受训的感觉我感同身受。</p><p>后来，事情发展到这一步，证明李文亮是对的时候，他的心情我非常能理解，可能跟我的心情一样，不是激动、高兴，而是后悔，后悔当初就应该继续大声疾呼，应该在所有的人问我们的时候，继续说。很多很多次我都在想，如果时间能够倒回来该多好。</p><p><img src="https://i.loli.net/2020/03/10/PeHncGWqQLhYrTm.jpg" alt="IMG_7754.JPG"></p><p><strong>活着就是好的</strong></p><p>在 1 月 23 日封城前一天的晚上，有相关部门的朋友打电话问我武汉市急诊病人的真实情况。我说你代表私人，还是代表公家。他说我代表私人。我说代表个人就告诉你真话，1 月 21 号，我们急诊科接诊 1523 个病人，是往常最多时的 3 倍，其中发烧的有 655 个人。</p><p>那段时间急诊科的状况，经历过的人一辈子都忘不了，甚至会颠覆你的所有人生观。</p><p>如果说这是打仗，急诊科就在最前线。但当时的情况是，后面的病区已经饱和了，基本上一个病人都不收，ICU 也坚决不收，说里面有干净的病人，一进去就污染了。病人不断地往急诊科涌，后面的路又不通，就全部堆在急诊科。病人来看病，一排队随便就是几个小时，我们也完全没法下班，发热门诊和急诊也都不分了，大厅里堆满了病人，抢救室输液室里到处都是病人。</p><p>还有的病人家属来了，说要一张床，我的爸爸在汽车里面不行了，因为那时候地下车库已封，他车子也堵着开不进来。我没办法，带着人和设备跑去汽车里去，一看，人已经死了，你说是什么感受，很难受很难受。这个人就死在汽车里，连下车的机会都没有。</p><p>还有一位老人，老伴刚在金银潭医院去世了，她的儿子、女儿都被感染了，在打针，照顾她的是女婿，一来我看她病得非常重，联系呼吸科给收进去住院，她女婿一看就是个有文化有素质的人，过来跟我说谢谢医生等等的，我心里一紧，说快去，根本耽误不了了。结果送去就去世了。一句谢谢虽然几秒钟，但也耽误了几秒。这句谢谢压得我很沉重。</p><p>还有很多人把自己的家人送到监护室的时候，就是他们见的最后一面，你永远见不着了。</p><p>我记得大年三十的早上我来交班，我说我们来照个相，纪念一下这个大年三十，还发了个朋友圈。那天，大家都没有说什么祝福，这种时候，活着就是好的。</p><p>以前，你如果有一点失误，比如没有及时打针，病人都可能还去闹，现在没人了，没有人跟你吵，没有人跟你闹了，所有人都被这种突然来的打击击垮了，搞蒙了。</p><p>病人死了，很少看到家属有很伤心地哭的，因为太多了，太多了。有些家属也不会说医生求求你救救我的家人，而是跟医生说，唉，那就快点解脱吧，已经到了这个地步。因为这时候每个人怕的都是自己被感染。</p><p>一天发热门诊门口的排队，要排 5 个小时。正排着一个女的倒下了，看她穿着皮衣，背着包包，穿着高跟鞋，应该是很讲究的一个中年女性，可是没有人敢上前去扶她，就在地上躺了很久。只得我去喊护士、医生来去扶她。</p><p>1 月 30 号我早上来上班，一个白发老人的儿子 32 岁死了，他就盯着看医生给他开死亡证明。根本没有眼泪，怎么哭？没办法哭。看他的打扮，可能就是一个外来的打工的，没有任何渠道去反映。没有确诊，他的儿子，就变成了一张死亡证明。</p><p>这也是我想要去呼吁一下的。在急诊科死亡的病人都是没有诊断、没办法确诊的病例，等这个疫情过去之后，我希望能给他们一个交代，给他们的家庭一些安抚，我们的病人很可怜的，很可怜。</p><p><strong>「幸运」</strong></p><p>做了这么多年医生，我一直觉得没有什么困难能够打倒我，这也和我的经历、个性有关。</p><p>9 岁那年我爸爸就胃癌去世了，那个时候我就想着长大了当个医生去救别人的命。后来高考的时候，我的志愿填的全部都是医学专业，最后考取了同济医学院。1997 年我大学毕业，就到了中心医院，之前在心血管内科工作，2010 年到急诊科当主任的。</p><p>我觉得急诊科就像我的一个孩子一样，我把它搞成这么大，搞得大家团结起来，做成这个局面不容易，所以很珍惜，非常珍惜这个集体。</p><p>前几天，我的一个护士发朋友圈说，好怀念以前忙碌的大急诊，那种忙跟这种忙完全是两个概念。</p><p>在这次疫情之前，心梗、脑梗、消化道出血、外伤等等这些才是我们急诊的范畴。那种忙是有成就感的忙，目的明确，针对各种类型的病人都有很通畅的流程，很成熟，下一步干什么，怎么做，出了问题找哪一个。而这一次是这么多危重病人没办法去处理，没办法收住院，而且我们医务人员还在这种风险之中，这种忙真的很无奈，很痛心。</p><p>有一天早上 8 点，我们科一个年轻医生跟我发微信，也是蛮有性格的，说我今天不来上班了，不舒服。因为我们这里都有规矩的，你不舒服要提前跟我说好安排，你到 8 点钟跟我说，我到哪里去找人。他在微信中对我发脾气，说大量的高度疑似病例被你领导的急诊科放回社会，我们这是作孽！我理解他是因为作为医生的良知，但我也急了，我说你可以去告我，如果你是急诊科主任，你该怎么办？</p><p>后来，这个医生休息了几天后，还是照样来工作。他不是说怕死怕累，而是遇到这种情况，一下子面对这么多病人感到很崩溃。</p><p>作为医生来说，特别是后面很多来支援的医生，根本心理上受不了，碰到这种情况懵了，有的医生、护士就哭。一个是哭别人，再一个也是哭自己，因为每个人都不知道什么时候就轮到自己感染。</p><p>大概在 1 月中下旬，医院的领导也陆陆续续地都病倒了，包括我们的门办主任，三位副院长。医务科科长的女儿也病了，他也在家里休息。所以基本上那一段时间是没有人管你，你就在那儿战斗吧，就是那种感觉。</p><p>我身边的人也开始一个接一个地倒掉。1 月 18 日，早上 8 点半，我们倒的第一个医生，他说主任我中招了，不烧，只做了 CT，肺部一大坨磨玻璃。不一会儿，隔离病房负责的一个责任护士，告诉我说他也倒了。晚上，我们的护士长也倒了。我当时非常真实的第一感觉是——幸运，因为倒得早，可以早点下战场。</p><p>这三个人我都密切接触过，我就是抱着必倒的信念每天在工作，结果一直没倒。全院的人都觉得我是个奇迹。我自己分析了一下，可能是因为我本身有哮喘，在用一些吸入性的激素，可能会抑制这些病毒在肺内沉积。</p><p>我总觉得我们做急诊的人都算是有情怀的人——在中国的医院，急诊科的地位在所有科室当中应该是比较低的，因为大家觉得急诊，无非就是个通道，把病人收进去就行了。这次抗疫中，这种忽视也一直都存在。</p><p>早期的时候，物资不够，有时候分给急诊科的防护服质量非常差，看到我们的护士竟然穿着这种衣服上班，我很生气，在周会群里面发脾气。后来还是好多主任把他们自己科室藏的衣服都给我了。</p><p>还有吃饭问题。病人多的时候管理混乱，他们根本想不到急诊科还差东西吃，很多科室下班了都有吃的喝的，摆一大排，我们这里什么都没有，发热门诊的微信群里，有医生抱怨，「我们急诊科只有纸尿裤……」我们在最前线战斗，结果是这样，有时候心里真的很气。</p><p>我们这个集体真的是很好，大家都是只有生病了才下火线。这次，我们急诊科有 40 多个人感染了。我把所有生病的人建了一个群，本来叫「急诊生病群」，护士长说不吉利，改成「急诊加油群」。就是生病的人也没有很悲伤、很绝望、很抱怨的心态，都是蛮积极的，就是大家互相帮助，共度难关那种心态。</p><p>这些孩子们、年轻人都非常好，就是跟着我受委屈了。我也希望这次疫情过后，国家能加大对急诊科的投入，在很多国家的医疗体系中，急诊专业都是非常受重视的。</p><p><img src="https://i.loli.net/2020/03/10/MbICL3EFjOtTcmA.jpg" alt="IMG_7755.JPG"></p><p><strong>不能达到的幸福</strong></p><p>2 月 17 号，我收到了一条微信，是那个同济医院的同学发给我的，他跟我说「对不起」，我说：幸好你传出去了，及时提醒了一部分人。他如果不传出去的话，可能就没有李文亮他们这 8 个人，知道的人可能就会更少。</p><p>这次，我们有三个女医生全家感染。两个女医生的公公、婆婆加老公感染，一个女医生的爸爸、妈妈、姐姐、老公，加她自己 5 个人感染。大家都觉得这么早就发现这个病毒，结果却是这样，造成这么大的损失，代价太惨重了。</p><p>这种代价体现在方方面面。除了去世的人，患病的人也在承受。</p><p>我们「急诊加油群」里，大家经常会交流身体状况，有人问心率总在 120 次 / 分，要不要紧？那肯定要紧，一动就心慌，这对他们终身都会有影响的，以后年纪大了会不会心衰？这都不好说。以后别人可以去爬山，出去旅游，他们可能就不行，那都是有可能的。</p><p>还有武汉。你说我们武汉是个多热闹的地方，现在一路上都是安安静静的，很多东西买不到，还搞得全国都来支援。前几天广西的一个医疗队的护士在工作的时候突然昏迷了，抢救，后来人心跳有了，但还是在昏迷。她如果不来的话，在家里可以过得好好的，也不会出这种意外。所以，我觉得我们欠大家的人情，真的是。</p><p>经历过这次的疫情，对医院里很多人的打击都非常大。我下面好几个医务人员都有了辞职的想法，包括一些骨干。大家之前对于这个职业的那些观念、常识都难免有点动摇——就是你这么努力工作到底对不对？就像江学庆一样，他工作太认真，太对病人好，每一年的过年过节都在做手术。今天有人发一个江学庆女儿写的微信，说她爸爸的时间全部给了病人。</p><p>我自己也有过无数次的念头，是不是也回到家做个家庭主妇？疫情之后，我基本上没回家，和我老公住在外面，我妹妹在家帮我照顾孩子。我的二宝都不认得我了，他看视频对我没感觉，我很失落，我生这个二胎不容易，出生的时候他有 10 斤，妊娠糖尿病我也得了，原本我还一直喂奶的，这一次也断了奶——做这个决定的时候，我有点难过，我老公就跟我说，他说人的一生能够遇到一件这样的事情，并且你不光是参与者，你还要带一个团队去打这场仗，那也是一件很有意义的事情，等将来一切都恢复正常以后大家再去回忆，也是一个很宝贵的经历。</p><p>2 月 21 号早上领导和我谈话，其实我想问几个问题，比如有没有觉得那天批评我批评错了？我希望能够给我一个道歉。但是我不敢问。没有人在任何场合跟我说表示抱歉这句话。但我依然觉得，这次的事情更加说明了每个人还是要坚持自己独立的思想，因为要有人站出来说真话，必须要有人，这个世界必须要有不同的声音，是吧？</p><p>作为武汉人，我们哪一个不热爱自己的城市？我们现在回想起来以前过得那种最普通的生活，是多么奢侈的幸福。我现在觉得把宝宝抱着，陪他出去玩一下滑梯或者跟老公出去看个电影，在以前再平常都不过，到现在来说都是一种幸福，都是不能达到的幸福。</p>]]></content>
    
    <summary type="html">
    
      这是《人物》3 月刊封面《武汉医生》的第二篇报道。
    
    </summary>
    
    
      <category term="Archive" scheme="http://yoursite.com/categories/Archive/"/>
    
    
      <category term="新冠肺炎" scheme="http://yoursite.com/tags/%E6%96%B0%E5%86%A0%E8%82%BA%E7%82%8E/"/>
    
  </entry>
  
  <entry>
    <title>snorkel抽取BC5CDR数据集关系</title>
    <link href="http://yoursite.com/2019/12/17/snorkel%E6%8A%BD%E5%8F%96BC5CDR%E6%95%B0%E6%8D%AE%E9%9B%86%E5%85%B3%E7%B3%BB/"/>
    <id>http://yoursite.com/2019/12/17/snorkel%E6%8A%BD%E5%8F%96BC5CDR%E6%95%B0%E6%8D%AE%E9%9B%86%E5%85%B3%E7%B3%BB/</id>
    <published>2019-12-17T14:58:13.000Z</published>
    <updated>2019-12-23T02:02:03.782Z</updated>
    
    <content type="html"><![CDATA[<p>本周的工作是继续用snorkel工具以弱监督的方法在BC5CDR数据集进行抽取和评估，这也是snorkel在生物医学领域关系抽取的官方tutorial示例。其中BC5CDR包含500篇摘要的CID关系(chemical-induced-diseases)，与我们制定的关系类型chemical-causes-disease一致。此外，阅读了一篇发表在AKBC 2019探讨了在半监督模型中加入集成学习对关系抽取影响的文章。</p><a id="more"></a><p>上篇博客用弱监督的方法在chemical-disease关系抽取上进行了尝试，证明了与有监督模型相比的有效性，本周基于BC5CDR数据集的新特性，对标签函数进行了修改和重写。还在此基础上加入集成学习提高精度。</p><p>原始数据为xml格式的PubMed摘要和标注信息：</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/1.png"><p>抽取方法同上篇，采用的snorkel弱监督学习框架，通过用户编写标签函数(LFs)，然后利用生成模型学习标签函数准确性，输出概率训练标签，来训练神经网络判别模型。其中标签函数的制定采用规则、正则匹配或是远程监督的方法（本周选用了一个），生成模型为对标签函数的概率投票，作为输入x的概率标签y，最后用一个判别模型（如神经网络）进行关系分类。  </p><p>首先进行数据预处理，snorkel内部预置了CorpusParser模块处理xml得到句子，然后用TaggerOne标注实体（这也是pubtator使用的工具），选出句子中的候选实体对。之后是编写标签函数生成概率标签：</p><p>这里采用了三种标签函数类型，有CTD知识库远程监督方法：</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/2.png"><p>正则表达式规则：</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/3.png"><p>上下文层级特征：</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/4.png"><p>然后将标签函数用于训练集的标签产生，在dev数据集判别效果，训练生成式模型：</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/5.png"><p>最后将生成模型产生的概率标签作为训练集x的标签，用LSTM网络进行模型训练，在测试集评估精度。</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/6.png"><p>最后测得的F-score为0.5286。</p><p>与其他模型达到的SOTA结果对比：</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/10.png">  <p>最后将模型用在大规模PubMed文献上，与前期文献获取和实体标注的流程串联。</p><p>生成的候选实体如下（1000篇文献，12537个句子，1779个chemical-disease实体对）</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/8.png"><p>最终预测结果（前20个候选实体及预测标签）：</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/9.png"><p>后来在AKBC 2019找到一篇用半监督集成学习做弱监督关系抽取的文章《Semi-supervised Ensemble Learning with Weak Supervision for Biomedical Relation Extraction》，文章为避免标签函数的制定过程中采用复杂的feature engineering造成过拟合，采用了集成学习的方法。</p><p>思路是(1)用小型带标签数据集训练base learners，来预测更多的unlabeled data为weak labels；(2)加denoiser，然后在此基础上用弱监督学习训练更强大的meta-learner(noise-aware discriminative model，这里选用的是双向LSTM)。文章的创新之处是选用K个基础学习器，通过改变features、文本特征表示和机器学习模型等来构建多个分类器，这样生成的概率标签相当于集多个模型的优点，更robust。</p><p>下图结果展示了用机器学习模型集成学习产生弱标签对关系抽取的影响，在参数的选择，降噪方法的选择，meta-learner选择上的不同表现。</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/7.png"><p>可以看出在弱监督学习中加入base learners确实相比我们自己定义的标签函数学习到的结果（0.5286）有F-score的提升（右侧三列），而却可以用本文提出的模型做数据扩增，迁移领域只需要标注少量的金标准数据集即可。此外，鉴于F1 score有时会不具有说服力，文章还因此提出了对marginal weak labels更好的评估方法。  </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本周的工作是继续用snorkel工具以弱监督的方法在BC5CDR数据集进行抽取和评估，这也是snorkel在生物医学领域关系抽取的官方tutorial示例。其中BC5CDR包含500篇摘要的CID关系(chemical-induced-diseases)，与我们制定的关系类型chemical-causes-disease一致。此外，阅读了一篇发表在AKBC 2019探讨了在半监督模型中加入集成学习对关系抽取影响的文章。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>snorkel初探</title>
    <link href="http://yoursite.com/2019/11/25/snorkel%E5%88%9D%E6%8E%A2/"/>
    <id>http://yoursite.com/2019/11/25/snorkel%E5%88%9D%E6%8E%A2/</id>
    <published>2019-11-25T01:35:32.000Z</published>
    <updated>2019-12-17T14:56:52.947Z</updated>
    
    <content type="html"><![CDATA[<p>远程监督是关系抽取中最常采用的方法，它的核心思想是将文本与大规模知识图谱进行实体对齐，利用知识图谱已有的实体间关系对文本进行标注，可以有效解决有监督学习抽取样本过少的问题。而snorkel是斯坦福大学deepdive框架的后续项目，它将deepdive中的远程监督和弱监督的思想进一步完善，并用纯python的形式构成了一套完整的学习框架。我们的关系抽取项目采用snorkel与深度学习相结合的方法。</p><a id="more"></a><p>人工标记训练数据费时费力，所以最好的方式是利用外部知识库、模式/规则或其他分类器来启发式地生成训练数据。从本质上来讲，这些都是以编程方式生成训练数据的方法，或者更简洁地说就是编程训练数据。</p><p>远程监督基本假设是：如果从知识图谱中可获取三元组R(E1, E2)（注：R代表关系，E1、E2代表两个实体），且E1和E2共现与句子S中，则S表达了E1和E2间的关系R，标注为训练正例。由于假设过强，会出现wrong label的问题，常采用多实例学习的方法解决，将所有包含该关系的句子组成一个bag然后筛选句子生成训练样本。后来提出multi-instance multi-labels，即一个句子只能表达E1和E2的一种关系，但是不同的句子可以表达多个关系即labels，为同时挖掘实体对的多个关系提供了可能。</p><p>snorkel采用的方法是用户编写标签函数(LFs)，然后利用生成模型学习标签函数准确性，输出概率训练标签，来训练神经网络判别模型，流程如下：</p><img src="/2019/11/25/snorkel初探/1.png"><img src="/2019/11/25/snorkel初探/2.png"><img src="/2019/11/25/snorkel初探/3.png"><p>By using the label model to transfer the domain knowledge encoded in our LFs to the discriminative model, we were able to generalize beyond the noisy labeling heuristics.</p><p>以下是周报的内容：</p><h5 id="工作内容："><a href="#工作内容：" class="headerlink" title="工作内容："></a>工作内容：</h5><p>(1)关系抽取是知识图谱构建中非常基础和重要的一环，可以说知识图谱内部保存的数据就是高精度的三元组关系。前期的工作已经完成了实体抽取和实体规范化，已经得到了关系抽取中的候选实体，下一步就是在每句话的候选实体对上运用关系抽取模型抽取得到关系。</p><p>(2)之前的工作包括调研关系抽取方法，制定关系标准，寻找可用的数据集。由于关系抽取的金标准数据集太少，大规模图谱构建一般采用有监督和弱监督相结合的方法，前者通过研究新模型提高识别精度，后者加入远程监督解决金标准数据集较少的问题。但在生物医学领域多数研究都是基于前者，极少有能够落地到对文献进行大规模关系抽取的方法（尤其是深度学习模型），因为训练数据集少导致模型过拟合不足以应对文献内的复杂变化的关系。通过加入后者弱监督学习，可以提高模型的泛化能力。本周工作即为弱监督模型在chemical-disease关系抽取的尝试，证明该方法在使用少量金标准数据集就能达到相当的精度。</p><p>(3)本次工作为用snorkel框架，对chemical和disease间的cause和treat关系进行抽取。数据集为通过众包构建的<a href="https://github.com/CrowdTruth/Medical-Relation-Extraction" target="_blank" rel="noopener">CrowdTruth数据集</a>: 包括3984个包含cause和treat关系的句子，部分经过人工标注。  </p><img src="/2019/11/25/snorkel初探/4.png"><p>首先准备数据，得到结果如上图，划分数据集为train-dev-val-test四部分。其中train不含金标准标签（因为要在训练时生成x的概率标签），dev为少量带专家标注的金标准数据，通过评估选择标签函数和得到生成模型，val充当验证集调整最后的判别式模型参数，最后在test上测试精度。</p><p>其中标签函数的编写是决定模型性能的关键，其实有点类似于基于规则的有监督学习中的特征工程，包括关键词类型的：</p><img src="/2019/11/25/snorkel初探/5.png"><p>正则表达式类型的：</p><img src="/2019/11/25/snorkel初探/6.png"><p>还可以加入启发式规则还有基于远程监督的，最后将规则用于训练集的标签产生，在dev数据集判别如下，然后通过coverage（recall）和correct（precision）的trade-off来选择标签输入生成模型：</p><img src="/2019/11/25/snorkel初探/7.png"><p>最后设计将生成模型产生的概率标签作为训练集x的标签，用LSTM网络进行模型训练，将训练好的模型在测试集评估精度，与从开始直接用金标准数据集训练的模型对比。  </p><img src="/2019/11/25/snorkel初探/8.png"><p>结果如下，可以看出基于不同标签函数的snorkel与使用众包标签和基线的精度对比精度下降在可接受的范围内。</p><img src="/2019/11/25/snorkel初探/9.png">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;远程监督是关系抽取中最常采用的方法，它的核心思想是将文本与大规模知识图谱进行实体对齐，利用知识图谱已有的实体间关系对文本进行标注，可以有效解决有监督学习抽取样本过少的问题。而snorkel是斯坦福大学deepdive框架的后续项目，它将deepdive中的远程监督和弱监督的思想进一步完善，并用纯python的形式构成了一套完整的学习框架。我们的关系抽取项目采用snorkel与深度学习相结合的方法。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>脑区连接关系提取</title>
    <link href="http://yoursite.com/2019/11/21/%E8%84%91%E5%8C%BA%E8%BF%9E%E6%8E%A5%E5%85%B3%E7%B3%BB%E6%8F%90%E5%8F%96/"/>
    <id>http://yoursite.com/2019/11/21/%E8%84%91%E5%8C%BA%E8%BF%9E%E6%8E%A5%E5%85%B3%E7%B3%BB%E6%8F%90%E5%8F%96/</id>
    <published>2019-11-21T09:06:55.000Z</published>
    <updated>2019-11-25T01:26:48.650Z</updated>
    
    <content type="html"><![CDATA[<p>大多数生物医学领域的关系提取都是面向通用的基因、化学物质、疾病间的，很少研究大脑神经投射和连接性的。调研找到的文献不多，这里汇总一下：</p><a id="more"></a><h4 id="Automated-recognition-of-brain-region-mentions-in-neuroscience-literature-2009"><a href="#Automated-recognition-of-brain-region-mentions-in-neuroscience-literature-2009" class="headerlink" title="Automated recognition of brain region mentions in neuroscience literature(2009)"></a>Automated recognition of brain region mentions in neuroscience literature(2009)</h4><p>课题意义是建立与脑区有关的基因表达和模拟连接，为此他们提出了whitetext项目，手工标注了1377篇神经科学文献摘要中的18242个脑区，然后采用几种方法识别并评估了识别精度：基于词典（被词典大小严重限制导致召回率低）和CRF；还分析了词窗大小、词干化处理和缩写扩展对识别精度的影响。</p><ol><li><p>语料库建立方法：依据关键词检索、随机挑选Journal of Comparative Neurology期刊文章、mesh匹配的方法选择了1377篇尽可能提及脑区的文章，以xml格式存储，然后使用缩写扩增算法将文中提及的全称或缩写统一用”全称(缩写)”的形式扩增。然后请人依照脑图谱和词典手工标注，标注范围不能太宽泛(不标注system级别的)，也不能太精细(不具体到核团的某一层)，标注示例： “motor related areas of the hippocampus”.</p></li><li><p>基于词典的匹配： 使用的词典：Neuronames，Nomenclatures of Canonical Mouse，Rat Brain Atlases and the Ontology of Human and Macaque Neuroanatomy.  匹配方法：GATE Gazetteer</p></li><li><p>条件随机场：相比HMM优点是当前状态的概率依据整个输入序列tokens计算而不仅仅是前一状态的token，通过定义feature function组合features</p></li><li><p>features的选择：拼写特征(如大写字母或者数字)和词性特征POS tagging；词干特征（用GENIA biomedical corpus训练的TreeTagger标注）；上下文特征：n-grams，word window；还有一些描述脑区边界的特征词：(e.g. bank, sulci, surface,area), neuroanatomical directions (e.g. dorsal, superior), root neuroscience terms (e.g. chiasm, raphe, striated). 识别结果如下：，</p><img src="/2019/11/21/脑区连接关系提取/1.png"></li></ol><h4 id="Application-and-evaluation-of-automated-methods-to-extract-neuroanatomical-connectivity-statements-from-free-text-2012"><a href="#Application-and-evaluation-of-automated-methods-to-extract-neuroanatomical-connectivity-statements-from-free-text-2012" class="headerlink" title="Application and evaluation of automated methods to extract neuroanatomical connectivity statements from free text(2012)"></a>Application and evaluation of automated methods to extract neuroanatomical connectivity statements from free text(2012)</h4><p>接上一篇，继续标注了1377篇the Journal of Comparative Neurology文献的神经模拟连接，只考虑连接关系，不考虑连接属性、强度和方向，然后用基于词语共现和规则的方法，基于POS、依存解析和句法特征的机器学习方法抽取关系做测试，证实了之前抽取PPI的几种核方法可以用于抽取脑连接关系，并建立了完整的脑区识别和关系识别流程。这是大规模文本挖掘在神经解剖学连接抽取的首次应用。</p><ol><li><p>金标准标注：先标注所有脑区，然后标注所有的脑区连接，不标注白质和神经冲动，仅标注突触或直接连接。</p></li><li><p>基于共现的方法：在单个句子内共现或整个摘要内共现；基于规则：限制脑区提及数目，限制连接关键词(‘afferent’, ‘efferent’, ‘projects’, ‘projection’, ‘pathway’ or ‘inputs’)</p></li><li><p>四种基于核函数的统计机器学习方法：句法和依存解析核，all-paths graph kernel，k-band shortest path spectrum kernel，使用单词共现和POS的浅层语义核 (SLK)，精度比较如图：</p><img src="/2019/11/21/脑区连接关系提取/2.png"></li><li><p>然后用slk做关系抽取，将抽取的连接关系与现存的脑模拟连接数据库如<a href="https://bams1.org" target="_blank" rel="noopener">BAMS</a>作比较（normalization)，抽取及规范化流程如下：</p><img src="/2019/11/21/脑区连接关系提取/3.png"><p>将提取到的关系映射到标准化的BAMS词典比较困难（63％），采用关系同义词匹配或是用共现代替关系的方法可以改善匹配率，但会降低准确率。</p></li></ol><h4 id="Text-mining-for-neuroanatomy-using-WhiteText-with-an-updated-corpus-and-a-new-web-application-2015"><a href="#Text-mining-for-neuroanatomy-using-WhiteText-with-an-updated-corpus-and-a-new-web-application-2015" class="headerlink" title="Text mining for neuroanatomy using WhiteText with an updated corpus and a new web application(2015)"></a>Text mining for neuroanatomy using WhiteText with an updated corpus and a new web application(2015)</h4><p>接上两篇，先总结了一下过去的结果：</p><img src="/2019/11/21/脑区连接关系提取/4.png"><ol><li>脑区识别：对标注的1377篇摘要进行脑区NER，采用条件随机场，八折交叉验证，recalled 76% of brain region mentions at 81% precision</li><li>脑区标准化/规范化：采用了5个跨物种的神经科学词典（NeuroNames, NIFSTD, the Brede Database, BAMS and AMBA)，它们提供了大约1000个脑区的11,909 个名称。尝试词典匹配（先精确匹配，然后忽略词序的词袋匹配，最后词干匹配），设计修改规则提高精度（P 95％ R 63％）</li><li>脑区连接：多数提及的脑区连接是负样本(no connectivity )，采用浅层语义核(slk)能达到P 50％ R 70％</li></ol><p>然后用半自动抽取+手工修正的方式创建了新数据集（加入了1828篇摘要和2111个连接关系），用MScanner 工具扩展标注其他期刊的8264篇JCN文献模拟连接信息。</p><img src="/2019/11/21/脑区连接关系提取/5.png"><p>最后还将结果展示在<a href="https://whitetext.msl.ubc.ca" target="_blank" rel="noopener">网页上</a>，提供查询和导出（Indexing 71306 sentences with 68957 connections between 88088 brain region mentions.），查询关键词是与NIFSTD中的名词匹配的。</p><p>不足之处：仅摘要、单个句子、关系无方向性</p><h4 id="Extracting-Relation-between-Brain-Region-pairs-from-White-Text-2017"><a href="#Extracting-Relation-between-Brain-Region-pairs-from-White-Text-2017" class="headerlink" title="Extracting Relation between Brain Region pairs from White Text(2017)"></a>Extracting Relation between Brain Region pairs from White Text(2017)</h4><p>创新之处是运用graph Kernel的方法抽取在同一个句子中出现不止两个脑区实体间的关系。</p><img src="/2019/11/21/脑区连接关系提取/6.png"><p>方法就是对whitetext语料，选择词的tf-idf作特征，加入基于图的浅层语义核SLK还有解析树核DTK得到特征向量，用SVM分类器输出每对实体的关系。其中baseline为只用tf-idf或BOW作特征，结果如下：</p><img src="/2019/11/21/脑区连接关系提取/7.png"><h4 id="Large-scale-extraction-of-brain-connectivity-from-the-neuroscientific-literature-2015"><a href="#Large-scale-extraction-of-brain-connectivity-from-the-neuroscientific-literature-2015" class="headerlink" title="Large-scale extraction of brain connectivity from the neuroscientific literature(2015)"></a>Large-scale extraction of brain connectivity from the neuroscientific literature(2015)</h4><h5 id="Introduction："><a href="#Introduction：" class="headerlink" title="Introduction："></a>Introduction：</h5><ol><li>神经科学的结果、知识和数据分散在期刊中，访问效率很低。脑连接性数据有这些来源：1. Allen Mouse Brain Connectivity Atlas(AMBCA)，2. BAMS（包含600多篇手工整理的文献数据）3. 神经科学文章，采用传统手工搜索的方法有一些局限：命名系统的多样性导致手动搜索的不确定性，还有召回率低（缺少缩写扩展和同义词扩展），精度低（共现关系不代表相关关系）。</li><li>信息抽取综述：IE = NER+RE，其中NER最简单的方式是直接匹配（Lexical matching ）字典中的实体（缺乏同义词，而且过于具体，导致召回率低），稍复杂的方式是有监督学习；RE多采用基于规则和基于机器学习(P 50.3% R 70.1%)</li></ol><h5 id="Methods-and-Results"><a href="#Methods-and-Results" class="headerlink" title="Methods and Results:"></a>Methods and Results:</h5><ol><li><p>Brain region NERs: 词典匹配的方法处理同义词、扩展缩写；机器学习的方法在CRF上发掘更多特征</p></li><li><p>Connectivity Extractors: FILTER的方法采用过滤器过滤脑区共现的句子，KERNEL的方法同采用浅层语义解析，RULES的方法基于九种规则类似于‘projection from the region A (of the region B) to the region C and the region D’ </p></li><li><p>NER结果：基于词典的方式无论采用精确匹配还是粗略匹配召回率都不高，但是用于非常大的语料库注重精度时，可以采用基于词典匹配的方法</p><img src="/2019/11/21/脑区连接关系提取/8.png"> </li><li><p>RE结果（不考虑有1/4是跨句子的连接关系）：基于FILTER召回率高，基于RULES精确率高，基于KERNEL适中，对于大规模的语料库需要提高精度可以采用组合的方式。</p><img src="/2019/11/21/脑区连接关系提取/9.png"> </li></ol><h5 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation:"></a>Evaluation:</h5><img src="/2019/11/21/脑区连接关系提取/10.png"> <p>对13.2 million篇PubMed摘要和630 216篇PMC全文，用上图pipeline做了提取，并统计了内部模型一致性和外部数据库AMBCA匹配一致性。</p><img src="/2019/11/21/脑区连接关系提取/11.png"> <p>最后总结这项工作的意义不是替代人抽取关系，而是提供一个平台让研究人员关注更可能出现的连接性关系，还有对模型不一致的情况进行手动筛选和评估（包括POS和NEG关系）。开源了抽取框架<a href="https://github.com/BlueBrain/bluima" target="_blank" rel="noopener">bluima</a></p><p>之后可以在框架内改进模型比如加入深度学习。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大多数生物医学领域的关系提取都是面向通用的基因、化学物质、疾病间的，很少研究大脑神经投射和连接性的。调研找到的文献不多，这里汇总一下：&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>知识库流程综述v1</title>
    <link href="http://yoursite.com/2019/07/30/%E7%9F%A5%E8%AF%86%E5%BA%93%E6%B5%81%E7%A8%8B%E7%BB%BC%E8%BF%B0v1/"/>
    <id>http://yoursite.com/2019/07/30/%E7%9F%A5%E8%AF%86%E5%BA%93%E6%B5%81%E7%A8%8B%E7%BB%BC%E8%BF%B0v1/</id>
    <published>2019-07-30T02:11:43.000Z</published>
    <updated>2019-09-02T03:42:24.050Z</updated>
    
    <content type="html"><![CDATA[<p>这篇应该算是知识库构建的整个流程，之后可能需要跟老师交流后增减一些东西。</p><a id="more"></a><ol><li><p>文献数据获取及预处理：</p><p>思路：先获取所有与脑区核团相关的Pubmed文献，脑区核团名称来自于Allen本体，获取的数据格式一般为txt，之后，对获取数据进行数据预处理，转化为json格式或其他需要的格式。</p><p>难点：①获取完整全面的文献数据，需要考虑各个核团名称的缩写词、同义词；</p><p>②获取的数据编码为utf-8，但部分数据存在乱码现象，需要做一个预处理。</p><p>思考：①只获取与核团相关的文献构建知识库可能不够，所以需要获取更多的文献导入进知识库中；</p><p>②需要获取PMC的文献，对全文数据进行检索，使数据库变得更加丰富。</p></li><li><p>NER（实体抽取）：</p><p>接下来，使用现有工具对获取到的文献进行命名实体识别，具体工具有pubtator和saber，这两个工具主要识别基因（gene）、疾病（disease）、化学物质（chemical）三类实体。</p><p>Pubtator：将获取文献的pmid整理成一个txt，输入给pubtator，返回标注后的结果，该方法速度快，1000篇文献需要30-40s；</p><p>Saber：将获取的原始文献输入给saber，返回标注结果，该方法的速度较慢，10篇文献需要20s左右。</p><p>难点：①saber方法返回速度较慢，处理所有文献需要的时间过长，需要考虑是否继续使用该方法。具体思路：先将获取的文献进行抽样，将抽样的文献输入给该系统，进行NER，将获取的结果与pubtator进行比较，提取出saber识别的但pubtator不存在的实体进行评估，将该实体与标准字典进行匹配，计算数据的准确率，以此确认该方法是否继续使用。</p><p>②需要考虑获取的三种类别是否能够满足知识库的需求，是否需要继续寻找其他可用工具。</p></li><li><p>NEL（实体链接）（进行中）：</p><p>获取的命名实体数据主要包括实体名称，外部数据库编号，将这部分数据与标准字典（UMLS）进行匹配，将匹配到的数据保留下来，未匹配到的数据进行剔除。</p><p>难点：①首先要构建标准字典，讨论确定标准字典的数据集；</p><p>②实体名称字段进行精确匹配会存在很大的问题。首先，文献中实体名称不一定是标准名称，有可能出现匹配不到的情况；其次，识别保存结果可能与标准名称存在格式差异，也会导致匹配不到相应结果的情况；</p><p>③外部数据库编号匹配也可能存在问题。首先，不同NER系统给出的外部数据库编号之间可能存在差异，因此，和标准数据库匹配时可能存在不匹配的问题。</p></li><li><p>RE（关系抽取）（进行中）：</p><p>利用现有工具对文献中实体进行关系抽取，现有工具利用Pubtator抽取文献中的实体，之后对实体进行关系抽取。接下来，需要将抽取的关系与标准数据库（SemmedDB）进行匹配。</p><p>难点：①现有工具的选择和确认：初步有几个项目和工具，bran，GNBR和snorkel，需要整合到标准库上</p><p>②标准关系类别定义：UMLS Semantic Network。现有工具抽取的关系定义与标准关系可能存在差异，需要将抽取的关系先与标准关系进行对应，此处需要人为筛选定义映射关系。之后，对抽取的关系进行筛选，将不存在的实体关系剔除掉，筛选方案需要继续讨论；</p><p>③需要评估关系抽取的精度，对文献检索的参考意义有多大</p></li><li><p>与本体匹配（方法已实现）：</p><p>暂时选用的是biolink本体，因为没有发现更适用的神经科学本体，手工制定也不太现实</p></li><li><p>数据存储：</p><p>将获取的文献、命名实体和实体关系全部导入MongoDB数据库中，以json格式数据进行保存；还将标准化后的关系导入图数据库neo4j方便展示</p></li><li><p>数据检索（未做）：</p><p>将数据库中的数据导入进elasticsearch中，利用elasticsearch进行数据检索，输入关键词后，返回相应的文献，并将文献中的实体（关系）标注出来。</p><p>难点：①elasticsearch搜索是基于关键词检索，会将满足关键词的信息返回，并以一定的排序算法将文献排序下来，需要思考如何改进排序算法，利用实体和关系将用户最需要的文献返回回来；</p><p>②需要将文献中的实体进行高亮标注，并以不同的颜色代表不同的实体（此步骤需要前端人员编写相应的函数）；</p><p>③需要思考如何将获取的关系在搜索结果中做进一步展示。</p></li><li><p>数据表示（未做）：</p><p>将检索的结果以网页可视化的形式展示出来。</p><p>难点：①需要懂前端的人员进行构建。</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇应该算是知识库构建的整个流程，之后可能需要跟老师交流后增减一些东西。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0726</title>
    <link href="http://yoursite.com/2019/07/26/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0726/"/>
    <id>http://yoursite.com/2019/07/26/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0726/</id>
    <published>2019-07-26T12:28:39.000Z</published>
    <updated>2020-08-28T06:55:22.911Z</updated>
    
    <content type="html"><![CDATA[<p>最后是注意力机制在RE的应用。</p><a id="more"></a><h4 id="Attention-based-Neural-Networks-for-Chemical-Protein-Relation-Extraction-2017"><a href="#Attention-based-Neural-Networks-for-Chemical-Protein-Relation-Extraction-2017" class="headerlink" title="Attention-based Neural Networks for Chemical Protein Relation Extraction(2017)"></a>Attention-based Neural Networks for Chemical Protein Relation Extraction(2017)</h4><h4 id="Learning-local-and-global-contexts-using-a-convolutional-recurrent-network-model-for-relation-classification-in-biomedical-text-2017"><a href="#Learning-local-and-global-contexts-using-a-convolutional-recurrent-network-model-for-relation-classification-in-biomedical-text-2017" class="headerlink" title="Learning local and global contexts using a convolutional recurrent network model for relation classification in biomedical text(2017)"></a>Learning local and global contexts using a convolutional recurrent network model for relation classification in biomedical text(2017)</h4><h4 id="Attending-to-All-Mention-Pairs-for-Full-Abstract-Biological-Relation-Extraction-2017"><a href="#Attending-to-All-Mention-Pairs-for-Full-Abstract-Biological-Relation-Extraction-2017" class="headerlink" title="Attending to All Mention Pairs for Full Abstract Biological Relation Extraction(2017)"></a>Attending to All Mention Pairs for Full Abstract Biological Relation Extraction(2017)</h4><h4 id="Simultaneously-Self-Attending-to-All-Mentions-for-Full-Abstract-Biological-Relation-Extraction-2018"><a href="#Simultaneously-Self-Attending-to-All-Mentions-for-Full-Abstract-Biological-Relation-Extraction-2018" class="headerlink" title="Simultaneously Self-Attending to All Mentions for Full-Abstract Biological Relation Extraction(2018)"></a>Simultaneously Self-Attending to All Mentions for Full-Abstract Biological Relation Extraction(2018)</h4><h4 id="Extracting-chemical-protein-relations-usingattention-based-neural-networks-2018"><a href="#Extracting-chemical-protein-relations-usingattention-based-neural-networks-2018" class="headerlink" title="Extracting chemical-protein relations usingattention-based neural networks(2018)"></a>Extracting chemical-protein relations usingattention-based neural networks(2018)</h4><h4 id="Combining-Context-and-Knowledge-Representations-for-Chemical-disease-Relation-Extraction-2018"><a href="#Combining-Context-and-Knowledge-Representations-for-Chemical-disease-Relation-Extraction-2018" class="headerlink" title="Combining Context and Knowledge Representations for Chemical-disease Relation Extraction(2018)"></a>Combining Context and Knowledge Representations for Chemical-disease Relation Extraction(2018)</h4><h4 id="A-document-level-neural-model-integrated-domain-knowledge-for-chemical-induced-disease-relations-2018"><a href="#A-document-level-neural-model-integrated-domain-knowledge-for-chemical-induced-disease-relations-2018" class="headerlink" title="A document level neural model integrated domain knowledge for chemical-induced disease relations(2018)"></a>A document level neural model integrated domain knowledge for chemical-induced disease relations(2018)</h4><h4 id="Chemical-induced-disease-relation-extraction-with-dependency-information-T-and-prior-knowledge-2018"><a href="#Chemical-induced-disease-relation-extraction-with-dependency-information-T-and-prior-knowledge-2018" class="headerlink" title="Chemical-induced disease relation extraction with dependency information T and prior knowledge(2018)"></a>Chemical-induced disease relation extraction with dependency information T and prior knowledge(2018)</h4><h4 id="Distantly-Supervised-Biomedical-Knowledge-Acquisition-via-Knowledge-Graph-Based-Attention-2019"><a href="#Distantly-Supervised-Biomedical-Knowledge-Acquisition-via-Knowledge-Graph-Based-Attention-2019" class="headerlink" title="Distantly Supervised Biomedical Knowledge Acquisition via Knowledge Graph Based Attention(2019)"></a>Distantly Supervised Biomedical Knowledge Acquisition via Knowledge Graph Based Attention(2019)</h4><h4 id="Chemical-induced-disease-relation-extraction-via-attention-based-distant-supervision-2019"><a href="#Chemical-induced-disease-relation-extraction-via-attention-based-distant-supervision-2019" class="headerlink" title="Chemical-induced disease relation extraction via attention-based distant supervision(2019)"></a>Chemical-induced disease relation extraction via attention-based distant supervision(2019)</h4><h4 id="Relation-Extraction-using-Explicit-Context-Conditioning-2019"><a href="#Relation-Extraction-using-Explicit-Context-Conditioning-2019" class="headerlink" title="Relation Extraction using Explicit Context Conditioning(2019)"></a>Relation Extraction using Explicit Context Conditioning(2019)</h4><h4 id><a href="#" class="headerlink" title=" "></a> </h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最后是注意力机制在RE的应用。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0725</title>
    <link href="http://yoursite.com/2019/07/25/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0725/"/>
    <id>http://yoursite.com/2019/07/25/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0725/</id>
    <published>2019-07-25T12:28:33.000Z</published>
    <updated>2020-08-28T06:52:29.176Z</updated>
    
    <content type="html"><![CDATA[<p>这篇是NER和RE的联合抽取模型。</p><a id="more"></a><h4 id="A-hybrid-deep-learning-approach-for-medical-relation-extraction-2018"><a href="#A-hybrid-deep-learning-approach-for-medical-relation-extraction-2018" class="headerlink" title="A hybrid deep learning approach for medical relation extraction(2018)"></a>A hybrid deep learning approach for medical relation extraction(2018)</h4><h4 id="A-hybrid-model-based-on-neural-networks-for-biomedical-relation-extraction-2018"><a href="#A-hybrid-model-based-on-neural-networks-for-biomedical-relation-extraction-2018" class="headerlink" title="A hybrid model based on neural networks for biomedical relation extraction(2018)"></a>A hybrid model based on neural networks for biomedical relation extraction(2018)</h4><h4 id="Automatic-extraction-of-gene-disease-associations-from-literature-using-joint-ensemble-learning-2018"><a href="#Automatic-extraction-of-gene-disease-associations-from-literature-using-joint-ensemble-learning-2018" class="headerlink" title="Automatic extraction of gene-disease associations from literature using joint ensemble learning(2018)"></a>Automatic extraction of gene-disease associations from literature using joint ensemble learning(2018)</h4><h4 id="Joint-entity-recognition-and-relation-extraction-as-a-multi-head-selection-problem-2018"><a href="#Joint-entity-recognition-and-relation-extraction-as-a-multi-head-selection-problem-2018" class="headerlink" title="Joint entity recognition and relation extraction as a multi-head selection problem(2018)"></a>Joint entity recognition and relation extraction as a multi-head selection problem(2018)</h4><h4 id="Transfer-Learning-for-Scientific-Data-Chain-Extraction-in-Small-Chemical-Corpus-with-BERT-CRF-Model-2019"><a href="#Transfer-Learning-for-Scientific-Data-Chain-Extraction-in-Small-Chemical-Corpus-with-BERT-CRF-Model-2019" class="headerlink" title="Transfer Learning for Scientific Data Chain Extraction in Small Chemical Corpus with BERT-CRF Model(2019)"></a>Transfer Learning for Scientific Data Chain Extraction in Small Chemical Corpus with BERT-CRF Model(2019)</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇是NER和RE的联合抽取模型。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0724</title>
    <link href="http://yoursite.com/2019/07/24/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0724/"/>
    <id>http://yoursite.com/2019/07/24/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0724/</id>
    <published>2019-07-24T14:20:05.000Z</published>
    <updated>2020-08-28T06:53:31.542Z</updated>
    
    <content type="html"><![CDATA[<p>这篇是递归神经网络和树/图LSTM。</p><a id="more"></a><h4 id="Chemical-gene-relation-extraction-using-recursive-neural-network-2018"><a href="#Chemical-gene-relation-extraction-using-recursive-neural-network-2018" class="headerlink" title="Chemical-gene relation extraction using recursive neural network(2018)"></a>Chemical-gene relation extraction using recursive neural network(2018)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>提出了一种treeLSTM和叫Stack-augmented Parser Interpreter Neural Network (SPINN)的神经网络</p><h4 id="Drug-drug-interaction-extraction-from-the-literature-using-a-recursive-neural-network-2018"><a href="#Drug-drug-interaction-extraction-from-the-literature-using-a-recursive-neural-network-2018" class="headerlink" title="Drug drug interaction extraction from the literature using a recursive neural network(2018)"></a>Drug drug interaction extraction from the literature using a recursive neural network(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>采用treeLSTM的变体递归神经网络识别DDI四类关系（advice, effect, mechanism, and int），其中除了句子依存解析外，还加入了位置嵌入信息、子树包含特征和集成方法提高精度</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><p>模型如图，其中子树包含特征是指：如果一种目标药物存在于当前节点的叶子节点时特征的置1，否则置0</p><img src="/2019/07/24/文献阅读0724/1.png"><h4 id="BERE-AN-ACCURATE-DISTANTLY-SUPERVISED-BIOMEDICAL-ENTITY-RELATION-EXTRACTION-NETWORK-2019"><a href="#BERE-AN-ACCURATE-DISTANTLY-SUPERVISED-BIOMEDICAL-ENTITY-RELATION-EXTRACTION-NETWORK-2019" class="headerlink" title="BERE: AN ACCURATE DISTANTLY SUPERVISED BIOMEDICAL ENTITY RELATION EXTRACTION NETWORK(2019)"></a>BERE: AN ACCURATE DISTANTLY SUPERVISED BIOMEDICAL ENTITY RELATION EXTRACTION NETWORK(2019)</h4><h5 id="一句话总结-2"><a href="#一句话总结-2" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>采用了Gumbel Tree-GRU模型学习句子结构并整合实体嵌入信息，模型也加入了单词和句子级别的注意力机制提高关系抽取精度，在DDI’13数据集上取得了最好效果。</p><img src="/2019/07/24/文献阅读0724/2.png"><h4 id="Cross-Sentence-N-ary-Relation-Extraction-with-Graph-LSTMs-2017"><a href="#Cross-Sentence-N-ary-Relation-Extraction-with-Graph-LSTMs-2017" class="headerlink" title="Cross-Sentence N -ary Relation Extraction with Graph LSTMs(2017)"></a>Cross-Sentence N -ary Relation Extraction with Graph LSTMs(2017)</h4><h4 id="N-ary-Relation-Extraction-using-Graph-State-LSTM-2018"><a href="#N-ary-Relation-Extraction-using-Graph-State-LSTM-2018" class="headerlink" title="N -ary Relation Extraction using Graph State LSTM(2018)"></a>N -ary Relation Extraction using Graph State LSTM(2018)</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇是递归神经网络和树/图LSTM。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0723</title>
    <link href="http://yoursite.com/2019/07/23/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0723/"/>
    <id>http://yoursite.com/2019/07/23/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0723/</id>
    <published>2019-07-23T08:42:33.000Z</published>
    <updated>2020-08-28T06:54:04.801Z</updated>
    
    <content type="html"><![CDATA[<p>这篇是双向LSTM的。</p><a id="more"></a><h4 id="Leveraging-Biomedical-Resources-in-Bi-LSTM-for-Drug-Drug-Interaction-Extraction-2018"><a href="#Leveraging-Biomedical-Resources-in-Bi-LSTM-for-Drug-Drug-Interaction-Extraction-2018" class="headerlink" title="Leveraging Biomedical Resources in Bi-LSTM for Drug-Drug Interaction Extraction(2018)"></a>Leveraging Biomedical Resources in Bi-LSTM for Drug-Drug Interaction Extraction(2018)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>也是利用生物医学领域信息训练（metamap和skip-gram）的词向量结合Bi-LSTM抽取DDI关系。</p><img src="/2019/07/23/文献阅读0723/2.png"><h4 id="Feature-Assisted-bi-directional-LSTM-Model-for-Protein-Protein-Interaction-Identification-from-Biomedical-Texts-2018"><a href="#Feature-Assisted-bi-directional-LSTM-Model-for-Protein-Protein-Interaction-Identification-from-Biomedical-Texts-2018" class="headerlink" title="Feature Assisted bi-directional LSTM Model for Protein-Protein Interaction Identification from Biomedical Texts(2018)"></a>Feature Assisted bi-directional LSTM Model for Protein-Protein Interaction Identification from Biomedical Texts(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>加了最短依存路径SDP的Bi-LSTM提取PPI</p><img src="/2019/07/23/文献阅读0723/1.png"><h4 id="From-POS-tagging-to-dependency-parsing-for-biomedical-event-extraction-2019"><a href="#From-POS-tagging-to-dependency-parsing-for-biomedical-event-extraction-2019" class="headerlink" title="From POS tagging to dependency parsing for biomedical event extraction(2019)"></a>From POS tagging to dependency parsing for biomedical event extraction(2019)</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇是双向LSTM的。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0722</title>
    <link href="http://yoursite.com/2019/07/22/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0722/"/>
    <id>http://yoursite.com/2019/07/22/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0722/</id>
    <published>2019-07-22T00:46:54.000Z</published>
    <updated>2019-09-02T08:56:44.710Z</updated>
    
    <content type="html"><![CDATA[<p>在snorkel上卡了壳，不会写LF。。。回过头读一些CNN/LSTM/Attention+SDP+远程监督的文章补充基础知识吧，这也是通用领域做关系抽取的思路。</p><p>就按主体模型分几天记吧，这篇是CNN(之前写的BioRE文献阅读报告里面详述了模型演化过程，这里只是选了两篇运用到生物医学领域的)</p><a id="more"></a><h4 id="Convolutional-neural-networks-for-chemical-disease-relation-extraction-are-improved-with-character-based-word-embeddings-2018"><a href="#Convolutional-neural-networks-for-chemical-disease-relation-extraction-are-improved-with-character-based-word-embeddings-2018" class="headerlink" title="Convolutional neural networks for chemical-disease relation extraction are improved with character-based word embeddings(2018)"></a>Convolutional neural networks for chemical-disease relation extraction are improved with character-based word embeddings(2018)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p> CNN+CNNchar 和 CNN+LSTMchar 的模型对比，证实了字符嵌入的有效性。其实就是在15年提出的PCNN基础上加了一层char embedding，这在NER里面已经很常见了。</p><img src="/2019/07/22/文献阅读0722/1.png"><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>在BC5CDR上取得了SOTA的结果。</p><img src="/2019/07/22/文献阅读0722/2.png"><h4 id="Biomedical-Event-Extraction-Using-Convolutional-Neural-Networks-and-Dependency-Parsing-2018"><a href="#Biomedical-Event-Extraction-Using-Convolutional-Neural-Networks-and-Dependency-Parsing-2018" class="headerlink" title="Biomedical Event Extraction Using Convolutional Neural Networks and Dependency Parsing(2018)"></a>Biomedical Event Extraction Using Convolutional Neural Networks and Dependency Parsing(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>在他们先前开发的用SVM做NRE的TEES系统上加入了一个抽取生物医学关系和事件的CNN子模块，利用了多种输入和依存解析嵌入。</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li><p>数据集和模型：</p><p>BioNLP，DDI and BioCreative corpora</p></li><li><p>抽取流程：</p><p>TEES基于事件或关系的图表示，其中命名实体和触发词是节点，关系是边。抽取过程包括：entity detection（识别候选实体或触发词）、edge detection（关系检测）、unmerging stage（判定是否为真实事件）、modifier detection(检测事件方式：否定或是对立)</p></li><li><p>模型：</p><p>输入的嵌入包括词嵌入、POS嵌入、距离嵌入、相对位置嵌入（当前token在识别关系词的前、后或中，是否是实体一部分）、实体特征嵌入（当前token是否是候选实体、触发词等，在关系检测中使用）、最短路径嵌入(指示token是否在两实体的最短依存路径中及扮演的关系，在关系抽取中使用)</p><img src="/2019/07/22/文献阅读0722/3.png"></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在snorkel上卡了壳，不会写LF。。。回过头读一些CNN/LSTM/Attention+SDP+远程监督的文章补充基础知识吧，这也是通用领域做关系抽取的思路。&lt;/p&gt;
&lt;p&gt;就按主体模型分几天记吧，这篇是CNN(之前写的BioRE文献阅读报告里面详述了模型演化过程，这里只是选了两篇运用到生物医学领域的)&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0719</title>
    <link href="http://yoursite.com/2019/07/19/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0719/"/>
    <id>http://yoursite.com/2019/07/19/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0719/</id>
    <published>2019-07-19T01:03:23.000Z</published>
    <updated>2020-08-28T06:33:21.739Z</updated>
    
    <content type="html"><![CDATA[<p>找到两篇直接面向文献中关系抽取的文献，对做工程很有启发性，不单单只是测试新模型提高数据集精度。</p><a id="more"></a><h4 id="An-Insight-Extraction-System-on-BioMedical-Literature-with-Deep-Neural-Networks-2017"><a href="#An-Insight-Extraction-System-on-BioMedical-Literature-with-Deep-Neural-Networks-2017" class="headerlink" title="An Insight Extraction System on BioMedical Literature with Deep Neural Networks(2017)"></a>An Insight Extraction System on BioMedical Literature with Deep Neural Networks(2017)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>按照知识表示的思路，提出了一个相似度测度方法来评价实体间的相关性然后排序预测Cause-Effect关系</p><img src="/2019/07/19/文献阅读0719/1.png"><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li>首先用生物医学词典（关键词匹配）和浅层语义解析器（实体边界预测）做NER</li><li>然后用上下文相似度模型和语义相似度模型来对实体A、B、上下文和关系R建模并排名。思路是先用BiLSTM和attention机制获得带有上下文信息表示的实体A和B，然后输入到relational similarity model中计算A B还有关系R的相似性测度，训练使得R与A B在低维空间中有相近的表示。</li></ol><h4 id="Deep-learning-of-mutation-gene-drug-relations-from-the-literature-2018"><a href="#Deep-learning-of-mutation-gene-drug-relations-from-the-literature-2018" class="headerlink" title="Deep learning of mutation-gene-drug relations from the literature(2018)"></a>Deep learning of mutation-gene-drug relations from the literature(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>利用PubMed预训练的词向量和Biomedical entity search tool (BEST)搜索引擎返回的结果，训练卷积神经网络抽取PubMed文献中的Mutation-Gene和Mutation-Drug关系。优点是将PubMed文献信息当作背景知识学习。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;找到两篇直接面向文献中关系抽取的文献，对做工程很有启发性，不单单只是测试新模型提高数据集精度。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0717</title>
    <link href="http://yoursite.com/2019/07/17/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0717/"/>
    <id>http://yoursite.com/2019/07/17/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0717/</id>
    <published>2019-07-17T02:10:43.000Z</published>
    <updated>2019-09-02T08:50:56.250Z</updated>
    
    <content type="html"><![CDATA[<p>新文章固然好，但模型复杂且不稳定，难以用于大规模PubMed关系的抽取。deepdive及后续的snorkel是个好工具，看到好多大厂也都在用，老师一直强调我们是做工程的，尽量要快要能用，所以还是回到snorkel吧。</p><a id="more"></a><h4 id="Semi-supervised-Ensemble-Learning-with-Weak-Supervision-for-Biomedical-Relation-Extraction-2019"><a href="#Semi-supervised-Ensemble-Learning-with-Weak-Supervision-for-Biomedical-Relation-Extraction-2019" class="headerlink" title="Semi-supervised Ensemble Learning with Weak Supervision for Biomedical Relation Extraction(2019)"></a>Semi-supervised Ensemble Learning with Weak Supervision for Biomedical Relation Extraction(2019)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>用半监督集成学习模型来产生弱标签然后弱监督学习做关系抽取。<a href="https://github.com/littlewine/snorkel-ml/" target="_blank" rel="noopener">项目地址</a></p><h5 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h5><ol><li><p>目标是抽取生物医学摘要中的regulation(CPR)和induce(CID)语义关系对</p><img src="/2019/07/17/文献阅读0717/2.png"></li><li><p>为避免复杂的feature engineering使用ANN，但容易过拟合，所以用集成学习提高泛化能力</p></li><li><p>半监督集成学习：将半监督和集成学习结合在一起是个新颖的思路，集成学习可以加强半监督学习的表现，无监督标签可以增加learners的多样性，反过来降噪，这是种co-training的方式</p></li><li><p>思路是(1)用小型带标签数据集训练base learners，来预测更多的unlabeled data为weak labels；(2)加denoiser，然后在此基础上用弱监督学习训练更强大的meta-learner(noise-aware discriminative model)</p></li></ol><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li>数据收集：假设已有大小为m的金标准数据集DB（拆分成train dev test）但是远不够训练模型得到很好的效果，我们获取一个大小为M(&gt;&gt;m)的无标签数据集DU</li><li>建立K个基础学习器：通过改变features、文本特征表示和机器学习模型等来构建多个base learner，尽量不要使用相似的分类器(这是通过K*K的相似度矩阵来聚类计算的)</li><li>预测DU，得到K*M的预测标签（这里用到snorkel来推断候选实体对关系），然后用denoiser将投票矩阵变为M个标签</li><li>训练一个双向LSTM的meta-learner</li></ol><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>展示了用机器学习模型集成学习产生弱标签对关系抽取的影响，还有参数的选择，降噪方法的选择，meta-learner的表现，如图：</p><img src="/2019/07/17/文献阅读0717/2.png" title="base-learner的精度，集成学习产生弱标签的精度，以及meta-learner的精度"><p>结果展示这种弱监督方式几乎可以达到全部有监督的精度，所以可以用本文提出的模型做数据扩增Unlabeled dataset expansion，而且迁移领域只需要标注少量的金标准数据集即可。鉴于F1 score通常不具有说服力，本文也提出了对marginal weak labels更好的评估方法。</p><p>(文章的思路很巧妙，效果也不错。看到开源的项目是用jupyter notebook写的，准备用几天时间好好学习一下)</p><h4 id="A-global-network-of-biomedical-relationships-derived-from-text-2018"><a href="#A-global-network-of-biomedical-relationships-derived-from-text-2018" class="headerlink" title="A global network of biomedical relationships derived from text(2018)"></a>A global network of biomedical relationships derived from text(2018)</h4><p>Zenodo: Proposed a labeled, weighted network of structured biomedical relationships for all Medline abstracts using NCBI’s PubTator, the Stanford dependency parser and ensemble biclustering algorithm (EBC) .</p><p>抽取到的PubMed级别的chemical-disease-gene三者间的关系：<a href="https://zenodo.org/record/3346007" target="_blank" rel="noopener">https://zenodo.org/record/3346007</a></p><h4 id="Reusing-label-functions-to-extract-multiple-types-of-relationships-from-biomedical-abstracts-at-scale-2019"><a href="#Reusing-label-functions-to-extract-multiple-types-of-relationships-from-biomedical-abstracts-at-scale-2019" class="headerlink" title="Reusing label functions to extract multiple types of relationships from biomedical abstracts at scale(2019)"></a>Reusing label functions to extract multiple types of relationships from biomedical abstracts at scale(2019)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>通过制定snorkel LF大规模抽取PubMed生物医学关系。<a href="https://github.com/greenelab/snorkeling" target="_blank" rel="noopener">项目地址</a></p><p>准备借鉴这个做之后的项目。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;新文章固然好，但模型复杂且不稳定，难以用于大规模PubMed关系的抽取。deepdive及后续的snorkel是个好工具，看到好多大厂也都在用，老师一直强调我们是做工程的，尽量要快要能用，所以还是回到snorkel吧。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0716</title>
    <link href="http://yoursite.com/2019/07/16/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0716/"/>
    <id>http://yoursite.com/2019/07/16/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0716/</id>
    <published>2019-07-16T02:43:02.000Z</published>
    <updated>2019-07-29T13:24:23.320Z</updated>
    
    <content type="html"><![CDATA[<p>继续BioRE，看几篇最新的。</p><a id="more"></a><h4 id="BO-LSTM-classifying-relations-via-long-short-term-memory-networks-along-biomedical-ontologies-2019"><a href="#BO-LSTM-classifying-relations-via-long-short-term-memory-networks-along-biomedical-ontologies-2019" class="headerlink" title="BO-LSTM: classifying relations via long short-term memory networks along biomedical ontologies(2019)"></a>BO-LSTM: classifying relations via long short-term memory networks along biomedical ontologies(2019)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>利用领域本体匹配和溯源来提高DDI关系分类精度。<a href="https://github.com/lasigeBioTM/BOLSTM" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/16/文献阅读0716/1.png" title="BO-LSTM Model architecture"><p>模型如图，假设已经标注好实体，任务是识别候选实体对的关系，我们先用spaCy得到最短依存路径SDP，对SDP中的每个词得到它们的词嵌入；wordnet上义词（也就是描述的类别）；还有与本体中的概念匹配（用距离相似度）和找概念原型，按照从通用概念—&gt;单词自身的实体链来表示；找到候选实体的概念链中公共的概念。将这些都作为嵌入的组件通过LSTM网络，来测试外部本体对 SemEval 2013 Task 9 DDI识别精度的影响。</p><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>如图分别在关系检测和关系分类上的结果，关系检测忽略关系类型，关系分类则更难些要求识别出positive和它们的类型(advise, effect, mechanism, int)</p><img src="/2019/07/16/文献阅读0716/3.png"><img src="/2019/07/16/文献阅读0716/2.png"><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>这个框架思路(就是用领域本体匹配实体作为embedding来学习能提高识别精度)具有可扩展性，比如提取基因-表型关系时，可以利用Gene Ontology，只要有标注好的数据集即可拿来训练然后预测。</p><p>初期准备用这个项目实战，但是GitHub有些问题，正在提交issues和作者交流中…</p><h4 id="REflex-Flexible-Framework-for-Relation-Extraction-in-Multiple-Domains-2019"><a href="#REflex-Flexible-Framework-for-Relation-Extraction-in-Multiple-Domains-2019" class="headerlink" title="REflex: Flexible Framework for Relation Extraction in Multiple Domains(2019)"></a>REflex: Flexible Framework for Relation Extraction in Multiple Domains(2019)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>针对生物医学领域关系抽取文献多而杂且都不开源不具有普遍性的特点，提出了一个关系抽取的通用框架！！研究了预处理、模型训练、参数调节、结果评估这些步骤的影响，主要在三个数据集上做了测试：Semeval 2010，DDI Extraction，i2b2/VA 2010 relations。这篇文章条理清晰，代码开源，泛化性强，是难得的好文章。<a href="https://github.com/geetickachauhan/relation-extraction" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/16/文献阅读0716/5.png" title="workflow"><ol><li>预处理：分句分词，大写转小写，去除停用词，数字统一化，NER blinding(就是把句子中的实体按照关系识别的要求规范化，比如for semeval were <em>ENTITY</em>, for ddi were <em>DRUG</em> and for i2b2 were <em>PROBLEM</em>, <em>TREATMENT</em> and <em>TEST</em>)，用spacy和ScispaCy标记这些特定类型</li><li>建模：选用的基本模型是带位置嵌入和ranking loss的卷积神经网络CRCNN，测试了piecewise max-pooling，ELMo还有BERT等的影响。其中ELMo可以用token级别的embedding，BERT可选两种：token级别的和句子CLS级别的。</li><li>训练：两种调参方式，手动调参和随机搜索</li><li>评估：分类和检测两个任务</li></ol><h5 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h5><img src="/2019/07/16/文献阅读0716/4.png"><ol><li>好的预处理比模型更重要</li><li>由于split bias单独报告一个测试集的精度会有问题，最好选用具有显著性的交叉验证</li><li>Contextualized embeddings很有用，所以featurizing embedding(ELMo，BERT等)很重要，在通过卷积层前把它们和词嵌入连接起来很有效</li><li>调参很关键，手动和随机搜索差不多但随机搜索需要设置经验范围</li><li>为新数据集依照正负样本的imbalance选择相应的评估准则</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;继续BioRE，看几篇最新的。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0715</title>
    <link href="http://yoursite.com/2019/07/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0715/"/>
    <id>http://yoursite.com/2019/07/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0715/</id>
    <published>2019-07-15T02:20:50.000Z</published>
    <updated>2019-09-02T08:46:51.140Z</updated>
    
    <content type="html"><![CDATA[<p>本着思路优先、生物医学领域优先和开源代码优先的原则，这周准备写一些关系抽取的文献。因为关系抽取的文献多又杂，方法五花八门，不像NER模型简单应用起来也方便，所以看起来比较吃力。废话不多说了正文如下：</p><a id="more"></a><h4 id="Relation-Extraction-from-Biomedical-Literature-with-Minimal-Supervision-and-Grouping-Strategy-2014"><a href="#Relation-Extraction-from-Biomedical-Literature-with-Minimal-Supervision-and-Grouping-Strategy-2014" class="headerlink" title="Relation Extraction from Biomedical Literature with Minimal Supervision and Grouping Strategy(2014)"></a>Relation Extraction from Biomedical Literature with Minimal Supervision and Grouping Strategy(2014)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>文章提出了一个新颖的远程监督模型，不需要手动标注数据，运用了外部知识库UMLS和分组策略，基于统计模型而非启发式规则，抽取文献中的基因和脑区间的基因表达关系。</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li><p>实体标注：标注基因（BioTagger）和脑区实体(NIF和脑区词典)</p></li><li><p>分组策略：远程监督通常假设抽取到的实体对是独立的，但是在生物医学领域很容易出现平行的实体对，所以文章采用Stanford parser解析句子获取出现在相似位置的名词和名词短语（通常是and相连的），并把连续的实体组成一组然后表示它们与其他实体的关系。</p><img src="/2019/07/15/文献阅读0715/1.png" title="以and相连的名词和名词短语"></li><li><p>特征提取：词法特征（两实体的词袋，和实体间单词的词袋特征）和句法特征（最短依存路径）。</p></li><li><p>远程监督关系抽取(模型训练)：远程监督假设文本中至少出现一个实体对表现出知识库中相应实体对的关系，这里利用了生物医学领域的知识库UMLS，然后将关系对用无向图建模。</p><img src="/2019/07/15/文献阅读0715/2.png"><p>建立条件概率公式如下，z(i)表示从每个句子x(i)抽取得到的关系，然后用y表示建立关系到知识库的映射：</p><img src="/2019/07/15/文献阅读0715/3.png"><p>我理解的公式的意思是：(3)是只要有句子表现出知识库中的r(e1,e2)关系就Φcorpus设定为1，然后(2)是一个对数线性模型来衡量实体对的关系类型（是基因表达关系还是其他关系），(1)然后把基因表达关系映射到知识库中的基因表达关系上，训练公式(2)中的θ参数使结果概率最大化。</p><p>(The model first predicts the relation types for the entity pair corresponding to each of its evidences.<br>Then, the predictions of relation types at sentential-level are aggregated to approximate the relation types for the entity pair at corpus-level. As long as one of the sentences is classified into the <em>geneExpression</em> category, the <em>geneExpression</em> relation is returned at corpus-level; otherwise, only <em>otherRelation</em> is returned.)</p></li></ol><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>找了10000篇全文，抽取大约得到30,000个有基因-脑区关系的句子，用分组得到包含大约7700个实体对，然后金标准标选了259个句子(114个基因表达，143个其他关系)用作模型测试，最后得到的精度大致和有监督的SVM相当。</p><h4 id="Large-scale-extraction-of-gene-interactions-from-full-text-literature-using-DeepDive-2016"><a href="#Large-scale-extraction-of-gene-interactions-from-full-text-literature-using-DeepDive-2016" class="headerlink" title="Large-scale extraction of gene interactions from full-text literature using DeepDive(2016)"></a>Large-scale extraction of gene interactions from full-text literature using DeepDive(2016)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>用deepdive远程监督抽取100000篇plos全文的基因间的关系(包括PPI和转录因子间的关系)。<a href="https://github.com/edoughty/deepdive_genegene_app" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/15/文献阅读0715/4.png" title="预处理、构建候选实体对、deepdive推理计算概率、专家微调"><ol><li>文献预处理：使用Stanford CoreNLP分句、分词、POS、NER、DP</li><li>提取候选实体对：基于共现关系提取出现在HGNC的候选基因对，并提取特征(词窗特征、依存特征等)</li><li>远程监督：运用外部数据库为候选基因对设labels为True，False or Unknown。为防止过拟合，设定一些高频的已知为True的基因对为Unknown，再随机设置一些unknown为负例</li><li>用deepdive推理：将带is_correct label的候选基因对输入，50％的标签不动作为权重特征学习和校准，其他的用factor graph推测概率(deepdive的原理待补充)</li><li>系统微调：每次迭代做错误分析和预测，用滚雪球策略增加正例(如果候选对被预测为真，加入到training中)</li><li>两种评估：金标准PPI数据集测F值，以及随机挑选的正负基因对curation</li></ol><h4 id="Distant-Supervision-for-Large-Scale-Extraction-of-Gene–Disease-Associations-from-Literature-Using-DeepDive-2018"><a href="#Distant-Supervision-for-Large-Scale-Extraction-of-Gene–Disease-Associations-from-Literature-Using-DeepDive-2018" class="headerlink" title="Distant Supervision for Large-Scale Extraction of Gene–Disease Associations from Literature Using DeepDive(2018)"></a>Distant Supervision for Large-Scale Extraction of Gene–Disease Associations from Literature Using DeepDive(2018)</h4><p>用deepdive抽取了879585篇PubMed摘要中的75595个独特基因-疾病关系，没什么新意，思路和上一篇文章基本一样，放下结果吧。</p><img src="/2019/07/15/文献阅读0715/5.png">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本着思路优先、生物医学领域优先和开源代码优先的原则，这周准备写一些关系抽取的文献。因为关系抽取的文献多又杂，方法五花八门，不像NER模型简单应用起来也方便，所以看起来比较吃力。废话不多说了正文如下：&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0712</title>
    <link href="http://yoursite.com/2019/07/12/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0712/"/>
    <id>http://yoursite.com/2019/07/12/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0712/</id>
    <published>2019-07-12T02:41:59.000Z</published>
    <updated>2019-09-01T08:06:35.150Z</updated>
    
    <content type="html"><![CDATA[<p>阅读文献要紧跟前沿，不能闭门造车。生物医学nlp领域也随着ELMo, bert等Contextualized embedding的出现推陈出新，涌现了最前沿的几篇词向量、语言模型和预训练方法等的文章，这里按时间顺序做个记录慢慢补充。</p><a id="more"></a><h4 id="BioBERT-a-pre-trained-biomedical-language-representation-model-for-biomedical-text-mining-2019"><a href="#BioBERT-a-pre-trained-biomedical-language-representation-model-for-biomedical-text-mining-2019" class="headerlink" title="BioBERT: a pre-trained biomedical language representation model for biomedical text mining(2019)"></a>BioBERT: a pre-trained biomedical language representation model for biomedical text mining(2019)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>BioBERT全称生物医学双向Transformer编码器，也算是一种用迁移学习（双向语言模型）来解决数据缺失的方法。</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/12/文献阅读0712/1.png" title="训练和微调"><p>用PubMed和PMC预训练BERT的方法就不说了，在微调的时候，常采用WordPiece tokenization的方式，将新词用频繁的子词表示然后通过BioBERT。对NER，直接在biobert的输出加一层网络计算BIO/BIOES标签概率，也不需要CRF；对NRE，可以视为句子分类任务，也是在使用[CLS]表示的bert输出后加一层网络，其中对实体的处理eg: @GENE$</p><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><ol><li>ner：BERT &lt; BioBERT (+PubMed) &lt; BioBERT (+ PMC) &lt; SOTA models &lt; BioBERT (+PubMed + PMC).</li><li>nre：通常是SOTA models &lt;BERT &lt; BioBERT. 一般来说数据集越小提升效果越明显</li></ol><p>这是它的后续文章，用BERT配合Pubtator做NER，标注了所有的PubMed数据集</p><h4 id="A-Neural-Named-Entity-Recognition-and-Multi-Type-Normalization-Tool-for-Biomedical-Text-Mining-2019"><a href="#A-Neural-Named-Entity-Recognition-and-Multi-Type-Normalization-Tool-for-Biomedical-Text-Mining-2019" class="headerlink" title="A Neural Named Entity Recognition and Multi-Type Normalization Tool for Biomedical Text Mining(2019)"></a>A Neural Named Entity Recognition and Multi-Type Normalization Tool for Biomedical Text Mining(2019)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>传统的ner工具很难应对新实体，也不考虑被标注成多个类型的重叠实体，bern基于biobert标注然后运用决策规则和实体规范化技术解决这些问题。</p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/12/文献阅读0712/2.png"><p>先用tmTool和tmVar2.0处理输入的PMID或原文识别mutation，然后用biobert识别其他几种实体，对重叠实体，对重叠实体按照概率决策，对多个类型的实体规范化处理并分配统一id，输出标注后的文档(json或pubtator)。</p><ol><li><p>决策机制：下图左图是重叠实体的比例，右图是决策方式</p><img src="/2019/07/12/文献阅读0712/3.png"></li><li><p>实体规范化技术：</p><img src="/2019/07/12/文献阅读0712/4.png"><p>比如可以用bern快速发现HGNC IDs for genes, 和MeSH IDs for diseases</p></li></ol><h5 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h5><p><a href="https://bern.korea.ac.kr" target="_blank" rel="noopener">网址</a> <a href="https://bern.korea.ac.kr/pubmed/&lt;one or more PMIDs&gt;[/&lt;pubtator or json&gt;]" target="_blank" rel="noopener">API</a></p><h4 id="SCIBERT-Pretrained-Contextualized-Embeddings-for-Scientific-Text-2019"><a href="#SCIBERT-Pretrained-Contextualized-Embeddings-for-Scientific-Text-2019" class="headerlink" title="SCIBERT: Pretrained Contextualized Embeddings for Scientific Text(2019)"></a>SCIBERT: Pretrained Contextualized Embeddings for Scientific Text(2019)</h4><h5 id="一句话总结-2"><a href="#一句话总结-2" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>类似于BioBERT，建立方法是用Semantic Scholar的1.14M原文在BERT预训练，然后在多个领域的多种类型的任务数据集上做了精度测试</p><h5 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h5><ol><li><p>基于领域特定的文献语料库建立了新的WordPiece词汇库：SCIVOCAB，和原来BERT的BASEVOCAB作对比</p></li><li><p>加下游任务的方式是：</p><p>We apply a multilayer BiLSTM to token embeddings. For <strong>text classification</strong>, we apply a multilayer perceptron on the first and last BiLSTM states. For <strong>sequence tagging</strong>, we use a CRF on top of the BiLSTM, as done in (Ma and Hovy, 2016). For <strong>dependency parsing</strong> we use the biaffine attention model from Dozat and Manning (2017).  然后直接用预训练好的权重不加fine-tuning来预测精度</p></li></ol><h5 id="结果-2"><a href="#结果-2" class="headerlink" title="结果"></a>结果</h5><p>我们只关心生物医学类的</p><img src="/2019/07/12/文献阅读0712/5.png"><h4 id="Improving-Chemical-Named-Entity-Recognition-in-Patents-with-Contextualized-Word-Embeddings-2019"><a href="#Improving-Chemical-Named-Entity-Recognition-in-Patents-with-Contextualized-Word-Embeddings-2019" class="headerlink" title="Improving Chemical Named Entity Recognition in Patents with Contextualized Word Embeddings(2019)"></a>Improving Chemical Named Entity Recognition in Patents with Contextualized Word Embeddings(2019)</h4><p>将ELMo(利用语言模型获得的一个上下文相关的预训练表示)直接当做特征拼接到具体任务模型的词向量输入（不同于GPT和BERT这种微调的方法），识别化学专利中的实体。识别模型如图：</p><img src="/2019/07/12/文献阅读0712/6.png"><p>文章还证实了使用专门的化学专利词嵌入比PubMed-PMC-word2vec效果要好(废话)。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;阅读文献要紧跟前沿，不能闭门造车。生物医学nlp领域也随着ELMo, bert等Contextualized embedding的出现推陈出新，涌现了最前沿的几篇词向量、语言模型和预训练方法等的文章，这里按时间顺序做个记录慢慢补充。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0710</title>
    <link href="http://yoursite.com/2019/07/10/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0710/"/>
    <id>http://yoursite.com/2019/07/10/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0710/</id>
    <published>2019-07-10T01:15:45.000Z</published>
    <updated>2019-09-01T09:46:05.650Z</updated>
    
    <content type="html"><![CDATA[<p>之前一直没写到过用规则和领域字典做NER，还有NER后的normalization，这次补充一下。</p><a id="more"></a><h4 id="Learning-Named-Entity-Tagger-using-Domain-Specific-Dictionary-2018"><a href="#Learning-Named-Entity-Tagger-using-Domain-Specific-Dictionary-2018" class="headerlink" title="Learning Named Entity Tagger using Domain-Specific Dictionary(2018)"></a>Learning Named Entity Tagger using Domain-Specific Dictionary(2018)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>没有直接用dictionary作为features而是采用类似于RE中远程监督的方式产生大量数据集然后训练。去噪的方式有两种：一是在将原来的LSTM+CRF替换成revised fuzzy CRF处理多个可能标签的情况（其中标签是用词典匹配的），二是提出一个具有Tie or Break模式的新模型AutoNER预测产生输出</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li>Fuzzy-LSTM-CRF with Modified IOBES</li></ol><img src="/2019/07/10/文献阅读0710/1.png"><ol><li>AutoNER with “Tie or Break”：区别于BIOES，这里只关心相邻两个tokens之间的关系是连在一起还是分开的</li></ol><img src="/2019/07/10/文献阅读0710/2.png"><p>这样匹配的好处是可以更多的利用字符串匹配得到的信息：当一个entity被部分匹配的时候，其中部分正确的Tie信息得以被利用；当一个unigram entity被错误匹配的时候，Tie or Break部分并不会出错。而unigram entity正是字符串匹配中最容易匹配错误的部分。</p><h4 id="Recognizing-irregular-entities-in-biomedical-text-via-deep-neural-networks-2018"><a href="#Recognizing-irregular-entities-in-biomedical-text-via-deep-neural-networks-2018" class="headerlink" title="Recognizing irregular entities in biomedical text via deep neural networks(2018)"></a>Recognizing irregular entities in biomedical text via deep neural networks(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>提出一个NerOne模型，识别文献中带有不规则实体部分的规则实体（见下图）。在原来双向LSTM+CRF的基础上，通过计算最短依存路径确定是否应该加入一个分类子模块（另一个双向LSTM+CRF）来对不规则实体分类。</p><img src="/2019/07/10/文献阅读0710/3.png"><h4 id="A-Neural-Multi-Task-Learning-Framework-to-Jointly-Model-Medical-Named-Entity-Recognition-and-Normalization-2018"><a href="#A-Neural-Multi-Task-Learning-Framework-to-Jointly-Model-Medical-Named-Entity-Recognition-and-Normalization-2018" class="headerlink" title="A Neural Multi-Task Learning Framework to Jointly Model Medical Named Entity Recognition and Normalization(2018)"></a>A Neural Multi-Task Learning Framework to Jointly Model Medical Named Entity Recognition and Normalization(2018)</h4><h5 id="一句话总结-2"><a href="#一句话总结-2" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>提出一个新颖的多任务神经网络框架同时做NER和NEN，通过建立NER和NEN的反馈机制将逐级任务转为并行任务(也就是多任务共享权重)</p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><p>模型如图，base还是char CNN+BiLSTM+CRF，然后引入平行的NER和NEN任务作输出，然后互相反馈</p><img src="/2019/07/10/文献阅读0710/4.png"><p>反馈机制计算式如下：</p><img src="/2019/07/10/文献阅读0710/5.png"><h4 id><a href="#" class="headerlink" title=" "></a> </h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前一直没写到过用规则和领域字典做NER，还有NER后的normalization，这次补充一下。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0709</title>
    <link href="http://yoursite.com/2019/07/09/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0709/"/>
    <id>http://yoursite.com/2019/07/09/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0709/</id>
    <published>2019-07-09T10:12:41.000Z</published>
    <updated>2019-09-01T07:43:05.200Z</updated>
    
    <content type="html"><![CDATA[<p>今天读了几篇词向量和预训练模型的文献，简单记一下。</p><a id="more"></a><h4 id="How-to-Train-Good-Word-Embeddings-for-Biomedical-NLP-2016"><a href="#How-to-Train-Good-Word-Embeddings-for-Biomedical-NLP-2016" class="headerlink" title="How to Train Good Word Embeddings for Biomedical NLP(2016)"></a>How to Train Good Word Embeddings for Biomedical NLP(2016)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>这篇文章研究了用word2vec训练生物医学领域词向量时，训练数据集、模型结构和高阶参数对词向量质量的影响。评估方法用到了内部评估（单词相似测度）和外部评估（两个NER数据集）。</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li>数据集大小的影响：选用了三种：PubMed数据集，PMC数据集，PubMed+PMC数据集，发现更大的数据集不一定能训练出更好的词向量，效果最好的是PubMed</li><li>模型结构：对比了skip-gram（当前词预测上下文）和CBOW，发现skip-gram训练出来的要好一些</li><li>6个高阶参数：negative sampling（对当前词随机采样N个负例进行预测），Subsampling(去除频率高的词的共现)，min-count(最低出现的频数），学习率，词向量维度，上下文的词窗大小。</li><li>内部评估：UMNSRS单词相似度数据集，对出现的单词对，用模型计算余弦相似度然后再计算相关系数</li><li>外部评估：用训练好的词嵌入向量加简单的前馈神经网络做下游NER任务，不做fine-tuning</li></ol><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>具体参数的调整对结果的影响就不放上来了，最终选择的最佳参数和对应的精度如图。选这篇文章主要是之前看好多NER文献都在词向量部分提到这篇调参的启发，不过想不明白为什么还是每次都用词向量wikipedia-pubmed-and-PMC-w2v而不是这篇测试效果最好的wikipedia-PubMed，可能fine-tuning后效果提升更明显吧</p><img src="/2019/07/09/文献阅读0709/1.png" title="最佳参数和相应的精度"><h4 id="A-Comparison-of-Word-Embeddings-for-the-Biomedical-Natural-Language-Processing-2018"><a href="#A-Comparison-of-Word-Embeddings-for-the-Biomedical-Natural-Language-Processing-2018" class="headerlink" title="A Comparison of Word Embeddings for the Biomedical Natural Language Processing(2018)"></a>A Comparison of Word Embeddings for the Biomedical Natural Language Processing(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>评估了从四种数据源（电子医疗、PubMed、Wikipedia、Google news）训练的词向量在运用到内部评估和外部下游任务(临床信息提取，生物医学信息提取，关系抽取)时的表现，发现没有通用的提高生物医学下游nlp任务的词嵌入模型。</p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><ol><li>内部评估使用的相似性测度的方式是：选择三个类别（disorder, symptom, drug）的目标词汇，从四种词向量中取出5个最相关的词，结果显然是用电子医疗和PubMed训练的词向量要好过Wikipedia和Google news；还有选择377个语义相关的词对，用四种词向量表示，观察词簇的密集程度，用相似性测度衡量（UMNSRS）</li><li>外部评估分三部分<ul><li>Clinical Information Extraction：检测骨折信息数据集；i2b2吸烟状态数据集。结果是通用词向量效果不一定比相关领域训练的词向量差</li><li>Biomedical Information Retrieval：提供医疗决策信息。结果是四种词向量几乎都无精度提升</li><li>drug-drug interaction (DDI) extraction：Google News词向量效果最好(虽然都差不多但还是很神奇)</li></ul></li></ol><h4 id="Comparing-CNN-and-LSTM-character-level-embeddings-in-BiLSTM-CRF-models-for-chemical-and-disease-named-entity-recognition-2018"><a href="#Comparing-CNN-and-LSTM-character-level-embeddings-in-BiLSTM-CRF-models-for-chemical-and-disease-named-entity-recognition-2018" class="headerlink" title="Comparing CNN and LSTM character-level embeddings in BiLSTM-CRF models for chemical and disease named entity recognition(2018)"></a>Comparing CNN and LSTM character-level embeddings in BiLSTM-CRF models for chemical and disease named entity recognition(2018)</h4><h5 id="一句话总结-2"><a href="#一句话总结-2" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>比较了同样的BiLSTM+CRF模型用char-CNN和char-bilstm对CDNER的影响，发现无太大差别不过CNN可以显著降低模型复杂度明显提高计算效率。</p><p>接着介绍一下NCBI NIH的几个词向量工作。</p><h4 id="BioWordVec-improving-biomedical-word-embeddings-with-subword-information-and-MeSH-2018"><a href="#BioWordVec-improving-biomedical-word-embeddings-with-subword-information-and-MeSH-2018" class="headerlink" title="BioWordVec, improving biomedical word embeddings with subword information and MeSH(2018)"></a>BioWordVec, improving biomedical word embeddings with subword information and MeSH(2018)</h4><h5 id="一句话总结-3"><a href="#一句话总结-3" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>传统直接用领域相关的语料训练词向量如word2vec或者glove，即使glove是context相关的能解决一词多义问题，但也还是没有利用到文本内部的结构信息，本文用MeSH条款提供subword信息，能够有效增加OOV的词嵌入表示，极大提升词嵌入性能。</p><h5 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/09/文献阅读0709/2.png"><ol><li>采样MeSH条款序列：利用随机游走采样算法node2vec把用RDF构建的MeSH术语图转换成有序的术语序列，然后再把对应的id转成单词，这样链表就转成了具有语义关系的类似于句子的有向单词序列。</li><li>子词嵌入模型：在统一的字符嵌入空间中学习文本序列和MeSH术语序列，也就是同时用PubMed和MeSH训练n-grams。用了类似于CBOW模型的fastText算法，学习分布式的字符表示，然后每个单词的词向量是这些n-grams的组合和原Vc的点乘，训练方式也类似于word2vec，只不过是训练字符，优化损失函数也是两个skip-gram损失函数的叠加。</li></ol><h5 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h5><img src="/2019/07/09/文献阅读0709/3.png"><h5 id="应用案例"><a href="#应用案例" class="headerlink" title="应用案例"></a>应用案例</h5><ol><li>句子对间相似度计算：多采用将句子中的每个单词转换为词向量然后平均求相似度</li><li><strong>生物医学关系抽取</strong>：这是我关注的重点。文章在二元关系PPI和多元关系DDI上做了测试，采用带dropout的CNN模型，还有复杂的RNN模型测试，均取得了最高的F-score。但在RNN上精度提升不明显，可能是SOTA的RNN模型是集成了最短路径依赖信息和POS嵌入的多层双向LSTM，降低了词嵌入层的重要性。</li></ol><img src="/2019/07/09/文献阅读0709/4.png" title="DDI 2013提取结果对比"><h4 id="BioSentVec-creating-sentence-embeddings-for-biomedical-texts-2018"><a href="#BioSentVec-creating-sentence-embeddings-for-biomedical-texts-2018" class="headerlink" title="BioSentVec: creating sentence embeddings for biomedical texts(2018)"></a>BioSentVec: creating sentence embeddings for biomedical texts(2018)</h4><h5 id="一句话总结-4"><a href="#一句话总结-4" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>使用PubMed和MIMIC-III临床数据库类似于CBOW模型训练sent2vec，能在给定任意句子作为输入的情况下生成句子向量，能在高维空间中更好表征语义信息。在句子相似性和多标签句子分类数据集上做了测试。</p><img src="/2019/07/09/文献阅读0709/5.png" title="在句子分类数据集上采用的模型和精度"><h4 id="Transfer-Learning-in-Biomedical-Natural-Language-Processing-An-Evaluation-of-BERT-and-ELMo-on-Ten-Benchmarking-Datasets-2019"><a href="#Transfer-Learning-in-Biomedical-Natural-Language-Processing-An-Evaluation-of-BERT-and-ELMo-on-Ten-Benchmarking-Datasets-2019" class="headerlink" title="Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets(2019)"></a>Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets(2019)</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天读了几篇词向量和预训练模型的文献，简单记一下。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0708</title>
    <link href="http://yoursite.com/2019/07/08/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0708/"/>
    <id>http://yoursite.com/2019/07/08/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0708/</id>
    <published>2019-07-08T02:36:16.000Z</published>
    <updated>2019-09-02T08:46:22.420Z</updated>
    
    <content type="html"><![CDATA[<p>上篇主要是用多任务学习做NER的文献，这次关注一下迁移学习。正文如下：</p> <a id="more"></a><h4 id="Transfer-learning-for-biomedical-named-entity-recognition-with-neural-networks-2018"><a href="#Transfer-learning-for-biomedical-named-entity-recognition-with-neural-networks-2018" class="headerlink" title="Transfer learning for biomedical named entity recognition with neural networks(2018)"></a>Transfer learning for biomedical named entity recognition with neural networks(2018)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>深度学习大量依赖金标准数据集GSCs，带噪声的银标准数据集SSCs能够用于迁移学习弥补金标准数据集较少的情况，目标数据集越小迁移带来的精度提高越明显，目标GSC数据集较大时反而可能会恶化精度。<a href="https://github.com/BaderLab/Transfer-Learning-BNER-Bioinformatics-2018/" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><p>迁移学习的原理就是在”source”数据集上学到的知识能够帮助提高”target”数据集的表现，提高泛化能力，减少训练次数，模型本身baseline用的是<a href="https://github.com/Franck-Dernoncourt/NeuroNER" target="_blank" rel="noopener">neuroner</a>，一个BiLSTM字符嵌入+BiLSTM词嵌入+CRF的网络，注意一点就是训练时要从银标准数据集中剔除那些出现在金标准数据集中的PubMed ID。</p><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>在23个金标准数据集上与baseline相比平均误差降低了11％</p><h4 id="Effective-Use-of-Bidirectional-Language-Modeling-for-Transfer-Learning-in-Biomedical-Named-Entity-Recognition-2018"><a href="#Effective-Use-of-Bidirectional-Language-Modeling-for-Transfer-Learning-in-Biomedical-Named-Entity-Recognition-2018" class="headerlink" title="Effective Use of Bidirectional Language Modeling for Transfer Learning in Biomedical Named Entity Recognition(2018)"></a>Effective Use of Bidirectional Language Modeling for Transfer Learning in Biomedical Named Entity Recognition(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>在无标签数据上运用双向语言模型来预训练初始化模型权重，对金标准数据NER做迁移学习来提高精度。</p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><p>基本模型也是char-textCNN+word-BiLSTM+CRF，对每套数据集，用training和validation训练双向语言模型，双向语言模型的训练方法是最小化前后语言模型的平均交叉熵CElm = −λ(log pf (w1:n) + log pb(wn:1))。然后在此权重参数基础上训练NER模型微调，得到decoder CRF的参数。</p><h5 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h5><img src="/2019/07/08/文献阅读0708/1.png" title="4个数据集上的效果提升"><p>效果比之前那个多任务学习的精度要好，而且只针对当前数据集训练，没有用到别的数据集信息。最后还绘制了learning curve曲线展示了无论target数据集有多大，都能带来精度的提升。</p><h4 id="Towards-reliable-named-entity-recognition-in-the-biomedical-domain-2019"><a href="#Towards-reliable-named-entity-recognition-in-the-biomedical-domain-2019" class="headerlink" title="Towards reliable named entity recognition in the biomedical domain(2019)"></a>Towards reliable named entity recognition in the biomedical domain(2019)</h4><h5 id="一句话总结-2"><a href="#一句话总结-2" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>一个很大的问题是在金标准数据集训练好的NER模型很难泛化到其他数据集上（主要还是训练数据太少了），更别说直接用到生物医学非结构化文本抽取了。这篇文章用了几个方法来improve regularization，包括Variational Dropout、多任务学习和迁移学习，然后综合这些模型的优点开源了一个Python工具包。<a href="https://github.com/BaderLab/saber" target="_blank" rel="noopener">工具地址</a>  <a href="https://github.com/BaderLab/Towards-reliable-BioNER" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h5><ol><li><p>Variational Dropout：文章说之前的模型用dropout主要是在字符嵌入层和词嵌入层的参数上，很少有用到LSTM层的？？？没有啊我之前看的都用在了LSTM层。但确实LSTM层的dropout不太一样，因为直接使用会损害RNNs对文本的长距离依赖性。而2016年提出的variational dropout能够解决这一问题。因为它不是在每个time step都随机丢弃一些单元，而是在跨多个time steps丢弃相同的单元(因为LSTM是按照时间序列展开的，最终dropout会作用在同一层的连续位置，如图显示相同颜色的线代表在整个序列使用相同的dropout mask。我理解的就是有的一整个输入句子整个都被dropout，有的整个句子都不dropout，这样可以保证连续性)</p><img src="/2019/07/08/文献阅读0708/2.png" title="Naive dropout v.s. variational dropout"></li><li><p>迁移学习：同最上面那篇，用的数据集也是CALBC-SSC-III</p></li><li><p>多任务学习：用的是共享权重的方法，target-specific CRF前的所有字符层和单词层的隐层单元都共享权重，然后每个数据集计算各自的损失并优化，当所有的数据集都训练一遍（顺序随机，总共需要二项式系数次）算一个epoch。为什么没用之前那篇多任务文章提到的优化总的损失函数我也不知道，可能分别计算效果好吧。</p></li></ol><h5 id="结果-2"><a href="#结果-2" class="headerlink" title="结果"></a>结果</h5><p>文章花大量篇幅展示了baseline+VD，baseline+TL，MTL模型与baseline相比在In-corpus (IC) performance和Out-of-corpus (OOC) performance的效果提升，并分析了这些方法对提高泛化能力的作用。最后总结了OOC相比IC平均会减少31.16%的精度，加上这些方法的作用能够平均挽回10％的精度。开源的模型对用在PubMed大规模文本抽取有效。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上篇主要是用多任务学习做NER的文献，这次关注一下迁移学习。正文如下：&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0706</title>
    <link href="http://yoursite.com/2019/07/06/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0706/"/>
    <id>http://yoursite.com/2019/07/06/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0706/</id>
    <published>2019-07-06T01:52:00.000Z</published>
    <updated>2019-09-02T08:46:07.860Z</updated>
    
    <content type="html"><![CDATA[<p>受<a href="https://github.com/BrambleXu/knowledge-graph-learning" target="_blank" rel="noopener">awesome-knowledge-graph</a>这个项目的启发，看到自己项目里也存了大概一百篇文献，所以决定在博客记录下每天看过的文献，其中一部分是之前看过的，不过模型没有上手很容易忘记，所以算是重看整理，主要是想督促自己多写点东西。</p><a id="more"></a><h4 id="A-neural-network-multi-task-learning-approach-to-biomedical-named-entity-recognition-2016"><a href="#A-neural-network-multi-task-learning-approach-to-biomedical-named-entity-recognition-2016" class="headerlink" title="A neural network multi-task learning approach to biomedical named entity recognition(2016)"></a>A neural network multi-task learning approach to biomedical named entity recognition(2016)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>生物医学领域命名实体识别的金标准数据集量少，数据集间具有高度相关性但标注的又是不同的内容(Anatomy, Chemical, Disease, Gene/Protein and Species, Cell Type)，一个自然的思路是能否利用多任务学习提高NER精度，文章以卷积神经网络为基础构建了单任务模型和两个多任务模型验证了这一点。<a href="https://github.com/cambridgeltl/MTL-Bioinformatics-2016" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li><p>预训练词嵌入向量：用的是<a href="http://bio.nlplab.org" target="_blank" rel="noopener">wikipedia-pubmed-and-PMC-w2v</a>，注意OOV的处理</p></li><li><p>数据集：整合了15个ner数据集（包括BIO和BIOES两种格式）和1个GENIA-PoS-Tagging数据集</p></li><li><p>Baseline model ：全连接前馈神经网络，隐层大小300，激活函数ReLU，输出用Softmax分类，单个输入长度大小为7，batch-size 50，SGD优化</p></li><li><p>三个CNN模型：</p><img src="/2019/07/06/文献阅读0706/2.png" title="从左到右：单任务模型、多输出多任务模型、从属多任务模型"><ul><li><p>Single task model：高度为3、4、5各100个卷积核对长度为7的词窗做卷积，卷积核宽度等于词嵌入维度，为了保留位置信息没有用最大池化，卷积层到全连接层激活函数也是relu，多分类交叉熵损失函数，mini-batch 200，Adam优化，学习率1e-4，全连接层dropout 0.75</p></li><li><p>Multi-output multi-task model：共享前面的词嵌入和卷积层，后面的全连接和softmax随任务类型不同</p></li><li><p>Dependent multi-task model：NER任务运用POS信息，前面的CNN层分开训练，然后拼接后面的全连接层用来预测ner输出</p></li></ul></li></ol><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>如图：多输出模型能够对原single模型产生较大影响(多数是效果改进，少数会效果变差)，dependent模型对single模型带来的精度提高不如多输出，但整体趋势都是稍微改进无恶化的(至少是无实质变化)，也证明了我们的预期——具有相关关系的数据集用于多任务模型中共享输入特征和权重，结果不一定会相互促进，而从属模型大多能利用辅助数据集的信息来提升精度虽然效果可能不明显。<br><img src="/2019/07/06/文献阅读0706/3.png" title="F-score比较"></p><p>这篇多任务模型/迁移学习可以改进的地方还有很多：比如单任务模型换成BiLSTM+CRF；多任务思路也可以变化：从共享权重变为协同训练；从迁移模型到迁移数据。。。这就引出接下来很多篇文章：</p><h4 id="Cross-type-Biomedical-Named-Entity-Recognition-with-Deep-Multi-Task-Learning-2018"><a href="#Cross-type-Biomedical-Named-Entity-Recognition-with-Deep-Multi-Task-Learning-2018" class="headerlink" title="Cross-type Biomedical Named Entity Recognition with Deep Multi-Task Learning(2018)"></a>Cross-type Biomedical Named Entity Recognition with Deep Multi-Task Learning(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>双向LSTM+CRF网络通过共享字符和单词级别的嵌入层参数来提高NER精度。<a href="https://github.com/yuzhimanhua/Multi-BioNER" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/06/文献阅读0706/7.png" title="三种共享参数层的方式"><p>创新点是提出了三种共享参数层权重的方式来优化总的损失函数</p><img src="/2019/07/06/文献阅读0706/8.png" title="The loss function L"><p>还使用了CTD的单词信息作补充，用在两个地方：一是充当dictionary feature提供N-gram信息（结果并没有带来精度提高），二是用于后处理匹配那些被预测为O-label的单词，从而降低FN值(被预测为负的正样本)，但最后结果反而变差了，因为大大提高了FP值（有些单词表面和词典一样但是意思不同）。</p><h5 id="训练参数设置"><a href="#训练参数设置" class="headerlink" title="训练参数设置"></a>训练参数设置</h5><p>词嵌入200维，字符嵌入30维，两个双向LSTM隐藏层都是200，初始学习率0.01，其他大部分参数都和Neural architectures for named entity recognition这篇文章一样</p><h5 id="可以考虑改进的地方"><a href="#可以考虑改进的地方" class="headerlink" title="可以考虑改进的地方"></a>可以考虑改进的地方</h5><p>没有经过normalization所以很难判断预测的实体边界；虽然是一起训练的但对每个数据集都会学习得到一个模型，然后预测原始文本的时候是这些模型分别预测生成各自的预测结果，很容易造成冲突。</p><h4 id="CollaboNet-collaboration-of-deep-neural-networks-for-biomedical-named-entity-recognition-2018"><a href="#CollaboNet-collaboration-of-deep-neural-networks-for-biomedical-named-entity-recognition-2018" class="headerlink" title="CollaboNet: collaboration of deep neural networks for biomedical named entity recognition(2018)"></a>CollaboNet: collaboration of deep neural networks for biomedical named entity recognition(2018)</h4><h5 id="一句话总结-2"><a href="#一句话总结-2" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>在不同数据集上训练好的模型轮流充当主任务模型，其他数据集作为辅助模型来训练，这样协同训练来整体降低多义词的误分类，降低FP值。<a href="https://github.com/wonjininfo/CollaboNet" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h5><ol><li><img src="/2019/07/06/文献阅读0706/9.png"><p>单任务模型结构如图，和前一篇文章不同的地方是在Character Level Word Embedding (CLWE)层用的是text-CNN而不是Bi-LSTM，用dclwe个卷积核捕获窗口为k的字符（经最大池化），得到dclwe维的字符嵌入向量，然后和词向量拼接在一起作为双向LSTM-CRF的输入。</p><p>整个过程的公式如下图左侧所示(因为推导的比较清晰所以都列出来了)：</p><img src="/2019/07/06/文献阅读0706/10.png"></li><li><p>多任务模型结构如上图右，训练方式为：P0 Phase先把各数据集上的单个模型都训练一遍，在Pn phase，训练target模型时，将target模型的数据集和前一phase其他模型在target数据集上训练的输出加权合并做输入，用来训练前一phase的target模型，得到当前时刻的target输出。</p></li></ol><h5 id="训练参数设置-1"><a href="#训练参数设置-1" class="headerlink" title="训练参数设置"></a>训练参数设置</h5><p>词嵌入200维，字符向量初始化30维，然后采用3、5、7的卷积核各200个，所以得到字符嵌入维度200*3，拼接后经过前后各300维的LSTM，mini-batch为10，dropout分别是(CLWE)0.5和(BiLSTM)0.3，初始学习率0.01</p><h5 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h5><img src="/2019/07/06/文献阅读0706/11.png"><p>在相关数据集上取得了比上一篇文章更高的F值</p><h4 id="An-attention-based-BiLSTM-CRF-approach-to-document-level-chemical-named-entity-recognition-2017"><a href="#An-attention-based-BiLSTM-CRF-approach-to-document-level-chemical-named-entity-recognition-2017" class="headerlink" title="An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition(2017)"></a>An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition(2017)</h4><h5 id="一句话总结-3"><a href="#一句话总结-3" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>传统神经网络NER是基于句子级别的标注，容易造成同一文档不同句子间标注不一致性的问题，通常需要在后处理时加规则强行统一。本文提出了一个基于注意力机制的双向LSTM+CRF网络，能够实现文档级别的标注，在BC4CHEMDNER和BC5CDR数据集上都取得了SOTA的结果。<a href="https://github.com/lingluodlut/Att-ChemdNER" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法-3"><a href="#方法-3" class="headerlink" title="方法"></a>方法</h5><ol><li><p>input features：word embedding and character embedding作为基本，POS, chunking and dictionary embedding作额外补充。word embedding是用查询”chemical”关键词得到的文献在word2vec基础上训练的（很具有启发性）；POS和chunking是用GENIA tagger获得的；dictionary embedding是用化学词典（Jochem，ChEBI和CTD）匹配实体得到的。</p></li><li><p>基础的BiLSTM-CRF模型和改进的Att-BiLSTM-CRF模型：</p><img src="/2019/07/06/文献阅读0706/4.png"><p>双向LSTM层能够捕获序列的当前输入时刻上下文相关的信息；然后经过一个注意力层，用global vector捕获LSTM的输出加权，attention层的权重计算用了四种：曼哈顿距离、欧几里得距离、余弦相似度和感知机tanh(Wa[Xt;Xj])，attention 层的输出是global vector和LSTM输出状态向量的拼接然后通过一个tanh激活函数得到的，即Zt = tanh(Wg[gt;ht])，Zt然后再经一个tanh输出即tanh(WeZt)；CRF层是在输出概率矩阵上增加了状态转移矩阵建立隐藏状态的依赖，最终CRF输出也是经softmax用分类交叉熵计算损失，然后维特比算法递推优化。</p></li></ol><h5 id="训练参数设置-2"><a href="#训练参数设置-2" class="headerlink" title="训练参数设置"></a>训练参数设置</h5><img src="/2019/07/06/文献阅读0706/5.png"><h5 id="结果-2"><a href="#结果-2" class="headerlink" title="结果"></a>结果</h5><img src="/2019/07/06/文献阅读0706/6.png"><p>加入了额外特征的模型在两个数据集上都达到了SOTA的效果，优于NCBI的taggerone</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;受&lt;a href=&quot;https://github.com/BrambleXu/knowledge-graph-learning&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;awesome-knowledge-graph&lt;/a&gt;这个项目的启发，看到自己项目里也存了大概一百篇文献，所以决定在博客记录下每天看过的文献，其中一部分是之前看过的，不过模型没有上手很容易忘记，所以算是重看整理，主要是想督促自己多写点东西。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>脑空间信息知识图谱技术</title>
    <link href="http://yoursite.com/2019/05/08/%E8%84%91%E7%A9%BA%E9%97%B4%E4%BF%A1%E6%81%AF%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/"/>
    <id>http://yoursite.com/2019/05/08/%E8%84%91%E7%A9%BA%E9%97%B4%E4%BF%A1%E6%81%AF%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/</id>
    <published>2019-05-08T06:53:15.000Z</published>
    <updated>2019-07-30T03:23:26.880Z</updated>
    
    <content type="html"><![CDATA[<p>因为马上去上海开会交流还要做PPT展示，所以先写篇文章总结下目前这个项目我能实现的技术和卡住的地方，也算是对入手这个项目一年多的技术总结。</p><p>脑空间信息学是以脑连接的基本结构与功能单元为研究对象，揭示脑连接空间信息机制，引导脑疾病防治与智能技术发展的新兴交叉学科。脑空间信息知识库能够为研究认知和行为的神经活动机制等脑科学问题提供帮助。由于脑科学的研究范围涵盖面广，领域跨度大，研究人员很难具有跨自身专业的知识；此外脑科学领域的文献数目逐年剧增，了解并跟进前沿知识费时费力，催生了自动化获取文献信息的需求。项目目标是综合运用文本挖掘、自然语言处理和机器学习技术，建立一个服务脑科学研究人员，整合已有的知识库，能实现文献语义级别搜索的知识图谱。</p><p>知识图谱的构建流程大致是知识抽取、知识融合、知识加工、知识存储和知识表示。我的工作主要是前面的知识抽取和知识融合中的技术细节，主要做了文献挖掘、实体抽取和消歧、关系/事件抽取、知识库和本体整合等内容。详细如下：</p> <a id="more"></a><ol><li><p>文献获取和预处理</p><ul><li>以E-utilities向PubMed发送查询并下载文献，以关键词核团”nucleus accumbens”为例，共下载19572篇摘要，以txt的格式返回它们的，标识符pmids</li><li>使用StanfordNLP进行文本清洗：包括分词、过滤字符、去除停用词、词干化处理、词性标注等</li><li>统计词频、语言模型、tf-idf等</li></ul><p>遇到的问题及难点：PMC全文的获取有困难，缺少文献数据库</p></li><li><p>知识抽取</p><img src="/2019/05/08/脑空间信息知识图谱技术/1.png"><p>知识抽取根据不同的数据源分别进行，我们主要针对的是文献中的纯文本数据。三个子任务包括：</p><ul><li>实体抽取：识别文本中有意义的实体，通常是名词</li><li>关系抽取：SPO三元组，事件抽取相当于多元关系的抽取</li><li>属性抽取：三元组中一个谓词和两个形参各自的属性，也可以简化为关系抽取</li></ul><p>实体抽取：</p><p>采用端到端的深度学习算法，基于多任务学习的双向LSTM+CRF网络，采用的训练数据集为CoNLL格式的金标准生物医学NER数据集，该系统能够识别基因、蛋白质、细胞类型、化学物质、疾病实体。</p><p>模型和训练数据集详细信息如图：</p><img src="/2019/05/08/脑空间信息知识图谱技术/2.png"><img src="/2019/05/08/脑空间信息知识图谱技术/3.png"><p>目前识别出的结果如下：</p><img src="/2019/05/08/脑空间信息知识图谱技术/6.png"><p>后期准备整合Pubtator和UMLS对识别出来的实体按照实体类型和MESH条款进行管控。</p><p>遇到的问题及难点：</p><ul><li>难以识别出脑区核团、神经元等一些金标准训练集中未标定出来的实体类型。</li><li>金标准训练集的数量太少，训练模型易欠拟合，泛化能力差，难以对大量的文献文本做实体预测，且难以对预测结果的精确度进行定量评估。</li></ul><p>关系抽取：</p><p>同样是基于端到端的方法，模型是加入自注意力机制的双向LSTM网络，主要抽取的是基因-化学物质-疾病这三者相互之间的关系。</p><p>模型和训练数据集详细信息如图：</p><img src="/2019/05/08/脑空间信息知识图谱技术/7.png"><img src="/2019/05/08/脑空间信息知识图谱技术/8.png"><p>目前的训练精度很差，准备加入句法依存树解决句法依赖的问题，还有配合生物医学本体建立层级间的关联，加入远程监督和多实例学习解决训练样本太少的问题。</p><p>遇到的问题及难点：</p><ul><li>关系抽取难度大，主流的最好的模型精度也只有60-70％</li><li>划定关系类型没有统一的标准，严重依赖本体层级的划分，需要神经科学背景的研究人员提供指导</li><li>关系抽取得到的结果中包含的主语和宾语实体需要与实体抽取的结果匹配，可以考虑采用联合模型同时抽取实体和它们间的关系。</li></ul></li><li><p>知识融合</p><p>主要做了SemMedDB关系数据库(NIH抽取PubMed摘要得到的9400多万个关系)与本体层面的融合。</p><p>采用的本体是biolink，是一个以节点、边、槽表示生物医学实体和关系的本体层架构。SemMedDB数据库以MySQL的形式存储，先将其通过UMLS进行规范化，然后用biolink在模式层管理这些关系。</p><p>遇到的问题及难点：</p><ul><li>原SemMedDB是采用SemRep系统抽取，它的精确度、召回率和F值分别为 0.73, 0.55, 0.63</li></ul></li></ol><ul><li>由于精确度较低，所以需要先过滤总共只出现很少次的关系类型，在次数的选择上也需要折中考虑关系的误判和漏判<ul><li>由于系统只能做到抽取单个句子中的实体间的关系，很难抽取到跨句子级别的关系，所以召回率很低，但是PubMed摘要中的很多关系只出现在整个文档级别中</li></ul></li><li>biolink并不一定是最适合我们的生物医学本体，需要内部专家修改和评估。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;因为马上去上海开会交流还要做PPT展示，所以先写篇文章总结下目前这个项目我能实现的技术和卡住的地方，也算是对入手这个项目一年多的技术总结。&lt;/p&gt;
&lt;p&gt;脑空间信息学是以脑连接的基本结构与功能单元为研究对象，揭示脑连接空间信息机制，引导脑疾病防治与智能技术发展的新兴交叉学科。脑空间信息知识库能够为研究认知和行为的神经活动机制等脑科学问题提供帮助。由于脑科学的研究范围涵盖面广，领域跨度大，研究人员很难具有跨自身专业的知识；此外脑科学领域的文献数目逐年剧增，了解并跟进前沿知识费时费力，催生了自动化获取文献信息的需求。项目目标是综合运用文本挖掘、自然语言处理和机器学习技术，建立一个服务脑科学研究人员，整合已有的知识库，能实现文献语义级别搜索的知识图谱。&lt;/p&gt;
&lt;p&gt;知识图谱的构建流程大致是知识抽取、知识融合、知识加工、知识存储和知识表示。我的工作主要是前面的知识抽取和知识融合中的技术细节，主要做了文献挖掘、实体抽取和消歧、关系/事件抽取、知识库和本体整合等内容。详细如下：&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
</feed>
