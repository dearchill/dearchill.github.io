<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>C&#39;est La Vie</title>
  
  <subtitle>Love or death</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-12-17T15:05:43.202Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>SonicYouth</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>snorkel抽取BC5CDR数据集关系</title>
    <link href="http://yoursite.com/2019/12/17/snorkel%E6%8A%BD%E5%8F%96BC5CDR%E6%95%B0%E6%8D%AE%E9%9B%86%E5%85%B3%E7%B3%BB/"/>
    <id>http://yoursite.com/2019/12/17/snorkel%E6%8A%BD%E5%8F%96BC5CDR%E6%95%B0%E6%8D%AE%E9%9B%86%E5%85%B3%E7%B3%BB/</id>
    <published>2019-12-17T14:58:13.000Z</published>
    <updated>2019-12-17T15:05:43.202Z</updated>
    
    <content type="html"><![CDATA[<p>本周的工作是继续用snorkel工具以弱监督的方法在BC5CDR数据集进行抽取和评估，这也是snorkel在生物医学领域关系抽取的官方tutorial示例。其中BC5CDR包含500篇摘要的CID关系(chemical-induced-diseases)，与我们制定的关系类型chemical-causes-disease一致。此外，阅读了一篇发表在AKBC 2019探讨了在半监督模型中加入集成学习对关系抽取影响的文章。</p><a id="more"></a><p>上篇博客用弱监督的方法在chemical-disease关系抽取上进行了尝试，证明了与有监督模型相比的有效性，本周基于BC5CDR数据集的新特性，对标签函数进行了修改和重写。还在此基础上加入集成学习提高精度。</p><p>原始数据为xml格式的PubMed摘要和标注信息：</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/1.png"><p>抽取方法同上篇，采用的snorkel弱监督学习框架，通过用户编写标签函数(LFs)，然后利用生成模型学习标签函数准确性，输出概率训练标签，来训练神经网络判别模型。其中标签函数的制定采用规则、正则匹配或是远程监督的方法（本周选用了一个），生成模型为对标签函数的概率投票，作为输入x的概率标签y，最后用一个判别模型（如神经网络）进行关系分类。  </p><p>首先进行数据预处理，snorkel内部预置了CorpusParser模块处理xml得到句子，然后用TaggerOne标注实体（这也是pubtator使用的工具），选出句子中的候选实体对。之后是编写标签函数生成概率标签：</p><p>这里采用了三种标签函数类型，有CTD知识库远程监督方法：</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/2.png"><p>正则表达式规则：</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/3.png"><p>上下文层级特征：</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/4.png"><p>然后将标签函数用于训练集的标签产生，在dev数据集判别效果，训练生成式模型：</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/5.png"><p>最后将生成模型产生的概率标签作为训练集x的标签，用LSTM网络进行模型训练，在测试集评估精度。</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/6.png"><p>最后测得的F-score为0.5286。</p><p>后来在AKBC 2019找到一篇用半监督集成学习做弱监督关系抽取的文章《Semi-supervised Ensemble Learning with Weak Supervision for Biomedical Relation Extraction》，文章为避免标签函数的制定过程中采用复杂的feature engineering造成过拟合，采用了集成学习的方法。</p><p>思路是(1)用小型带标签数据集训练base learners，来预测更多的unlabeled data为weak labels；(2)加denoiser，然后在此基础上用弱监督学习训练更强大的meta-learner(noise-aware discriminative model，这里选用的是双向LSTM)。文章的创新之处是选用K个基础学习器，通过改变features、文本特征表示和机器学习模型等来构建多个分类器，这样生成的概率标签相当于集多个模型的优点，更robust。</p><p>下图结果展示了用机器学习模型集成学习产生弱标签对关系抽取的影响，在参数的选择，降噪方法的选择，meta-learner选择上的不同表现。</p><img src="/2019/12/17/snorkel抽取BC5CDR数据集关系/7.png"><p>可以看出在弱监督学习中加入base learners确实相比我们自己定义的标签函数学习到的结果（0.5286）有F-score的提升（右侧三列），而却可以用本文提出的模型做数据扩增，迁移领域只需要标注少量的金标准数据集即可。此外，鉴于F1 score有时会不具有说服力，文章还因此提出了对marginal weak labels更好的评估方法。  </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本周的工作是继续用snorkel工具以弱监督的方法在BC5CDR数据集进行抽取和评估，这也是snorkel在生物医学领域关系抽取的官方tutorial示例。其中BC5CDR包含500篇摘要的CID关系(chemical-induced-diseases)，与我们制定的关系类型chemical-causes-disease一致。此外，阅读了一篇发表在AKBC 2019探讨了在半监督模型中加入集成学习对关系抽取影响的文章。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>snorkel初探</title>
    <link href="http://yoursite.com/2019/11/25/snorkel%E5%88%9D%E6%8E%A2/"/>
    <id>http://yoursite.com/2019/11/25/snorkel%E5%88%9D%E6%8E%A2/</id>
    <published>2019-11-25T01:35:32.000Z</published>
    <updated>2019-12-17T14:56:52.947Z</updated>
    
    <content type="html"><![CDATA[<p>远程监督是关系抽取中最常采用的方法，它的核心思想是将文本与大规模知识图谱进行实体对齐，利用知识图谱已有的实体间关系对文本进行标注，可以有效解决有监督学习抽取样本过少的问题。而snorkel是斯坦福大学deepdive框架的后续项目，它将deepdive中的远程监督和弱监督的思想进一步完善，并用纯python的形式构成了一套完整的学习框架。我们的关系抽取项目采用snorkel与深度学习相结合的方法。</p><a id="more"></a><p>人工标记训练数据费时费力，所以最好的方式是利用外部知识库、模式/规则或其他分类器来启发式地生成训练数据。从本质上来讲，这些都是以编程方式生成训练数据的方法，或者更简洁地说就是编程训练数据。</p><p>远程监督基本假设是：如果从知识图谱中可获取三元组R(E1, E2)（注：R代表关系，E1、E2代表两个实体），且E1和E2共现与句子S中，则S表达了E1和E2间的关系R，标注为训练正例。由于假设过强，会出现wrong label的问题，常采用多实例学习的方法解决，将所有包含该关系的句子组成一个bag然后筛选句子生成训练样本。后来提出multi-instance multi-labels，即一个句子只能表达E1和E2的一种关系，但是不同的句子可以表达多个关系即labels，为同时挖掘实体对的多个关系提供了可能。</p><p>snorkel采用的方法是用户编写标签函数(LFs)，然后利用生成模型学习标签函数准确性，输出概率训练标签，来训练神经网络判别模型，流程如下：</p><img src="/2019/11/25/snorkel初探/1.png"><img src="/2019/11/25/snorkel初探/2.png"><img src="/2019/11/25/snorkel初探/3.png"><p>By using the label model to transfer the domain knowledge encoded in our LFs to the discriminative model, we were able to generalize beyond the noisy labeling heuristics.</p><p>以下是周报的内容：</p><h5 id="工作内容："><a href="#工作内容：" class="headerlink" title="工作内容："></a>工作内容：</h5><p>(1)关系抽取是知识图谱构建中非常基础和重要的一环，可以说知识图谱内部保存的数据就是高精度的三元组关系。前期的工作已经完成了实体抽取和实体规范化，已经得到了关系抽取中的候选实体，下一步就是在每句话的候选实体对上运用关系抽取模型抽取得到关系。</p><p>(2)之前的工作包括调研关系抽取方法，制定关系标准，寻找可用的数据集。由于关系抽取的金标准数据集太少，大规模图谱构建一般采用有监督和弱监督相结合的方法，前者通过研究新模型提高识别精度，后者加入远程监督解决金标准数据集较少的问题。但在生物医学领域多数研究都是基于前者，极少有能够落地到对文献进行大规模关系抽取的方法（尤其是深度学习模型），因为训练数据集少导致模型过拟合不足以应对文献内的复杂变化的关系。通过加入后者弱监督学习，可以提高模型的泛化能力。本周工作即为弱监督模型在chemical-disease关系抽取的尝试，证明该方法在使用少量金标准数据集就能达到相当的精度。</p><p>(3)本次工作为用snorkel框架，对chemical和disease间的cause和treat关系进行抽取。数据集为通过众包构建的<a href="https://github.com/CrowdTruth/Medical-Relation-Extraction" target="_blank" rel="noopener">CrowdTruth数据集</a>: 包括3984个包含cause和treat关系的句子，部分经过人工标注。  </p><img src="/2019/11/25/snorkel初探/4.png"><p>首先准备数据，得到结果如上图，划分数据集为train-dev-val-test四部分。其中train不含金标准标签（因为要在训练时生成x的概率标签），dev为少量带专家标注的金标准数据，通过评估选择标签函数和得到生成模型，val充当验证集调整最后的判别式模型参数，最后在test上测试精度。</p><p>其中标签函数的编写是决定模型性能的关键，其实有点类似于基于规则的有监督学习中的特征工程，包括关键词类型的：</p><img src="/2019/11/25/snorkel初探/5.png"><p>正则表达式类型的：</p><img src="/2019/11/25/snorkel初探/6.png"><p>还可以加入启发式规则还有基于远程监督的，最后将规则用于训练集的标签产生，在dev数据集判别如下，然后通过coverage（recall）和correct（precision）的trade-off来选择标签输入生成模型：</p><img src="/2019/11/25/snorkel初探/7.png"><p>最后设计将生成模型产生的概率标签作为训练集x的标签，用LSTM网络进行模型训练，将训练好的模型在测试集评估精度，与从开始直接用金标准数据集训练的模型对比。  </p><img src="/2019/11/25/snorkel初探/8.png"><p>结果如下，可以看出基于不同标签函数的snorkel与使用众包标签和基线的精度对比精度下降在可接受的范围内。</p><img src="/2019/11/25/snorkel初探/9.png">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;远程监督是关系抽取中最常采用的方法，它的核心思想是将文本与大规模知识图谱进行实体对齐，利用知识图谱已有的实体间关系对文本进行标注，可以有效解决有监督学习抽取样本过少的问题。而snorkel是斯坦福大学deepdive框架的后续项目，它将deepdive中的远程监督和弱监督的思想进一步完善，并用纯python的形式构成了一套完整的学习框架。我们的关系抽取项目采用snorkel与深度学习相结合的方法。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>脑区连接关系提取</title>
    <link href="http://yoursite.com/2019/11/21/%E8%84%91%E5%8C%BA%E8%BF%9E%E6%8E%A5%E5%85%B3%E7%B3%BB%E6%8F%90%E5%8F%96/"/>
    <id>http://yoursite.com/2019/11/21/%E8%84%91%E5%8C%BA%E8%BF%9E%E6%8E%A5%E5%85%B3%E7%B3%BB%E6%8F%90%E5%8F%96/</id>
    <published>2019-11-21T09:06:55.000Z</published>
    <updated>2019-11-25T01:26:48.650Z</updated>
    
    <content type="html"><![CDATA[<p>大多数生物医学领域的关系提取都是面向通用的基因、化学物质、疾病间的，很少研究大脑神经投射和连接性的。调研找到的文献不多，这里汇总一下：</p><a id="more"></a><h4 id="Automated-recognition-of-brain-region-mentions-in-neuroscience-literature-2009"><a href="#Automated-recognition-of-brain-region-mentions-in-neuroscience-literature-2009" class="headerlink" title="Automated recognition of brain region mentions in neuroscience literature(2009)"></a>Automated recognition of brain region mentions in neuroscience literature(2009)</h4><p>课题意义是建立与脑区有关的基因表达和模拟连接，为此他们提出了whitetext项目，手工标注了1377篇神经科学文献摘要中的18242个脑区，然后采用几种方法识别并评估了识别精度：基于词典（被词典大小严重限制导致召回率低）和CRF；还分析了词窗大小、词干化处理和缩写扩展对识别精度的影响。</p><ol><li><p>语料库建立方法：依据关键词检索、随机挑选Journal of Comparative Neurology期刊文章、mesh匹配的方法选择了1377篇尽可能提及脑区的文章，以xml格式存储，然后使用缩写扩增算法将文中提及的全称或缩写统一用”全称(缩写)”的形式扩增。然后请人依照脑图谱和词典手工标注，标注范围不能太宽泛(不标注system级别的)，也不能太精细(不具体到核团的某一层)，标注示例： “motor related areas of the hippocampus”.</p></li><li><p>基于词典的匹配： 使用的词典：Neuronames，Nomenclatures of Canonical Mouse，Rat Brain Atlases and the Ontology of Human and Macaque Neuroanatomy.  匹配方法：GATE Gazetteer</p></li><li><p>条件随机场：相比HMM优点是当前状态的概率依据整个输入序列tokens计算而不仅仅是前一状态的token，通过定义feature function组合features</p></li><li><p>features的选择：拼写特征(如大写字母或者数字)和词性特征POS tagging；词干特征（用GENIA biomedical corpus训练的TreeTagger标注）；上下文特征：n-grams，word window；还有一些描述脑区边界的特征词：(e.g. bank, sulci, surface,area), neuroanatomical directions (e.g. dorsal, superior), root neuroscience terms (e.g. chiasm, raphe, striated). 识别结果如下：，</p><img src="/2019/11/21/脑区连接关系提取/1.png"></li></ol><h4 id="Application-and-evaluation-of-automated-methods-to-extract-neuroanatomical-connectivity-statements-from-free-text-2012"><a href="#Application-and-evaluation-of-automated-methods-to-extract-neuroanatomical-connectivity-statements-from-free-text-2012" class="headerlink" title="Application and evaluation of automated methods to extract neuroanatomical connectivity statements from free text(2012)"></a>Application and evaluation of automated methods to extract neuroanatomical connectivity statements from free text(2012)</h4><p>接上一篇，继续标注了1377篇the Journal of Comparative Neurology文献的神经模拟连接，只考虑连接关系，不考虑连接属性、强度和方向，然后用基于词语共现和规则的方法，基于POS、依存解析和句法特征的机器学习方法抽取关系做测试，证实了之前抽取PPI的几种核方法可以用于抽取脑连接关系，并建立了完整的脑区识别和关系识别流程。这是大规模文本挖掘在神经解剖学连接抽取的首次应用。</p><ol><li><p>金标准标注：先标注所有脑区，然后标注所有的脑区连接，不标注白质和神经冲动，仅标注突触或直接连接。</p></li><li><p>基于共现的方法：在单个句子内共现或整个摘要内共现；基于规则：限制脑区提及数目，限制连接关键词(‘afferent’, ‘efferent’, ‘projects’, ‘projection’, ‘pathway’ or ‘inputs’)</p></li><li><p>四种基于核函数的统计机器学习方法：句法和依存解析核，all-paths graph kernel，k-band shortest path spectrum kernel，使用单词共现和POS的浅层语义核 (SLK)，精度比较如图：</p><img src="/2019/11/21/脑区连接关系提取/2.png"></li><li><p>然后用slk做关系抽取，将抽取的连接关系与现存的脑模拟连接数据库如<a href="https://bams1.org" target="_blank" rel="noopener">BAMS</a>作比较（normalization)，抽取及规范化流程如下：</p><img src="/2019/11/21/脑区连接关系提取/3.png"><p>将提取到的关系映射到标准化的BAMS词典比较困难（63％），采用关系同义词匹配或是用共现代替关系的方法可以改善匹配率，但会降低准确率。</p></li></ol><h4 id="Text-mining-for-neuroanatomy-using-WhiteText-with-an-updated-corpus-and-a-new-web-application-2015"><a href="#Text-mining-for-neuroanatomy-using-WhiteText-with-an-updated-corpus-and-a-new-web-application-2015" class="headerlink" title="Text mining for neuroanatomy using WhiteText with an updated corpus and a new web application(2015)"></a>Text mining for neuroanatomy using WhiteText with an updated corpus and a new web application(2015)</h4><p>接上两篇，先总结了一下过去的结果：</p><img src="/2019/11/21/脑区连接关系提取/4.png"><ol><li>脑区识别：对标注的1377篇摘要进行脑区NER，采用条件随机场，八折交叉验证，recalled 76% of brain region mentions at 81% precision</li><li>脑区标准化/规范化：采用了5个跨物种的神经科学词典（NeuroNames, NIFSTD, the Brede Database, BAMS and AMBA)，它们提供了大约1000个脑区的11,909 个名称。尝试词典匹配（先精确匹配，然后忽略词序的词袋匹配，最后词干匹配），设计修改规则提高精度（P 95％ R 63％）</li><li>脑区连接：多数提及的脑区连接是负样本(no connectivity )，采用浅层语义核(slk)能达到P 50％ R 70％</li></ol><p>然后用半自动抽取+手工修正的方式创建了新数据集（加入了1828篇摘要和2111个连接关系），用MScanner 工具扩展标注其他期刊的8264篇JCN文献模拟连接信息。</p><img src="/2019/11/21/脑区连接关系提取/5.png"><p>最后还将结果展示在<a href="https://whitetext.msl.ubc.ca" target="_blank" rel="noopener">网页上</a>，提供查询和导出（Indexing 71306 sentences with 68957 connections between 88088 brain region mentions.），查询关键词是与NIFSTD中的名词匹配的。</p><p>不足之处：仅摘要、单个句子、关系无方向性</p><h4 id="Extracting-Relation-between-Brain-Region-pairs-from-White-Text-2017"><a href="#Extracting-Relation-between-Brain-Region-pairs-from-White-Text-2017" class="headerlink" title="Extracting Relation between Brain Region pairs from White Text(2017)"></a>Extracting Relation between Brain Region pairs from White Text(2017)</h4><p>创新之处是运用graph Kernel的方法抽取在同一个句子中出现不止两个脑区实体间的关系。</p><img src="/2019/11/21/脑区连接关系提取/6.png"><p>方法就是对whitetext语料，选择词的tf-idf作特征，加入基于图的浅层语义核SLK还有解析树核DTK得到特征向量，用SVM分类器输出每对实体的关系。其中baseline为只用tf-idf或BOW作特征，结果如下：</p><img src="/2019/11/21/脑区连接关系提取/7.png"><h4 id="Large-scale-extraction-of-brain-connectivity-from-the-neuroscientific-literature-2015"><a href="#Large-scale-extraction-of-brain-connectivity-from-the-neuroscientific-literature-2015" class="headerlink" title="Large-scale extraction of brain connectivity from the neuroscientific literature(2015)"></a>Large-scale extraction of brain connectivity from the neuroscientific literature(2015)</h4><h5 id="Introduction："><a href="#Introduction：" class="headerlink" title="Introduction："></a>Introduction：</h5><ol><li>神经科学的结果、知识和数据分散在期刊中，访问效率很低。脑连接性数据有这些来源：1. Allen Mouse Brain Connectivity Atlas(AMBCA)，2. BAMS（包含600多篇手工整理的文献数据）3. 神经科学文章，采用传统手工搜索的方法有一些局限：命名系统的多样性导致手动搜索的不确定性，还有召回率低（缺少缩写扩展和同义词扩展），精度低（共现关系不代表相关关系）。</li><li>信息抽取综述：IE = NER+RE，其中NER最简单的方式是直接匹配（Lexical matching ）字典中的实体（缺乏同义词，而且过于具体，导致召回率低），稍复杂的方式是有监督学习；RE多采用基于规则和基于机器学习(P 50.3% R 70.1%)</li></ol><h5 id="Methods-and-Results"><a href="#Methods-and-Results" class="headerlink" title="Methods and Results:"></a>Methods and Results:</h5><ol><li><p>Brain region NERs: 词典匹配的方法处理同义词、扩展缩写；机器学习的方法在CRF上发掘更多特征</p></li><li><p>Connectivity Extractors: FILTER的方法采用过滤器过滤脑区共现的句子，KERNEL的方法同采用浅层语义解析，RULES的方法基于九种规则类似于‘projection from the region A (of the region B) to the region C and the region D’ </p></li><li><p>NER结果：基于词典的方式无论采用精确匹配还是粗略匹配召回率都不高，但是用于非常大的语料库注重精度时，可以采用基于词典匹配的方法</p><img src="/2019/11/21/脑区连接关系提取/8.png"> </li><li><p>RE结果（不考虑有1/4是跨句子的连接关系）：基于FILTER召回率高，基于RULES精确率高，基于KERNEL适中，对于大规模的语料库需要提高精度可以采用组合的方式。</p><img src="/2019/11/21/脑区连接关系提取/9.png"> </li></ol><h5 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation:"></a>Evaluation:</h5><img src="/2019/11/21/脑区连接关系提取/10.png"> <p>对13.2 million篇PubMed摘要和630 216篇PMC全文，用上图pipeline做了提取，并统计了内部模型一致性和外部数据库AMBCA匹配一致性。</p><img src="/2019/11/21/脑区连接关系提取/11.png"> <p>最后总结这项工作的意义不是替代人抽取关系，而是提供一个平台让研究人员关注更可能出现的连接性关系，还有对模型不一致的情况进行手动筛选和评估（包括POS和NEG关系）。开源了抽取框架<a href="https://github.com/BlueBrain/bluima" target="_blank" rel="noopener">bluima</a></p><p>之后可以在框架内改进模型比如加入深度学习。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大多数生物医学领域的关系提取都是面向通用的基因、化学物质、疾病间的，很少研究大脑神经投射和连接性的。调研找到的文献不多，这里汇总一下：&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>知识库流程综述v1</title>
    <link href="http://yoursite.com/2019/07/30/%E7%9F%A5%E8%AF%86%E5%BA%93%E6%B5%81%E7%A8%8B%E7%BB%BC%E8%BF%B0v1/"/>
    <id>http://yoursite.com/2019/07/30/%E7%9F%A5%E8%AF%86%E5%BA%93%E6%B5%81%E7%A8%8B%E7%BB%BC%E8%BF%B0v1/</id>
    <published>2019-07-30T02:11:43.000Z</published>
    <updated>2019-09-02T03:42:24.050Z</updated>
    
    <content type="html"><![CDATA[<p>这篇应该算是知识库构建的整个流程，之后可能需要跟老师交流后增减一些东西。</p><a id="more"></a><ol><li><p>文献数据获取及预处理：</p><p>思路：先获取所有与脑区核团相关的Pubmed文献，脑区核团名称来自于Allen本体，获取的数据格式一般为txt，之后，对获取数据进行数据预处理，转化为json格式或其他需要的格式。</p><p>难点：①获取完整全面的文献数据，需要考虑各个核团名称的缩写词、同义词；</p><p>②获取的数据编码为utf-8，但部分数据存在乱码现象，需要做一个预处理。</p><p>思考：①只获取与核团相关的文献构建知识库可能不够，所以需要获取更多的文献导入进知识库中；</p><p>②需要获取PMC的文献，对全文数据进行检索，使数据库变得更加丰富。</p></li><li><p>NER（实体抽取）：</p><p>接下来，使用现有工具对获取到的文献进行命名实体识别，具体工具有pubtator和saber，这两个工具主要识别基因（gene）、疾病（disease）、化学物质（chemical）三类实体。</p><p>Pubtator：将获取文献的pmid整理成一个txt，输入给pubtator，返回标注后的结果，该方法速度快，1000篇文献需要30-40s；</p><p>Saber：将获取的原始文献输入给saber，返回标注结果，该方法的速度较慢，10篇文献需要20s左右。</p><p>难点：①saber方法返回速度较慢，处理所有文献需要的时间过长，需要考虑是否继续使用该方法。具体思路：先将获取的文献进行抽样，将抽样的文献输入给该系统，进行NER，将获取的结果与pubtator进行比较，提取出saber识别的但pubtator不存在的实体进行评估，将该实体与标准字典进行匹配，计算数据的准确率，以此确认该方法是否继续使用。</p><p>②需要考虑获取的三种类别是否能够满足知识库的需求，是否需要继续寻找其他可用工具。</p></li><li><p>NEL（实体链接）（进行中）：</p><p>获取的命名实体数据主要包括实体名称，外部数据库编号，将这部分数据与标准字典（UMLS）进行匹配，将匹配到的数据保留下来，未匹配到的数据进行剔除。</p><p>难点：①首先要构建标准字典，讨论确定标准字典的数据集；</p><p>②实体名称字段进行精确匹配会存在很大的问题。首先，文献中实体名称不一定是标准名称，有可能出现匹配不到的情况；其次，识别保存结果可能与标准名称存在格式差异，也会导致匹配不到相应结果的情况；</p><p>③外部数据库编号匹配也可能存在问题。首先，不同NER系统给出的外部数据库编号之间可能存在差异，因此，和标准数据库匹配时可能存在不匹配的问题。</p></li><li><p>RE（关系抽取）（进行中）：</p><p>利用现有工具对文献中实体进行关系抽取，现有工具利用Pubtator抽取文献中的实体，之后对实体进行关系抽取。接下来，需要将抽取的关系与标准数据库（SemmedDB）进行匹配。</p><p>难点：①现有工具的选择和确认：初步有几个项目和工具，bran，GNBR和snorkel，需要整合到标准库上</p><p>②标准关系类别定义：UMLS Semantic Network。现有工具抽取的关系定义与标准关系可能存在差异，需要将抽取的关系先与标准关系进行对应，此处需要人为筛选定义映射关系。之后，对抽取的关系进行筛选，将不存在的实体关系剔除掉，筛选方案需要继续讨论；</p><p>③需要评估关系抽取的精度，对文献检索的参考意义有多大</p></li><li><p>与本体匹配（方法已实现）：</p><p>暂时选用的是biolink本体，因为没有发现更适用的神经科学本体，手工制定也不太现实</p></li><li><p>数据存储：</p><p>将获取的文献、命名实体和实体关系全部导入MongoDB数据库中，以json格式数据进行保存；还将标准化后的关系导入图数据库neo4j方便展示</p></li><li><p>数据检索（未做）：</p><p>将数据库中的数据导入进elasticsearch中，利用elasticsearch进行数据检索，输入关键词后，返回相应的文献，并将文献中的实体（关系）标注出来。</p><p>难点：①elasticsearch搜索是基于关键词检索，会将满足关键词的信息返回，并以一定的排序算法将文献排序下来，需要思考如何改进排序算法，利用实体和关系将用户最需要的文献返回回来；</p><p>②需要将文献中的实体进行高亮标注，并以不同的颜色代表不同的实体（此步骤需要前端人员编写相应的函数）；</p><p>③需要思考如何将获取的关系在搜索结果中做进一步展示。</p></li><li><p>数据表示（未做）：</p><p>将检索的结果以网页可视化的形式展示出来。</p><p>难点：①需要懂前端的人员进行构建。</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇应该算是知识库构建的整个流程，之后可能需要跟老师交流后增减一些东西。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0726</title>
    <link href="http://yoursite.com/2019/07/26/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0726/"/>
    <id>http://yoursite.com/2019/07/26/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0726/</id>
    <published>2019-07-26T12:28:39.000Z</published>
    <updated>2019-09-02T09:01:59.500Z</updated>
    
    <content type="html"><![CDATA[<p>最后是注意力机制在RE的应用。</p><a id="more"></a><h4 id="Attention-based-Neural-Networks-for-Chemical-Protein-Relation-Extraction-2017"><a href="#Attention-based-Neural-Networks-for-Chemical-Protein-Relation-Extraction-2017" class="headerlink" title="Attention-based Neural Networks for Chemical Protein Relation Extraction(2017)"></a>Attention-based Neural Networks for Chemical Protein Relation Extraction(2017)</h4><h4 id="Learning-local-and-global-contexts-using-a-convolutional-recurrent-network-model-for-relation-classification-in-biomedical-text-2017"><a href="#Learning-local-and-global-contexts-using-a-convolutional-recurrent-network-model-for-relation-classification-in-biomedical-text-2017" class="headerlink" title="Learning local and global contexts using a convolutional recurrent network model for relation classification in biomedical text(2017)"></a>Learning local and global contexts using a convolutional recurrent network model for relation classification in biomedical text(2017)</h4><h4 id="Attending-to-All-Mention-Pairs-for-Full-Abstract-Biological-Relation-Extraction-2017"><a href="#Attending-to-All-Mention-Pairs-for-Full-Abstract-Biological-Relation-Extraction-2017" class="headerlink" title="Attending to All Mention Pairs for Full Abstract Biological Relation Extraction(2017)"></a>Attending to All Mention Pairs for Full Abstract Biological Relation Extraction(2017)</h4><h4 id="Simultaneously-Self-Attending-to-All-Mentions-for-Full-Abstract-Biological-Relation-Extraction-2018"><a href="#Simultaneously-Self-Attending-to-All-Mentions-for-Full-Abstract-Biological-Relation-Extraction-2018" class="headerlink" title="Simultaneously Self-Attending to All Mentions for Full-Abstract Biological Relation Extraction(2018)"></a>Simultaneously Self-Attending to All Mentions for Full-Abstract Biological Relation Extraction(2018)</h4><h4 id="Extracting-chemical-protein-relations-usingattention-based-neural-networks-2018"><a href="#Extracting-chemical-protein-relations-usingattention-based-neural-networks-2018" class="headerlink" title="Extracting chemical-protein relations usingattention-based neural networks(2018)"></a>Extracting chemical-protein relations usingattention-based neural networks(2018)</h4><h4 id="Combining-Context-and-Knowledge-Representations-for-Chemical-disease-Relation-Extraction-2018"><a href="#Combining-Context-and-Knowledge-Representations-for-Chemical-disease-Relation-Extraction-2018" class="headerlink" title="Combining Context and Knowledge Representations for Chemical-disease Relation Extraction(2018)"></a>Combining Context and Knowledge Representations for Chemical-disease Relation Extraction(2018)</h4><h4 id="A-document-level-neural-model-integrated-domain-knowledge-for-chemical-induced-disease-relations-2018"><a href="#A-document-level-neural-model-integrated-domain-knowledge-for-chemical-induced-disease-relations-2018" class="headerlink" title="A document level neural model integrated domain knowledge for chemical-induced disease relations(2018)"></a>A document level neural model integrated domain knowledge for chemical-induced disease relations(2018)</h4><h4 id="Chemical-induced-disease-relation-extraction-with-dependency-information-T-and-prior-knowledge-2018"><a href="#Chemical-induced-disease-relation-extraction-with-dependency-information-T-and-prior-knowledge-2018" class="headerlink" title="Chemical-induced disease relation extraction with dependency information T and prior knowledge(2018)"></a>Chemical-induced disease relation extraction with dependency information T and prior knowledge(2018)</h4><h4 id="Distantly-Supervised-Biomedical-Knowledge-Acquisition-via-Knowledge-Graph-Based-Attention-2019"><a href="#Distantly-Supervised-Biomedical-Knowledge-Acquisition-via-Knowledge-Graph-Based-Attention-2019" class="headerlink" title="Distantly Supervised Biomedical Knowledge Acquisition via Knowledge Graph Based Attention(2019)"></a>Distantly Supervised Biomedical Knowledge Acquisition via Knowledge Graph Based Attention(2019)</h4><h4 id="Relation-Extraction-using-Explicit-Context-Conditioning-2019"><a href="#Relation-Extraction-using-Explicit-Context-Conditioning-2019" class="headerlink" title="Relation Extraction using Explicit Context Conditioning(2019)"></a>Relation Extraction using Explicit Context Conditioning(2019)</h4><h4 id="Transfer-Learning-for-Scientific-Data-Chain-Extraction-in-Small-Chemical-Corpus-with-BERT-CRF-Model-2019"><a href="#Transfer-Learning-for-Scientific-Data-Chain-Extraction-in-Small-Chemical-Corpus-with-BERT-CRF-Model-2019" class="headerlink" title="Transfer Learning for Scientific Data Chain Extraction in Small Chemical Corpus with BERT-CRF Model(2019)"></a>Transfer Learning for Scientific Data Chain Extraction in Small Chemical Corpus with BERT-CRF Model(2019)</h4><h4 id><a href="#" class="headerlink" title=" "></a> </h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最后是注意力机制在RE的应用。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0725</title>
    <link href="http://yoursite.com/2019/07/25/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0725/"/>
    <id>http://yoursite.com/2019/07/25/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0725/</id>
    <published>2019-07-25T12:28:33.000Z</published>
    <updated>2019-09-02T08:59:58.290Z</updated>
    
    <content type="html"><![CDATA[<p>这篇是NER和RE的联合抽取模型。</p><a id="more"></a><h4 id="A-hybrid-deep-learning-approach-for-medical-relation-extraction-2018"><a href="#A-hybrid-deep-learning-approach-for-medical-relation-extraction-2018" class="headerlink" title="A hybrid deep learning approach for medical relation extraction(2018)"></a>A hybrid deep learning approach for medical relation extraction(2018)</h4><h4 id="A-hybrid-model-based-on-neural-networks-for-biomedical-relation-extraction-2018"><a href="#A-hybrid-model-based-on-neural-networks-for-biomedical-relation-extraction-2018" class="headerlink" title="A hybrid model based on neural networks for biomedical relation extraction(2018)"></a>A hybrid model based on neural networks for biomedical relation extraction(2018)</h4><h4 id="Automatic-extraction-of-gene-disease-associations-from-literature-using-joint-ensemble-learning-2018"><a href="#Automatic-extraction-of-gene-disease-associations-from-literature-using-joint-ensemble-learning-2018" class="headerlink" title="Automatic extraction of gene-disease associations from literature using joint ensemble learning(2018)"></a>Automatic extraction of gene-disease associations from literature using joint ensemble learning(2018)</h4><h4 id="Joint-entity-recognition-and-relation-extraction-as-a-multi-head-selection-problem-2018"><a href="#Joint-entity-recognition-and-relation-extraction-as-a-multi-head-selection-problem-2018" class="headerlink" title="Joint entity recognition and relation extraction as a multi-head selection problem(2018)"></a>Joint entity recognition and relation extraction as a multi-head selection problem(2018)</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇是NER和RE的联合抽取模型。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0724</title>
    <link href="http://yoursite.com/2019/07/24/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0724/"/>
    <id>http://yoursite.com/2019/07/24/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0724/</id>
    <published>2019-07-24T14:20:05.000Z</published>
    <updated>2019-09-02T09:01:27.260Z</updated>
    
    <content type="html"><![CDATA[<p>这篇是递归神经网络和树/图LSTM。</p><a id="more"></a><h4 id="Chemical-gene-relation-extraction-using-recursive-neural-network-2018"><a href="#Chemical-gene-relation-extraction-using-recursive-neural-network-2018" class="headerlink" title="Chemical-gene relation extraction using recursive neural network(2018)"></a>Chemical-gene relation extraction using recursive neural network(2018)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>提出了一种treeLSTM和叫Stack-augmented Parser Interpreter Neural Network (SPINN)的神经网络</p><h4 id="Drug-drug-interaction-extraction-from-the-literature-using-a-recursive-neural-network-2018"><a href="#Drug-drug-interaction-extraction-from-the-literature-using-a-recursive-neural-network-2018" class="headerlink" title="Drug drug interaction extraction from the literature using a recursive neural network(2018)"></a>Drug drug interaction extraction from the literature using a recursive neural network(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>采用treeLSTM的变体递归神经网络识别DDI四类关系（advice, effect, mechanism, and int），其中除了句子依存解析外，还加入了位置嵌入信息、子树包含特征和集成方法提高精度</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><p>模型如图，其中子树包含特征是指：如果一种目标药物存在于当前节点的叶子节点时特征的置1，否则置0</p><img src="/2019/07/24/文献阅读0724/1.png"><h4 id="Mapping-Text-to-Knowledge-Graph-Entities-using-Multi-Sense-LSTMs-2018"><a href="#Mapping-Text-to-Knowledge-Graph-Entities-using-Multi-Sense-LSTMs-2018" class="headerlink" title="Mapping Text to Knowledge Graph Entities using Multi-Sense LSTMs(2018)"></a>Mapping Text to Knowledge Graph Entities using Multi-Sense LSTMs(2018)</h4><h4 id="Syntax-based-Transfer-Learning-for-the-Task-of-Biomedical-Relation-Extraction-2018"><a href="#Syntax-based-Transfer-Learning-for-the-Task-of-Biomedical-Relation-Extraction-2018" class="headerlink" title="Syntax-based Transfer Learning for the Task of Biomedical Relation Extraction(2018)"></a>Syntax-based Transfer Learning for the Task of Biomedical Relation Extraction(2018)</h4><h4 id="Biomedical-Event-Extraction-based-on-Knowledge-driven-Tree-LSTM-2019"><a href="#Biomedical-Event-Extraction-based-on-Knowledge-driven-Tree-LSTM-2019" class="headerlink" title="Biomedical Event Extraction based on Knowledge-driven Tree-LSTM(2019)"></a>Biomedical Event Extraction based on Knowledge-driven Tree-LSTM(2019)</h4><h4 id="BERE-AN-ACCURATE-DISTANTLY-SUPERVISED-BIOMEDICAL-ENTITY-RELATION-EXTRACTION-NETWORK-2019"><a href="#BERE-AN-ACCURATE-DISTANTLY-SUPERVISED-BIOMEDICAL-ENTITY-RELATION-EXTRACTION-NETWORK-2019" class="headerlink" title="BERE: AN ACCURATE DISTANTLY SUPERVISED BIOMEDICAL ENTITY RELATION EXTRACTION NETWORK(2019)"></a>BERE: AN ACCURATE DISTANTLY SUPERVISED BIOMEDICAL ENTITY RELATION EXTRACTION NETWORK(2019)</h4><h5 id="一句话总结-2"><a href="#一句话总结-2" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>采用了Gumbel Tree-GRU模型学习句子结构并整合实体嵌入信息，模型也加入了单词和句子级别的注意力机制提高关系抽取精度，在DDI’13数据集上取得了最好效果。</p><img src="/2019/07/24/文献阅读0724/2.png"><h4 id="Cross-Sentence-N-ary-Relation-Extraction-with-Graph-LSTMs-2017"><a href="#Cross-Sentence-N-ary-Relation-Extraction-with-Graph-LSTMs-2017" class="headerlink" title="Cross-Sentence N -ary Relation Extraction with Graph LSTMs(2017)"></a>Cross-Sentence N -ary Relation Extraction with Graph LSTMs(2017)</h4><h4 id="N-ary-Relation-Extraction-using-Graph-State-LSTM-2018"><a href="#N-ary-Relation-Extraction-using-Graph-State-LSTM-2018" class="headerlink" title="N -ary Relation Extraction using Graph State LSTM(2018)"></a>N -ary Relation Extraction using Graph State LSTM(2018)</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇是递归神经网络和树/图LSTM。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0723</title>
    <link href="http://yoursite.com/2019/07/23/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0723/"/>
    <id>http://yoursite.com/2019/07/23/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0723/</id>
    <published>2019-07-23T08:42:33.000Z</published>
    <updated>2019-09-02T08:57:16.600Z</updated>
    
    <content type="html"><![CDATA[<p>这篇是双向LSTM的。(慢慢补充)</p><a id="more"></a><h4 id="Leveraging-Biomedical-Resources-in-Bi-LSTM-for-Drug-Drug-Interaction-Extraction-2018"><a href="#Leveraging-Biomedical-Resources-in-Bi-LSTM-for-Drug-Drug-Interaction-Extraction-2018" class="headerlink" title="Leveraging Biomedical Resources in Bi-LSTM for Drug-Drug Interaction Extraction(2018)"></a>Leveraging Biomedical Resources in Bi-LSTM for Drug-Drug Interaction Extraction(2018)</h4><h4 id="Feature-Assisted-bi-directional-LSTM-Model-for-Protein-Protein-Interaction-Identification-from-Biomedical-Texts-2018"><a href="#Feature-Assisted-bi-directional-LSTM-Model-for-Protein-Protein-Interaction-Identification-from-Biomedical-Texts-2018" class="headerlink" title="Feature Assisted bi-directional LSTM Model for Protein-Protein Interaction Identification from Biomedical Texts(2018)"></a>Feature Assisted bi-directional LSTM Model for Protein-Protein Interaction Identification from Biomedical Texts(2018)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>加了最短依存路径SDP的Bi-LSTM提取PPI</p><img src="/2019/07/23/文献阅读0723/1.png"><h4 id="Improving-the-learning-of-chemical-protein-interactions-from-literature-using-transfer-learning-and-specialized-word-embeddings-2018"><a href="#Improving-the-learning-of-chemical-protein-interactions-from-literature-using-transfer-learning-and-specialized-word-embeddings-2018" class="headerlink" title="Improving the learning of chemical-protein interactions from literature using transfer learning and specialized word embeddings(2018)"></a>Improving the learning of chemical-protein interactions from literature using transfer learning and specialized word embeddings(2018)</h4><h4 id="CONTEXT-AWARENESS-AND-EMBEDDING-FOR-BIOMEDICAL-EVENT-EXTRACTION-2019"><a href="#CONTEXT-AWARENESS-AND-EMBEDDING-FOR-BIOMEDICAL-EVENT-EXTRACTION-2019" class="headerlink" title="CONTEXT AWARENESS AND EMBEDDING FOR BIOMEDICAL EVENT EXTRACTION(2019)"></a>CONTEXT AWARENESS AND EMBEDDING FOR BIOMEDICAL EVENT EXTRACTION(2019)</h4><h4 id="Combining-relation-extraction-with-function-detection-for-BEL-statement-extraction-2019"><a href="#Combining-relation-extraction-with-function-detection-for-BEL-statement-extraction-2019" class="headerlink" title="Combining relation extraction with function detection for BEL statement extraction(2019)"></a>Combining relation extraction with function detection for BEL statement extraction(2019)</h4><h4 id="Exploring-semi-supervised-variational-autoencoders-for-biomedical-relation-extraction-2019"><a href="#Exploring-semi-supervised-variational-autoencoders-for-biomedical-relation-extraction-2019" class="headerlink" title="Exploring semi-supervised variational autoencoders for biomedical relation extraction(2019)"></a>Exploring semi-supervised variational autoencoders for biomedical relation extraction(2019)</h4><h4 id="From-POS-tagging-to-dependency-parsing-for-biomedical-event-extraction-2019"><a href="#From-POS-tagging-to-dependency-parsing-for-biomedical-event-extraction-2019" class="headerlink" title="From POS tagging to dependency parsing for biomedical event extraction(2019)"></a>From POS tagging to dependency parsing for biomedical event extraction(2019)</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇是双向LSTM的。(慢慢补充)&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0722</title>
    <link href="http://yoursite.com/2019/07/22/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0722/"/>
    <id>http://yoursite.com/2019/07/22/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0722/</id>
    <published>2019-07-22T00:46:54.000Z</published>
    <updated>2019-09-02T08:56:44.710Z</updated>
    
    <content type="html"><![CDATA[<p>在snorkel上卡了壳，不会写LF。。。回过头读一些CNN/LSTM/Attention+SDP+远程监督的文章补充基础知识吧，这也是通用领域做关系抽取的思路。</p><p>就按主体模型分几天记吧，这篇是CNN(之前写的BioRE文献阅读报告里面详述了模型演化过程，这里只是选了两篇运用到生物医学领域的)</p><a id="more"></a><h4 id="Convolutional-neural-networks-for-chemical-disease-relation-extraction-are-improved-with-character-based-word-embeddings-2018"><a href="#Convolutional-neural-networks-for-chemical-disease-relation-extraction-are-improved-with-character-based-word-embeddings-2018" class="headerlink" title="Convolutional neural networks for chemical-disease relation extraction are improved with character-based word embeddings(2018)"></a>Convolutional neural networks for chemical-disease relation extraction are improved with character-based word embeddings(2018)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p> CNN+CNNchar 和 CNN+LSTMchar 的模型对比，证实了字符嵌入的有效性。其实就是在15年提出的PCNN基础上加了一层char embedding，这在NER里面已经很常见了。</p><img src="/2019/07/22/文献阅读0722/1.png"><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>在BC5CDR上取得了SOTA的结果。</p><img src="/2019/07/22/文献阅读0722/2.png"><h4 id="Biomedical-Event-Extraction-Using-Convolutional-Neural-Networks-and-Dependency-Parsing-2018"><a href="#Biomedical-Event-Extraction-Using-Convolutional-Neural-Networks-and-Dependency-Parsing-2018" class="headerlink" title="Biomedical Event Extraction Using Convolutional Neural Networks and Dependency Parsing(2018)"></a>Biomedical Event Extraction Using Convolutional Neural Networks and Dependency Parsing(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>在他们先前开发的用SVM做NRE的TEES系统上加入了一个抽取生物医学关系和事件的CNN子模块，利用了多种输入和依存解析嵌入。</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li><p>数据集和模型：</p><p>BioNLP，DDI and BioCreative corpora</p></li><li><p>抽取流程：</p><p>TEES基于事件或关系的图表示，其中命名实体和触发词是节点，关系是边。抽取过程包括：entity detection（识别候选实体或触发词）、edge detection（关系检测）、unmerging stage（判定是否为真实事件）、modifier detection(检测事件方式：否定或是对立)</p></li><li><p>模型：</p><p>输入的嵌入包括词嵌入、POS嵌入、距离嵌入、相对位置嵌入（当前token在识别关系词的前、后或中，是否是实体一部分）、实体特征嵌入（当前token是否是候选实体、触发词等，在关系检测中使用）、最短路径嵌入(指示token是否在两实体的最短依存路径中及扮演的关系，在关系抽取中使用)</p><img src="/2019/07/22/文献阅读0722/3.png"></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在snorkel上卡了壳，不会写LF。。。回过头读一些CNN/LSTM/Attention+SDP+远程监督的文章补充基础知识吧，这也是通用领域做关系抽取的思路。&lt;/p&gt;
&lt;p&gt;就按主体模型分几天记吧，这篇是CNN(之前写的BioRE文献阅读报告里面详述了模型演化过程，这里只是选了两篇运用到生物医学领域的)&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0719</title>
    <link href="http://yoursite.com/2019/07/19/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0719/"/>
    <id>http://yoursite.com/2019/07/19/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0719/</id>
    <published>2019-07-19T01:03:23.000Z</published>
    <updated>2019-09-02T08:54:04.980Z</updated>
    
    <content type="html"><![CDATA[<p>找到两篇直接面向文献中关系抽取的文献，对做工程很有启发性，不单单只是测试新模型提高数据集精度。</p><a id="more"></a><h4 id="An-Insight-Extraction-System-on-BioMedical-Literature-with-Deep-Neural-Networks-2017"><a href="#An-Insight-Extraction-System-on-BioMedical-Literature-with-Deep-Neural-Networks-2017" class="headerlink" title="An Insight Extraction System on BioMedical Literature with Deep Neural Networks(2017)"></a>An Insight Extraction System on BioMedical Literature with Deep Neural Networks(2017)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>按照知识表示的思路，提出了一个相似度测度方法来评价实体间的相关性然后排序预测Cause-Effect关系</p><img src="/2019/07/19/文献阅读0719/1.png"><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li>首先用生物医学词典（关键词匹配）和浅层语义解析器（实体边界预测）做NER</li><li>然后用上下文相似度模型和语义相似度模型来对实体A、B、上下文和关系R建模并排名。思路是先用BiLSTM和attention机制获得带有上下文信息表示的实体A和B，然后输入到relational similarity model中计算A B还有关系R的相似性测度，训练使得R与A B在低维空间中有相近的表示。</li></ol><h4 id="Deep-learning-of-mutation-gene-drug-relations-from-the-literature-2018"><a href="#Deep-learning-of-mutation-gene-drug-relations-from-the-literature-2018" class="headerlink" title="Deep learning of mutation-gene-drug relations from the literature(2018)"></a>Deep learning of mutation-gene-drug relations from the literature(2018)</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;找到两篇直接面向文献中关系抽取的文献，对做工程很有启发性，不单单只是测试新模型提高数据集精度。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0717</title>
    <link href="http://yoursite.com/2019/07/17/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0717/"/>
    <id>http://yoursite.com/2019/07/17/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0717/</id>
    <published>2019-07-17T02:10:43.000Z</published>
    <updated>2019-09-02T08:50:56.250Z</updated>
    
    <content type="html"><![CDATA[<p>新文章固然好，但模型复杂且不稳定，难以用于大规模PubMed关系的抽取。deepdive及后续的snorkel是个好工具，看到好多大厂也都在用，老师一直强调我们是做工程的，尽量要快要能用，所以还是回到snorkel吧。</p><a id="more"></a><h4 id="Semi-supervised-Ensemble-Learning-with-Weak-Supervision-for-Biomedical-Relation-Extraction-2019"><a href="#Semi-supervised-Ensemble-Learning-with-Weak-Supervision-for-Biomedical-Relation-Extraction-2019" class="headerlink" title="Semi-supervised Ensemble Learning with Weak Supervision for Biomedical Relation Extraction(2019)"></a>Semi-supervised Ensemble Learning with Weak Supervision for Biomedical Relation Extraction(2019)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>用半监督集成学习模型来产生弱标签然后弱监督学习做关系抽取。<a href="https://github.com/littlewine/snorkel-ml/" target="_blank" rel="noopener">项目地址</a></p><h5 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h5><ol><li><p>目标是抽取生物医学摘要中的regulation(CPR)和induce(CID)语义关系对</p><img src="/2019/07/17/文献阅读0717/2.png"></li><li><p>为避免复杂的feature engineering使用ANN，但容易过拟合，所以用集成学习提高泛化能力</p></li><li><p>半监督集成学习：将半监督和集成学习结合在一起是个新颖的思路，集成学习可以加强半监督学习的表现，无监督标签可以增加learners的多样性，反过来降噪，这是种co-training的方式</p></li><li><p>思路是(1)用小型带标签数据集训练base learners，来预测更多的unlabeled data为weak labels；(2)加denoiser，然后在此基础上用弱监督学习训练更强大的meta-learner(noise-aware discriminative model)</p></li></ol><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li>数据收集：假设已有大小为m的金标准数据集DB（拆分成train dev test）但是远不够训练模型得到很好的效果，我们获取一个大小为M(&gt;&gt;m)的无标签数据集DU</li><li>建立K个基础学习器：通过改变features、文本特征表示和机器学习模型等来构建多个base learner，尽量不要使用相似的分类器(这是通过K*K的相似度矩阵来聚类计算的)</li><li>预测DU，得到K*M的预测标签（这里用到snorkel来推断候选实体对关系），然后用denoiser将投票矩阵变为M个标签</li><li>训练一个双向LSTM的meta-learner</li></ol><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>展示了用机器学习模型集成学习产生弱标签对关系抽取的影响，还有参数的选择，降噪方法的选择，meta-learner的表现，如图：</p><img src="/2019/07/17/文献阅读0717/2.png" title="base-learner的精度，集成学习产生弱标签的精度，以及meta-learner的精度"><p>结果展示这种弱监督方式几乎可以达到全部有监督的精度，所以可以用本文提出的模型做数据扩增Unlabeled dataset expansion，而且迁移领域只需要标注少量的金标准数据集即可。鉴于F1 score通常不具有说服力，本文也提出了对marginal weak labels更好的评估方法。</p><p>(文章的思路很巧妙，效果也不错。看到开源的项目是用jupyter notebook写的，准备用几天时间好好学习一下)</p><h4 id="A-global-network-of-biomedical-relationships-derived-from-text-2018"><a href="#A-global-network-of-biomedical-relationships-derived-from-text-2018" class="headerlink" title="A global network of biomedical relationships derived from text(2018)"></a>A global network of biomedical relationships derived from text(2018)</h4><p>Zenodo: Proposed a labeled, weighted network of structured biomedical relationships for all Medline abstracts using NCBI’s PubTator, the Stanford dependency parser and ensemble biclustering algorithm (EBC) .</p><p>抽取到的PubMed级别的chemical-disease-gene三者间的关系：<a href="https://zenodo.org/record/3346007" target="_blank" rel="noopener">https://zenodo.org/record/3346007</a></p><h4 id="Reusing-label-functions-to-extract-multiple-types-of-relationships-from-biomedical-abstracts-at-scale-2019"><a href="#Reusing-label-functions-to-extract-multiple-types-of-relationships-from-biomedical-abstracts-at-scale-2019" class="headerlink" title="Reusing label functions to extract multiple types of relationships from biomedical abstracts at scale(2019)"></a>Reusing label functions to extract multiple types of relationships from biomedical abstracts at scale(2019)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>通过制定snorkel LF大规模抽取PubMed生物医学关系。<a href="https://github.com/greenelab/snorkeling" target="_blank" rel="noopener">项目地址</a></p><p>准备借鉴这个做之后的项目。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;新文章固然好，但模型复杂且不稳定，难以用于大规模PubMed关系的抽取。deepdive及后续的snorkel是个好工具，看到好多大厂也都在用，老师一直强调我们是做工程的，尽量要快要能用，所以还是回到snorkel吧。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0716</title>
    <link href="http://yoursite.com/2019/07/16/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0716/"/>
    <id>http://yoursite.com/2019/07/16/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0716/</id>
    <published>2019-07-16T02:43:02.000Z</published>
    <updated>2019-07-29T13:24:23.320Z</updated>
    
    <content type="html"><![CDATA[<p>继续BioRE，看几篇最新的。</p><a id="more"></a><h4 id="BO-LSTM-classifying-relations-via-long-short-term-memory-networks-along-biomedical-ontologies-2019"><a href="#BO-LSTM-classifying-relations-via-long-short-term-memory-networks-along-biomedical-ontologies-2019" class="headerlink" title="BO-LSTM: classifying relations via long short-term memory networks along biomedical ontologies(2019)"></a>BO-LSTM: classifying relations via long short-term memory networks along biomedical ontologies(2019)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>利用领域本体匹配和溯源来提高DDI关系分类精度。<a href="https://github.com/lasigeBioTM/BOLSTM" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/16/文献阅读0716/1.png" title="BO-LSTM Model architecture"><p>模型如图，假设已经标注好实体，任务是识别候选实体对的关系，我们先用spaCy得到最短依存路径SDP，对SDP中的每个词得到它们的词嵌入；wordnet上义词（也就是描述的类别）；还有与本体中的概念匹配（用距离相似度）和找概念原型，按照从通用概念—&gt;单词自身的实体链来表示；找到候选实体的概念链中公共的概念。将这些都作为嵌入的组件通过LSTM网络，来测试外部本体对 SemEval 2013 Task 9 DDI识别精度的影响。</p><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>如图分别在关系检测和关系分类上的结果，关系检测忽略关系类型，关系分类则更难些要求识别出positive和它们的类型(advise, effect, mechanism, int)</p><img src="/2019/07/16/文献阅读0716/3.png"><img src="/2019/07/16/文献阅读0716/2.png"><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>这个框架思路(就是用领域本体匹配实体作为embedding来学习能提高识别精度)具有可扩展性，比如提取基因-表型关系时，可以利用Gene Ontology，只要有标注好的数据集即可拿来训练然后预测。</p><p>初期准备用这个项目实战，但是GitHub有些问题，正在提交issues和作者交流中…</p><h4 id="REflex-Flexible-Framework-for-Relation-Extraction-in-Multiple-Domains-2019"><a href="#REflex-Flexible-Framework-for-Relation-Extraction-in-Multiple-Domains-2019" class="headerlink" title="REflex: Flexible Framework for Relation Extraction in Multiple Domains(2019)"></a>REflex: Flexible Framework for Relation Extraction in Multiple Domains(2019)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>针对生物医学领域关系抽取文献多而杂且都不开源不具有普遍性的特点，提出了一个关系抽取的通用框架！！研究了预处理、模型训练、参数调节、结果评估这些步骤的影响，主要在三个数据集上做了测试：Semeval 2010，DDI Extraction，i2b2/VA 2010 relations。这篇文章条理清晰，代码开源，泛化性强，是难得的好文章。<a href="https://github.com/geetickachauhan/relation-extraction" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/16/文献阅读0716/5.png" title="workflow"><ol><li>预处理：分句分词，大写转小写，去除停用词，数字统一化，NER blinding(就是把句子中的实体按照关系识别的要求规范化，比如for semeval were <em>ENTITY</em>, for ddi were <em>DRUG</em> and for i2b2 were <em>PROBLEM</em>, <em>TREATMENT</em> and <em>TEST</em>)，用spacy和ScispaCy标记这些特定类型</li><li>建模：选用的基本模型是带位置嵌入和ranking loss的卷积神经网络CRCNN，测试了piecewise max-pooling，ELMo还有BERT等的影响。其中ELMo可以用token级别的embedding，BERT可选两种：token级别的和句子CLS级别的。</li><li>训练：两种调参方式，手动调参和随机搜索</li><li>评估：分类和检测两个任务</li></ol><h5 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h5><img src="/2019/07/16/文献阅读0716/4.png"><ol><li>好的预处理比模型更重要</li><li>由于split bias单独报告一个测试集的精度会有问题，最好选用具有显著性的交叉验证</li><li>Contextualized embeddings很有用，所以featurizing embedding(ELMo，BERT等)很重要，在通过卷积层前把它们和词嵌入连接起来很有效</li><li>调参很关键，手动和随机搜索差不多但随机搜索需要设置经验范围</li><li>为新数据集依照正负样本的imbalance选择相应的评估准则</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;继续BioRE，看几篇最新的。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0715</title>
    <link href="http://yoursite.com/2019/07/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0715/"/>
    <id>http://yoursite.com/2019/07/15/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0715/</id>
    <published>2019-07-15T02:20:50.000Z</published>
    <updated>2019-09-02T08:46:51.140Z</updated>
    
    <content type="html"><![CDATA[<p>本着思路优先、生物医学领域优先和开源代码优先的原则，这周准备写一些关系抽取的文献。因为关系抽取的文献多又杂，方法五花八门，不像NER模型简单应用起来也方便，所以看起来比较吃力。废话不多说了正文如下：</p><a id="more"></a><h4 id="Relation-Extraction-from-Biomedical-Literature-with-Minimal-Supervision-and-Grouping-Strategy-2014"><a href="#Relation-Extraction-from-Biomedical-Literature-with-Minimal-Supervision-and-Grouping-Strategy-2014" class="headerlink" title="Relation Extraction from Biomedical Literature with Minimal Supervision and Grouping Strategy(2014)"></a>Relation Extraction from Biomedical Literature with Minimal Supervision and Grouping Strategy(2014)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>文章提出了一个新颖的远程监督模型，不需要手动标注数据，运用了外部知识库UMLS和分组策略，基于统计模型而非启发式规则，抽取文献中的基因和脑区间的基因表达关系。</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li><p>实体标注：标注基因（BioTagger）和脑区实体(NIF和脑区词典)</p></li><li><p>分组策略：远程监督通常假设抽取到的实体对是独立的，但是在生物医学领域很容易出现平行的实体对，所以文章采用Stanford parser解析句子获取出现在相似位置的名词和名词短语（通常是and相连的），并把连续的实体组成一组然后表示它们与其他实体的关系。</p><img src="/2019/07/15/文献阅读0715/1.png" title="以and相连的名词和名词短语"></li><li><p>特征提取：词法特征（两实体的词袋，和实体间单词的词袋特征）和句法特征（最短依存路径）。</p></li><li><p>远程监督关系抽取(模型训练)：远程监督假设文本中至少出现一个实体对表现出知识库中相应实体对的关系，这里利用了生物医学领域的知识库UMLS，然后将关系对用无向图建模。</p><img src="/2019/07/15/文献阅读0715/2.png"><p>建立条件概率公式如下，z(i)表示从每个句子x(i)抽取得到的关系，然后用y表示建立关系到知识库的映射：</p><img src="/2019/07/15/文献阅读0715/3.png"><p>我理解的公式的意思是：(3)是只要有句子表现出知识库中的r(e1,e2)关系就Φcorpus设定为1，然后(2)是一个对数线性模型来衡量实体对的关系类型（是基因表达关系还是其他关系），(1)然后把基因表达关系映射到知识库中的基因表达关系上，训练公式(2)中的θ参数使结果概率最大化。</p><p>(The model first predicts the relation types for the entity pair corresponding to each of its evidences.<br>Then, the predictions of relation types at sentential-level are aggregated to approximate the relation types for the entity pair at corpus-level. As long as one of the sentences is classified into the <em>geneExpression</em> category, the <em>geneExpression</em> relation is returned at corpus-level; otherwise, only <em>otherRelation</em> is returned.)</p></li></ol><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>找了10000篇全文，抽取大约得到30,000个有基因-脑区关系的句子，用分组得到包含大约7700个实体对，然后金标准标选了259个句子(114个基因表达，143个其他关系)用作模型测试，最后得到的精度大致和有监督的SVM相当。</p><h4 id="Large-scale-extraction-of-gene-interactions-from-full-text-literature-using-DeepDive-2016"><a href="#Large-scale-extraction-of-gene-interactions-from-full-text-literature-using-DeepDive-2016" class="headerlink" title="Large-scale extraction of gene interactions from full-text literature using DeepDive(2016)"></a>Large-scale extraction of gene interactions from full-text literature using DeepDive(2016)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>用deepdive远程监督抽取100000篇plos全文的基因间的关系(包括PPI和转录因子间的关系)。<a href="https://github.com/edoughty/deepdive_genegene_app" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/15/文献阅读0715/4.png" title="预处理、构建候选实体对、deepdive推理计算概率、专家微调"><ol><li>文献预处理：使用Stanford CoreNLP分句、分词、POS、NER、DP</li><li>提取候选实体对：基于共现关系提取出现在HGNC的候选基因对，并提取特征(词窗特征、依存特征等)</li><li>远程监督：运用外部数据库为候选基因对设labels为True，False or Unknown。为防止过拟合，设定一些高频的已知为True的基因对为Unknown，再随机设置一些unknown为负例</li><li>用deepdive推理：将带is_correct label的候选基因对输入，50％的标签不动作为权重特征学习和校准，其他的用factor graph推测概率(deepdive的原理待补充)</li><li>系统微调：每次迭代做错误分析和预测，用滚雪球策略增加正例(如果候选对被预测为真，加入到training中)</li><li>两种评估：金标准PPI数据集测F值，以及随机挑选的正负基因对curation</li></ol><h4 id="Distant-Supervision-for-Large-Scale-Extraction-of-Gene–Disease-Associations-from-Literature-Using-DeepDive-2018"><a href="#Distant-Supervision-for-Large-Scale-Extraction-of-Gene–Disease-Associations-from-Literature-Using-DeepDive-2018" class="headerlink" title="Distant Supervision for Large-Scale Extraction of Gene–Disease Associations from Literature Using DeepDive(2018)"></a>Distant Supervision for Large-Scale Extraction of Gene–Disease Associations from Literature Using DeepDive(2018)</h4><p>用deepdive抽取了879585篇PubMed摘要中的75595个独特基因-疾病关系，没什么新意，思路和上一篇文章基本一样，放下结果吧。</p><img src="/2019/07/15/文献阅读0715/5.png">]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本着思路优先、生物医学领域优先和开源代码优先的原则，这周准备写一些关系抽取的文献。因为关系抽取的文献多又杂，方法五花八门，不像NER模型简单应用起来也方便，所以看起来比较吃力。废话不多说了正文如下：&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0712</title>
    <link href="http://yoursite.com/2019/07/12/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0712/"/>
    <id>http://yoursite.com/2019/07/12/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0712/</id>
    <published>2019-07-12T02:41:59.000Z</published>
    <updated>2019-09-01T08:06:35.150Z</updated>
    
    <content type="html"><![CDATA[<p>阅读文献要紧跟前沿，不能闭门造车。生物医学nlp领域也随着ELMo, bert等Contextualized embedding的出现推陈出新，涌现了最前沿的几篇词向量、语言模型和预训练方法等的文章，这里按时间顺序做个记录慢慢补充。</p><a id="more"></a><h4 id="BioBERT-a-pre-trained-biomedical-language-representation-model-for-biomedical-text-mining-2019"><a href="#BioBERT-a-pre-trained-biomedical-language-representation-model-for-biomedical-text-mining-2019" class="headerlink" title="BioBERT: a pre-trained biomedical language representation model for biomedical text mining(2019)"></a>BioBERT: a pre-trained biomedical language representation model for biomedical text mining(2019)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>BioBERT全称生物医学双向Transformer编码器，也算是一种用迁移学习（双向语言模型）来解决数据缺失的方法。</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/12/文献阅读0712/1.png" title="训练和微调"><p>用PubMed和PMC预训练BERT的方法就不说了，在微调的时候，常采用WordPiece tokenization的方式，将新词用频繁的子词表示然后通过BioBERT。对NER，直接在biobert的输出加一层网络计算BIO/BIOES标签概率，也不需要CRF；对NRE，可以视为句子分类任务，也是在使用[CLS]表示的bert输出后加一层网络，其中对实体的处理eg: @GENE$</p><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><ol><li>ner：BERT &lt; BioBERT (+PubMed) &lt; BioBERT (+ PMC) &lt; SOTA models &lt; BioBERT (+PubMed + PMC).</li><li>nre：通常是SOTA models &lt;BERT &lt; BioBERT. 一般来说数据集越小提升效果越明显</li></ol><p>这是它的后续文章，用BERT配合Pubtator做NER，标注了所有的PubMed数据集</p><h4 id="A-Neural-Named-Entity-Recognition-and-Multi-Type-Normalization-Tool-for-Biomedical-Text-Mining-2019"><a href="#A-Neural-Named-Entity-Recognition-and-Multi-Type-Normalization-Tool-for-Biomedical-Text-Mining-2019" class="headerlink" title="A Neural Named Entity Recognition and Multi-Type Normalization Tool for Biomedical Text Mining(2019)"></a>A Neural Named Entity Recognition and Multi-Type Normalization Tool for Biomedical Text Mining(2019)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>传统的ner工具很难应对新实体，也不考虑被标注成多个类型的重叠实体，bern基于biobert标注然后运用决策规则和实体规范化技术解决这些问题。</p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/12/文献阅读0712/2.png"><p>先用tmTool和tmVar2.0处理输入的PMID或原文识别mutation，然后用biobert识别其他几种实体，对重叠实体，对重叠实体按照概率决策，对多个类型的实体规范化处理并分配统一id，输出标注后的文档(json或pubtator)。</p><ol><li><p>决策机制：下图左图是重叠实体的比例，右图是决策方式</p><img src="/2019/07/12/文献阅读0712/3.png"></li><li><p>实体规范化技术：</p><img src="/2019/07/12/文献阅读0712/4.png"><p>比如可以用bern快速发现HGNC IDs for genes, 和MeSH IDs for diseases</p></li></ol><h5 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h5><p><a href="https://bern.korea.ac.kr" target="_blank" rel="noopener">网址</a> <a href="https://bern.korea.ac.kr/pubmed/&lt;one or more PMIDs&gt;[/&lt;pubtator or json&gt;]" target="_blank" rel="noopener">API</a></p><h4 id="SCIBERT-Pretrained-Contextualized-Embeddings-for-Scientific-Text-2019"><a href="#SCIBERT-Pretrained-Contextualized-Embeddings-for-Scientific-Text-2019" class="headerlink" title="SCIBERT: Pretrained Contextualized Embeddings for Scientific Text(2019)"></a>SCIBERT: Pretrained Contextualized Embeddings for Scientific Text(2019)</h4><h5 id="一句话总结-2"><a href="#一句话总结-2" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>类似于BioBERT，建立方法是用Semantic Scholar的1.14M原文在BERT预训练，然后在多个领域的多种类型的任务数据集上做了精度测试</p><h5 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h5><ol><li><p>基于领域特定的文献语料库建立了新的WordPiece词汇库：SCIVOCAB，和原来BERT的BASEVOCAB作对比</p></li><li><p>加下游任务的方式是：</p><p>We apply a multilayer BiLSTM to token embeddings. For <strong>text classification</strong>, we apply a multilayer perceptron on the first and last BiLSTM states. For <strong>sequence tagging</strong>, we use a CRF on top of the BiLSTM, as done in (Ma and Hovy, 2016). For <strong>dependency parsing</strong> we use the biaffine attention model from Dozat and Manning (2017).  然后直接用预训练好的权重不加fine-tuning来预测精度</p></li></ol><h5 id="结果-2"><a href="#结果-2" class="headerlink" title="结果"></a>结果</h5><p>我们只关心生物医学类的</p><img src="/2019/07/12/文献阅读0712/5.png"><h4 id="Improving-Chemical-Named-Entity-Recognition-in-Patents-with-Contextualized-Word-Embeddings-2019"><a href="#Improving-Chemical-Named-Entity-Recognition-in-Patents-with-Contextualized-Word-Embeddings-2019" class="headerlink" title="Improving Chemical Named Entity Recognition in Patents with Contextualized Word Embeddings(2019)"></a>Improving Chemical Named Entity Recognition in Patents with Contextualized Word Embeddings(2019)</h4><p>将ELMo(利用语言模型获得的一个上下文相关的预训练表示)直接当做特征拼接到具体任务模型的词向量输入（不同于GPT和BERT这种微调的方法），识别化学专利中的实体。识别模型如图：</p><img src="/2019/07/12/文献阅读0712/6.png"><p>文章还证实了使用专门的化学专利词嵌入比PubMed-PMC-word2vec效果要好(废话)。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;阅读文献要紧跟前沿，不能闭门造车。生物医学nlp领域也随着ELMo, bert等Contextualized embedding的出现推陈出新，涌现了最前沿的几篇词向量、语言模型和预训练方法等的文章，这里按时间顺序做个记录慢慢补充。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0710</title>
    <link href="http://yoursite.com/2019/07/10/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0710/"/>
    <id>http://yoursite.com/2019/07/10/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0710/</id>
    <published>2019-07-10T01:15:45.000Z</published>
    <updated>2019-09-01T09:46:05.650Z</updated>
    
    <content type="html"><![CDATA[<p>之前一直没写到过用规则和领域字典做NER，还有NER后的normalization，这次补充一下。</p><a id="more"></a><h4 id="Learning-Named-Entity-Tagger-using-Domain-Specific-Dictionary-2018"><a href="#Learning-Named-Entity-Tagger-using-Domain-Specific-Dictionary-2018" class="headerlink" title="Learning Named Entity Tagger using Domain-Specific Dictionary(2018)"></a>Learning Named Entity Tagger using Domain-Specific Dictionary(2018)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>没有直接用dictionary作为features而是采用类似于RE中远程监督的方式产生大量数据集然后训练。去噪的方式有两种：一是在将原来的LSTM+CRF替换成revised fuzzy CRF处理多个可能标签的情况（其中标签是用词典匹配的），二是提出一个具有Tie or Break模式的新模型AutoNER预测产生输出</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li>Fuzzy-LSTM-CRF with Modified IOBES</li></ol><img src="/2019/07/10/文献阅读0710/1.png"><ol><li>AutoNER with “Tie or Break”：区别于BIOES，这里只关心相邻两个tokens之间的关系是连在一起还是分开的</li></ol><img src="/2019/07/10/文献阅读0710/2.png"><p>这样匹配的好处是可以更多的利用字符串匹配得到的信息：当一个entity被部分匹配的时候，其中部分正确的Tie信息得以被利用；当一个unigram entity被错误匹配的时候，Tie or Break部分并不会出错。而unigram entity正是字符串匹配中最容易匹配错误的部分。</p><h4 id="Recognizing-irregular-entities-in-biomedical-text-via-deep-neural-networks-2018"><a href="#Recognizing-irregular-entities-in-biomedical-text-via-deep-neural-networks-2018" class="headerlink" title="Recognizing irregular entities in biomedical text via deep neural networks(2018)"></a>Recognizing irregular entities in biomedical text via deep neural networks(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>提出一个NerOne模型，识别文献中带有不规则实体部分的规则实体（见下图）。在原来双向LSTM+CRF的基础上，通过计算最短依存路径确定是否应该加入一个分类子模块（另一个双向LSTM+CRF）来对不规则实体分类。</p><img src="/2019/07/10/文献阅读0710/3.png"><h4 id="A-Neural-Multi-Task-Learning-Framework-to-Jointly-Model-Medical-Named-Entity-Recognition-and-Normalization-2018"><a href="#A-Neural-Multi-Task-Learning-Framework-to-Jointly-Model-Medical-Named-Entity-Recognition-and-Normalization-2018" class="headerlink" title="A Neural Multi-Task Learning Framework to Jointly Model Medical Named Entity Recognition and Normalization(2018)"></a>A Neural Multi-Task Learning Framework to Jointly Model Medical Named Entity Recognition and Normalization(2018)</h4><h5 id="一句话总结-2"><a href="#一句话总结-2" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>提出一个新颖的多任务神经网络框架同时做NER和NEN，通过建立NER和NEN的反馈机制将逐级任务转为并行任务(也就是多任务共享权重)</p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><p>模型如图，base还是char CNN+BiLSTM+CRF，然后引入平行的NER和NEN任务作输出，然后互相反馈</p><img src="/2019/07/10/文献阅读0710/4.png"><p>反馈机制计算式如下：</p><img src="/2019/07/10/文献阅读0710/5.png"><h4 id><a href="#" class="headerlink" title=" "></a> </h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前一直没写到过用规则和领域字典做NER，还有NER后的normalization，这次补充一下。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0709</title>
    <link href="http://yoursite.com/2019/07/09/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0709/"/>
    <id>http://yoursite.com/2019/07/09/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0709/</id>
    <published>2019-07-09T10:12:41.000Z</published>
    <updated>2019-09-01T07:43:05.200Z</updated>
    
    <content type="html"><![CDATA[<p>今天读了几篇词向量和预训练模型的文献，简单记一下。</p><a id="more"></a><h4 id="How-to-Train-Good-Word-Embeddings-for-Biomedical-NLP-2016"><a href="#How-to-Train-Good-Word-Embeddings-for-Biomedical-NLP-2016" class="headerlink" title="How to Train Good Word Embeddings for Biomedical NLP(2016)"></a>How to Train Good Word Embeddings for Biomedical NLP(2016)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>这篇文章研究了用word2vec训练生物医学领域词向量时，训练数据集、模型结构和高阶参数对词向量质量的影响。评估方法用到了内部评估（单词相似测度）和外部评估（两个NER数据集）。</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li>数据集大小的影响：选用了三种：PubMed数据集，PMC数据集，PubMed+PMC数据集，发现更大的数据集不一定能训练出更好的词向量，效果最好的是PubMed</li><li>模型结构：对比了skip-gram（当前词预测上下文）和CBOW，发现skip-gram训练出来的要好一些</li><li>6个高阶参数：negative sampling（对当前词随机采样N个负例进行预测），Subsampling(去除频率高的词的共现)，min-count(最低出现的频数），学习率，词向量维度，上下文的词窗大小。</li><li>内部评估：UMNSRS单词相似度数据集，对出现的单词对，用模型计算余弦相似度然后再计算相关系数</li><li>外部评估：用训练好的词嵌入向量加简单的前馈神经网络做下游NER任务，不做fine-tuning</li></ol><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>具体参数的调整对结果的影响就不放上来了，最终选择的最佳参数和对应的精度如图。选这篇文章主要是之前看好多NER文献都在词向量部分提到这篇调参的启发，不过想不明白为什么还是每次都用词向量wikipedia-pubmed-and-PMC-w2v而不是这篇测试效果最好的wikipedia-PubMed，可能fine-tuning后效果提升更明显吧</p><img src="/2019/07/09/文献阅读0709/1.png" title="最佳参数和相应的精度"><h4 id="A-Comparison-of-Word-Embeddings-for-the-Biomedical-Natural-Language-Processing-2018"><a href="#A-Comparison-of-Word-Embeddings-for-the-Biomedical-Natural-Language-Processing-2018" class="headerlink" title="A Comparison of Word Embeddings for the Biomedical Natural Language Processing(2018)"></a>A Comparison of Word Embeddings for the Biomedical Natural Language Processing(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>评估了从四种数据源（电子医疗、PubMed、Wikipedia、Google news）训练的词向量在运用到内部评估和外部下游任务(临床信息提取，生物医学信息提取，关系抽取)时的表现，发现没有通用的提高生物医学下游nlp任务的词嵌入模型。</p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><ol><li>内部评估使用的相似性测度的方式是：选择三个类别（disorder, symptom, drug）的目标词汇，从四种词向量中取出5个最相关的词，结果显然是用电子医疗和PubMed训练的词向量要好过Wikipedia和Google news；还有选择377个语义相关的词对，用四种词向量表示，观察词簇的密集程度，用相似性测度衡量（UMNSRS）</li><li>外部评估分三部分<ul><li>Clinical Information Extraction：检测骨折信息数据集；i2b2吸烟状态数据集。结果是通用词向量效果不一定比相关领域训练的词向量差</li><li>Biomedical Information Retrieval：提供医疗决策信息。结果是四种词向量几乎都无精度提升</li><li>drug-drug interaction (DDI) extraction：Google News词向量效果最好(虽然都差不多但还是很神奇)</li></ul></li></ol><h4 id="Comparing-CNN-and-LSTM-character-level-embeddings-in-BiLSTM-CRF-models-for-chemical-and-disease-named-entity-recognition-2018"><a href="#Comparing-CNN-and-LSTM-character-level-embeddings-in-BiLSTM-CRF-models-for-chemical-and-disease-named-entity-recognition-2018" class="headerlink" title="Comparing CNN and LSTM character-level embeddings in BiLSTM-CRF models for chemical and disease named entity recognition(2018)"></a>Comparing CNN and LSTM character-level embeddings in BiLSTM-CRF models for chemical and disease named entity recognition(2018)</h4><h5 id="一句话总结-2"><a href="#一句话总结-2" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>比较了同样的BiLSTM+CRF模型用char-CNN和char-bilstm对CDNER的影响，发现无太大差别不过CNN可以显著降低模型复杂度明显提高计算效率。</p><p>接着介绍一下NCBI NIH的几个词向量工作。</p><h4 id="BioWordVec-improving-biomedical-word-embeddings-with-subword-information-and-MeSH-2018"><a href="#BioWordVec-improving-biomedical-word-embeddings-with-subword-information-and-MeSH-2018" class="headerlink" title="BioWordVec, improving biomedical word embeddings with subword information and MeSH(2018)"></a>BioWordVec, improving biomedical word embeddings with subword information and MeSH(2018)</h4><h5 id="一句话总结-3"><a href="#一句话总结-3" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>传统直接用领域相关的语料训练词向量如word2vec或者glove，即使glove是context相关的能解决一词多义问题，但也还是没有利用到文本内部的结构信息，本文用MeSH条款提供subword信息，能够有效增加OOV的词嵌入表示，极大提升词嵌入性能。</p><h5 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/09/文献阅读0709/2.png"><ol><li>采样MeSH条款序列：利用随机游走采样算法node2vec把用RDF构建的MeSH术语图转换成有序的术语序列，然后再把对应的id转成单词，这样链表就转成了具有语义关系的类似于句子的有向单词序列。</li><li>子词嵌入模型：在统一的字符嵌入空间中学习文本序列和MeSH术语序列，也就是同时用PubMed和MeSH训练n-grams。用了类似于CBOW模型的fastText算法，学习分布式的字符表示，然后每个单词的词向量是这些n-grams的组合和原Vc的点乘，训练方式也类似于word2vec，只不过是训练字符，优化损失函数也是两个skip-gram损失函数的叠加。</li></ol><h5 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h5><img src="/2019/07/09/文献阅读0709/3.png"><h5 id="应用案例"><a href="#应用案例" class="headerlink" title="应用案例"></a>应用案例</h5><ol><li>句子对间相似度计算：多采用将句子中的每个单词转换为词向量然后平均求相似度</li><li><strong>生物医学关系抽取</strong>：这是我关注的重点。文章在二元关系PPI和多元关系DDI上做了测试，采用带dropout的CNN模型，还有复杂的RNN模型测试，均取得了最高的F-score。但在RNN上精度提升不明显，可能是SOTA的RNN模型是集成了最短路径依赖信息和POS嵌入的多层双向LSTM，降低了词嵌入层的重要性。</li></ol><img src="/2019/07/09/文献阅读0709/4.png" title="DDI 2013提取结果对比"><h4 id="BioSentVec-creating-sentence-embeddings-for-biomedical-texts-2018"><a href="#BioSentVec-creating-sentence-embeddings-for-biomedical-texts-2018" class="headerlink" title="BioSentVec: creating sentence embeddings for biomedical texts(2018)"></a>BioSentVec: creating sentence embeddings for biomedical texts(2018)</h4><h5 id="一句话总结-4"><a href="#一句话总结-4" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>使用PubMed和MIMIC-III临床数据库类似于CBOW模型训练sent2vec，能在给定任意句子作为输入的情况下生成句子向量，能在高维空间中更好表征语义信息。在句子相似性和多标签句子分类数据集上做了测试。</p><img src="/2019/07/09/文献阅读0709/5.png" title="在句子分类数据集上采用的模型和精度"><h4 id="Transfer-Learning-in-Biomedical-Natural-Language-Processing-An-Evaluation-of-BERT-and-ELMo-on-Ten-Benchmarking-Datasets-2019"><a href="#Transfer-Learning-in-Biomedical-Natural-Language-Processing-An-Evaluation-of-BERT-and-ELMo-on-Ten-Benchmarking-Datasets-2019" class="headerlink" title="Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets(2019)"></a>Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets(2019)</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天读了几篇词向量和预训练模型的文献，简单记一下。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0708</title>
    <link href="http://yoursite.com/2019/07/08/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0708/"/>
    <id>http://yoursite.com/2019/07/08/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0708/</id>
    <published>2019-07-08T02:36:16.000Z</published>
    <updated>2019-09-02T08:46:22.420Z</updated>
    
    <content type="html"><![CDATA[<p>上篇主要是用多任务学习做NER的文献，这次关注一下迁移学习。正文如下：</p> <a id="more"></a><h4 id="Transfer-learning-for-biomedical-named-entity-recognition-with-neural-networks-2018"><a href="#Transfer-learning-for-biomedical-named-entity-recognition-with-neural-networks-2018" class="headerlink" title="Transfer learning for biomedical named entity recognition with neural networks(2018)"></a>Transfer learning for biomedical named entity recognition with neural networks(2018)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>深度学习大量依赖金标准数据集GSCs，带噪声的银标准数据集SSCs能够用于迁移学习弥补金标准数据集较少的情况，目标数据集越小迁移带来的精度提高越明显，目标GSC数据集较大时反而可能会恶化精度。<a href="https://github.com/BaderLab/Transfer-Learning-BNER-Bioinformatics-2018/" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><p>迁移学习的原理就是在”source”数据集上学到的知识能够帮助提高”target”数据集的表现，提高泛化能力，减少训练次数，模型本身baseline用的是<a href="https://github.com/Franck-Dernoncourt/NeuroNER" target="_blank" rel="noopener">neuroner</a>，一个BiLSTM字符嵌入+BiLSTM词嵌入+CRF的网络，注意一点就是训练时要从银标准数据集中剔除那些出现在金标准数据集中的PubMed ID。</p><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>在23个金标准数据集上与baseline相比平均误差降低了11％</p><h4 id="Effective-Use-of-Bidirectional-Language-Modeling-for-Transfer-Learning-in-Biomedical-Named-Entity-Recognition-2018"><a href="#Effective-Use-of-Bidirectional-Language-Modeling-for-Transfer-Learning-in-Biomedical-Named-Entity-Recognition-2018" class="headerlink" title="Effective Use of Bidirectional Language Modeling for Transfer Learning in Biomedical Named Entity Recognition(2018)"></a>Effective Use of Bidirectional Language Modeling for Transfer Learning in Biomedical Named Entity Recognition(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>在无标签数据上运用双向语言模型来预训练初始化模型权重，对金标准数据NER做迁移学习来提高精度。</p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><p>基本模型也是char-textCNN+word-BiLSTM+CRF，对每套数据集，用training和validation训练双向语言模型，双向语言模型的训练方法是最小化前后语言模型的平均交叉熵CElm = −λ(log pf (w1:n) + log pb(wn:1))。然后在此权重参数基础上训练NER模型微调，得到decoder CRF的参数。</p><h5 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h5><img src="/2019/07/08/文献阅读0708/1.png" title="4个数据集上的效果提升"><p>效果比之前那个多任务学习的精度要好，而且只针对当前数据集训练，没有用到别的数据集信息。最后还绘制了learning curve曲线展示了无论target数据集有多大，都能带来精度的提升。</p><h4 id="Towards-reliable-named-entity-recognition-in-the-biomedical-domain-2019"><a href="#Towards-reliable-named-entity-recognition-in-the-biomedical-domain-2019" class="headerlink" title="Towards reliable named entity recognition in the biomedical domain(2019)"></a>Towards reliable named entity recognition in the biomedical domain(2019)</h4><h5 id="一句话总结-2"><a href="#一句话总结-2" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>一个很大的问题是在金标准数据集训练好的NER模型很难泛化到其他数据集上（主要还是训练数据太少了），更别说直接用到生物医学非结构化文本抽取了。这篇文章用了几个方法来improve regularization，包括Variational Dropout、多任务学习和迁移学习，然后综合这些模型的优点开源了一个Python工具包。<a href="https://github.com/BaderLab/saber" target="_blank" rel="noopener">工具地址</a>  <a href="https://github.com/BaderLab/Towards-reliable-BioNER" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h5><ol><li><p>Variational Dropout：文章说之前的模型用dropout主要是在字符嵌入层和词嵌入层的参数上，很少有用到LSTM层的？？？没有啊我之前看的都用在了LSTM层。但确实LSTM层的dropout不太一样，因为直接使用会损害RNNs对文本的长距离依赖性。而2016年提出的variational dropout能够解决这一问题。因为它不是在每个time step都随机丢弃一些单元，而是在跨多个time steps丢弃相同的单元(因为LSTM是按照时间序列展开的，最终dropout会作用在同一层的连续位置，如图显示相同颜色的线代表在整个序列使用相同的dropout mask。我理解的就是有的一整个输入句子整个都被dropout，有的整个句子都不dropout，这样可以保证连续性)</p><img src="/2019/07/08/文献阅读0708/2.png" title="Naive dropout v.s. variational dropout"></li><li><p>迁移学习：同最上面那篇，用的数据集也是CALBC-SSC-III</p></li><li><p>多任务学习：用的是共享权重的方法，target-specific CRF前的所有字符层和单词层的隐层单元都共享权重，然后每个数据集计算各自的损失并优化，当所有的数据集都训练一遍（顺序随机，总共需要二项式系数次）算一个epoch。为什么没用之前那篇多任务文章提到的优化总的损失函数我也不知道，可能分别计算效果好吧。</p></li></ol><h5 id="结果-2"><a href="#结果-2" class="headerlink" title="结果"></a>结果</h5><p>文章花大量篇幅展示了baseline+VD，baseline+TL，MTL模型与baseline相比在In-corpus (IC) performance和Out-of-corpus (OOC) performance的效果提升，并分析了这些方法对提高泛化能力的作用。最后总结了OOC相比IC平均会减少31.16%的精度，加上这些方法的作用能够平均挽回10％的精度。开源的模型对用在PubMed大规模文本抽取有效。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上篇主要是用多任务学习做NER的文献，这次关注一下迁移学习。正文如下：&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文献阅读0706</title>
    <link href="http://yoursite.com/2019/07/06/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0706/"/>
    <id>http://yoursite.com/2019/07/06/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB0706/</id>
    <published>2019-07-06T01:52:00.000Z</published>
    <updated>2019-09-02T08:46:07.860Z</updated>
    
    <content type="html"><![CDATA[<p>受<a href="https://github.com/BrambleXu/knowledge-graph-learning" target="_blank" rel="noopener">awesome-knowledge-graph</a>这个项目的启发，看到自己项目里也存了大概一百篇文献，所以决定在博客记录下每天看过的文献，其中一部分是之前看过的，不过模型没有上手很容易忘记，所以算是重看整理，主要是想督促自己多写点东西。</p><a id="more"></a><h4 id="A-neural-network-multi-task-learning-approach-to-biomedical-named-entity-recognition-2016"><a href="#A-neural-network-multi-task-learning-approach-to-biomedical-named-entity-recognition-2016" class="headerlink" title="A neural network multi-task learning approach to biomedical named entity recognition(2016)"></a>A neural network multi-task learning approach to biomedical named entity recognition(2016)</h4><h5 id="一句话总结"><a href="#一句话总结" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>生物医学领域命名实体识别的金标准数据集量少，数据集间具有高度相关性但标注的又是不同的内容(Anatomy, Chemical, Disease, Gene/Protein and Species, Cell Type)，一个自然的思路是能否利用多任务学习提高NER精度，文章以卷积神经网络为基础构建了单任务模型和两个多任务模型验证了这一点。<a href="https://github.com/cambridgeltl/MTL-Bioinformatics-2016" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li><p>预训练词嵌入向量：用的是<a href="http://bio.nlplab.org" target="_blank" rel="noopener">wikipedia-pubmed-and-PMC-w2v</a>，注意OOV的处理</p></li><li><p>数据集：整合了15个ner数据集（包括BIO和BIOES两种格式）和1个GENIA-PoS-Tagging数据集</p></li><li><p>Baseline model ：全连接前馈神经网络，隐层大小300，激活函数ReLU，输出用Softmax分类，单个输入长度大小为7，batch-size 50，SGD优化</p></li><li><p>三个CNN模型：</p><img src="/2019/07/06/文献阅读0706/2.png" title="从左到右：单任务模型、多输出多任务模型、从属多任务模型"><ul><li><p>Single task model：高度为3、4、5各100个卷积核对长度为7的词窗做卷积，卷积核宽度等于词嵌入维度，为了保留位置信息没有用最大池化，卷积层到全连接层激活函数也是relu，多分类交叉熵损失函数，mini-batch 200，Adam优化，学习率1e-4，全连接层dropout 0.75</p></li><li><p>Multi-output multi-task model：共享前面的词嵌入和卷积层，后面的全连接和softmax随任务类型不同</p></li><li><p>Dependent multi-task model：NER任务运用POS信息，前面的CNN层分开训练，然后拼接后面的全连接层用来预测ner输出</p></li></ul></li></ol><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>如图：多输出模型能够对原single模型产生较大影响(多数是效果改进，少数会效果变差)，dependent模型对single模型带来的精度提高不如多输出，但整体趋势都是稍微改进无恶化的(至少是无实质变化)，也证明了我们的预期——具有相关关系的数据集用于多任务模型中共享输入特征和权重，结果不一定会相互促进，而从属模型大多能利用辅助数据集的信息来提升精度虽然效果可能不明显。<br><img src="/2019/07/06/文献阅读0706/3.png" title="F-score比较"></p><p>这篇多任务模型/迁移学习可以改进的地方还有很多：比如单任务模型换成BiLSTM+CRF；多任务思路也可以变化：从共享权重变为协同训练；从迁移模型到迁移数据。。。这就引出接下来很多篇文章：</p><h4 id="Cross-type-Biomedical-Named-Entity-Recognition-with-Deep-Multi-Task-Learning-2018"><a href="#Cross-type-Biomedical-Named-Entity-Recognition-with-Deep-Multi-Task-Learning-2018" class="headerlink" title="Cross-type Biomedical Named Entity Recognition with Deep Multi-Task Learning(2018)"></a>Cross-type Biomedical Named Entity Recognition with Deep Multi-Task Learning(2018)</h4><h5 id="一句话总结-1"><a href="#一句话总结-1" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>双向LSTM+CRF网络通过共享字符和单词级别的嵌入层参数来提高NER精度。<a href="https://github.com/yuzhimanhua/Multi-BioNER" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><img src="/2019/07/06/文献阅读0706/7.png" title="三种共享参数层的方式"><p>创新点是提出了三种共享参数层权重的方式来优化总的损失函数</p><img src="/2019/07/06/文献阅读0706/8.png" title="The loss function L"><p>还使用了CTD的单词信息作补充，用在两个地方：一是充当dictionary feature提供N-gram信息（结果并没有带来精度提高），二是用于后处理匹配那些被预测为O-label的单词，从而降低FN值(被预测为负的正样本)，但最后结果反而变差了，因为大大提高了FP值（有些单词表面和词典一样但是意思不同）。</p><h5 id="训练参数设置"><a href="#训练参数设置" class="headerlink" title="训练参数设置"></a>训练参数设置</h5><p>词嵌入200维，字符嵌入30维，两个双向LSTM隐藏层都是200，初始学习率0.01，其他大部分参数都和Neural architectures for named entity recognition这篇文章一样</p><h5 id="可以考虑改进的地方"><a href="#可以考虑改进的地方" class="headerlink" title="可以考虑改进的地方"></a>可以考虑改进的地方</h5><p>没有经过normalization所以很难判断预测的实体边界；虽然是一起训练的但对每个数据集都会学习得到一个模型，然后预测原始文本的时候是这些模型分别预测生成各自的预测结果，很容易造成冲突。</p><h4 id="CollaboNet-collaboration-of-deep-neural-networks-for-biomedical-named-entity-recognition-2018"><a href="#CollaboNet-collaboration-of-deep-neural-networks-for-biomedical-named-entity-recognition-2018" class="headerlink" title="CollaboNet: collaboration of deep neural networks for biomedical named entity recognition(2018)"></a>CollaboNet: collaboration of deep neural networks for biomedical named entity recognition(2018)</h4><h5 id="一句话总结-2"><a href="#一句话总结-2" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>在不同数据集上训练好的模型轮流充当主任务模型，其他数据集作为辅助模型来训练，这样协同训练来整体降低多义词的误分类，降低FP值。<a href="https://github.com/wonjininfo/CollaboNet" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h5><ol><li><img src="/2019/07/06/文献阅读0706/9.png"><p>单任务模型结构如图，和前一篇文章不同的地方是在Character Level Word Embedding (CLWE)层用的是text-CNN而不是Bi-LSTM，用dclwe个卷积核捕获窗口为k的字符（经最大池化），得到dclwe维的字符嵌入向量，然后和词向量拼接在一起作为双向LSTM-CRF的输入。</p><p>整个过程的公式如下图左侧所示(因为推导的比较清晰所以都列出来了)：</p><img src="/2019/07/06/文献阅读0706/10.png"></li><li><p>多任务模型结构如上图右，训练方式为：P0 Phase先把各数据集上的单个模型都训练一遍，在Pn phase，训练target模型时，将target模型的数据集和前一phase其他模型在target数据集上训练的输出加权合并做输入，用来训练前一phase的target模型，得到当前时刻的target输出。</p></li></ol><h5 id="训练参数设置-1"><a href="#训练参数设置-1" class="headerlink" title="训练参数设置"></a>训练参数设置</h5><p>词嵌入200维，字符向量初始化30维，然后采用3、5、7的卷积核各200个，所以得到字符嵌入维度200*3，拼接后经过前后各300维的LSTM，mini-batch为10，dropout分别是(CLWE)0.5和(BiLSTM)0.3，初始学习率0.01</p><h5 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h5><img src="/2019/07/06/文献阅读0706/11.png"><p>在相关数据集上取得了比上一篇文章更高的F值</p><h4 id="An-attention-based-BiLSTM-CRF-approach-to-document-level-chemical-named-entity-recognition-2017"><a href="#An-attention-based-BiLSTM-CRF-approach-to-document-level-chemical-named-entity-recognition-2017" class="headerlink" title="An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition(2017)"></a>An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition(2017)</h4><h5 id="一句话总结-3"><a href="#一句话总结-3" class="headerlink" title="一句话总结"></a>一句话总结</h5><p>传统神经网络NER是基于句子级别的标注，容易造成同一文档不同句子间标注不一致性的问题，通常需要在后处理时加规则强行统一。本文提出了一个基于注意力机制的双向LSTM+CRF网络，能够实现文档级别的标注，在BC4CHEMDNER和BC5CDR数据集上都取得了SOTA的结果。<a href="https://github.com/lingluodlut/Att-ChemdNER" target="_blank" rel="noopener">项目地址</a></p><h5 id="方法-3"><a href="#方法-3" class="headerlink" title="方法"></a>方法</h5><ol><li><p>input features：word embedding and character embedding作为基本，POS, chunking and dictionary embedding作额外补充。word embedding是用查询”chemical”关键词得到的文献在word2vec基础上训练的（很具有启发性）；POS和chunking是用GENIA tagger获得的；dictionary embedding是用化学词典（Jochem，ChEBI和CTD）匹配实体得到的。</p></li><li><p>基础的BiLSTM-CRF模型和改进的Att-BiLSTM-CRF模型：</p><img src="/2019/07/06/文献阅读0706/4.png"><p>双向LSTM层能够捕获序列的当前输入时刻上下文相关的信息；然后经过一个注意力层，用global vector捕获LSTM的输出加权，attention层的权重计算用了四种：曼哈顿距离、欧几里得距离、余弦相似度和感知机tanh(Wa[Xt;Xj])，attention 层的输出是global vector和LSTM输出状态向量的拼接然后通过一个tanh激活函数得到的，即Zt = tanh(Wg[gt;ht])，Zt然后再经一个tanh输出即tanh(WeZt)；CRF层是在输出概率矩阵上增加了状态转移矩阵建立隐藏状态的依赖，最终CRF输出也是经softmax用分类交叉熵计算损失，然后维特比算法递推优化。</p></li></ol><h5 id="训练参数设置-2"><a href="#训练参数设置-2" class="headerlink" title="训练参数设置"></a>训练参数设置</h5><img src="/2019/07/06/文献阅读0706/5.png"><h5 id="结果-2"><a href="#结果-2" class="headerlink" title="结果"></a>结果</h5><img src="/2019/07/06/文献阅读0706/6.png"><p>加入了额外特征的模型在两个数据集上都达到了SOTA的效果，优于NCBI的taggerone</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;受&lt;a href=&quot;https://github.com/BrambleXu/knowledge-graph-learning&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;awesome-knowledge-graph&lt;/a&gt;这个项目的启发，看到自己项目里也存了大概一百篇文献，所以决定在博客记录下每天看过的文献，其中一部分是之前看过的，不过模型没有上手很容易忘记，所以算是重看整理，主要是想督促自己多写点东西。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>脑空间信息知识图谱技术</title>
    <link href="http://yoursite.com/2019/05/08/%E8%84%91%E7%A9%BA%E9%97%B4%E4%BF%A1%E6%81%AF%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/"/>
    <id>http://yoursite.com/2019/05/08/%E8%84%91%E7%A9%BA%E9%97%B4%E4%BF%A1%E6%81%AF%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/</id>
    <published>2019-05-08T06:53:15.000Z</published>
    <updated>2019-07-30T03:23:26.880Z</updated>
    
    <content type="html"><![CDATA[<p>因为马上去上海开会交流还要做PPT展示，所以先写篇文章总结下目前这个项目我能实现的技术和卡住的地方，也算是对入手这个项目一年多的技术总结。</p><p>脑空间信息学是以脑连接的基本结构与功能单元为研究对象，揭示脑连接空间信息机制，引导脑疾病防治与智能技术发展的新兴交叉学科。脑空间信息知识库能够为研究认知和行为的神经活动机制等脑科学问题提供帮助。由于脑科学的研究范围涵盖面广，领域跨度大，研究人员很难具有跨自身专业的知识；此外脑科学领域的文献数目逐年剧增，了解并跟进前沿知识费时费力，催生了自动化获取文献信息的需求。项目目标是综合运用文本挖掘、自然语言处理和机器学习技术，建立一个服务脑科学研究人员，整合已有的知识库，能实现文献语义级别搜索的知识图谱。</p><p>知识图谱的构建流程大致是知识抽取、知识融合、知识加工、知识存储和知识表示。我的工作主要是前面的知识抽取和知识融合中的技术细节，主要做了文献挖掘、实体抽取和消歧、关系/事件抽取、知识库和本体整合等内容。详细如下：</p> <a id="more"></a><ol><li><p>文献获取和预处理</p><ul><li>以E-utilities向PubMed发送查询并下载文献，以关键词核团”nucleus accumbens”为例，共下载19572篇摘要，以txt的格式返回它们的，标识符pmids</li><li>使用StanfordNLP进行文本清洗：包括分词、过滤字符、去除停用词、词干化处理、词性标注等</li><li>统计词频、语言模型、tf-idf等</li></ul><p>遇到的问题及难点：PMC全文的获取有困难，缺少文献数据库</p></li><li><p>知识抽取</p><img src="/2019/05/08/脑空间信息知识图谱技术/1.png"><p>知识抽取根据不同的数据源分别进行，我们主要针对的是文献中的纯文本数据。三个子任务包括：</p><ul><li>实体抽取：识别文本中有意义的实体，通常是名词</li><li>关系抽取：SPO三元组，事件抽取相当于多元关系的抽取</li><li>属性抽取：三元组中一个谓词和两个形参各自的属性，也可以简化为关系抽取</li></ul><p>实体抽取：</p><p>采用端到端的深度学习算法，基于多任务学习的双向LSTM+CRF网络，采用的训练数据集为CoNLL格式的金标准生物医学NER数据集，该系统能够识别基因、蛋白质、细胞类型、化学物质、疾病实体。</p><p>模型和训练数据集详细信息如图：</p><img src="/2019/05/08/脑空间信息知识图谱技术/2.png"><img src="/2019/05/08/脑空间信息知识图谱技术/3.png"><p>目前识别出的结果如下：</p><img src="/2019/05/08/脑空间信息知识图谱技术/6.png"><p>后期准备整合Pubtator和UMLS对识别出来的实体按照实体类型和MESH条款进行管控。</p><p>遇到的问题及难点：</p><ul><li>难以识别出脑区核团、神经元等一些金标准训练集中未标定出来的实体类型。</li><li>金标准训练集的数量太少，训练模型易欠拟合，泛化能力差，难以对大量的文献文本做实体预测，且难以对预测结果的精确度进行定量评估。</li></ul><p>关系抽取：</p><p>同样是基于端到端的方法，模型是加入自注意力机制的双向LSTM网络，主要抽取的是基因-化学物质-疾病这三者相互之间的关系。</p><p>模型和训练数据集详细信息如图：</p><img src="/2019/05/08/脑空间信息知识图谱技术/7.png"><img src="/2019/05/08/脑空间信息知识图谱技术/8.png"><p>目前的训练精度很差，准备加入句法依存树解决句法依赖的问题，还有配合生物医学本体建立层级间的关联，加入远程监督和多实例学习解决训练样本太少的问题。</p><p>遇到的问题及难点：</p><ul><li>关系抽取难度大，主流的最好的模型精度也只有60-70％</li><li>划定关系类型没有统一的标准，严重依赖本体层级的划分，需要神经科学背景的研究人员提供指导</li><li>关系抽取得到的结果中包含的主语和宾语实体需要与实体抽取的结果匹配，可以考虑采用联合模型同时抽取实体和它们间的关系。</li></ul></li><li><p>知识融合</p><p>主要做了SemMedDB关系数据库(NIH抽取PubMed摘要得到的9400多万个关系)与本体层面的融合。</p><p>采用的本体是biolink，是一个以节点、边、槽表示生物医学实体和关系的本体层架构。SemMedDB数据库以MySQL的形式存储，先将其通过UMLS进行规范化，然后用biolink在模式层管理这些关系。</p><p>遇到的问题及难点：</p><ul><li>原SemMedDB是采用SemRep系统抽取，它的精确度、召回率和F值分别为 0.73, 0.55, 0.63</li></ul></li></ol><ul><li>由于精确度较低，所以需要先过滤总共只出现很少次的关系类型，在次数的选择上也需要折中考虑关系的误判和漏判<ul><li>由于系统只能做到抽取单个句子中的实体间的关系，很难抽取到跨句子级别的关系，所以召回率很低，但是PubMed摘要中的很多关系只出现在整个文档级别中</li></ul></li><li>biolink并不一定是最适合我们的生物医学本体，需要内部专家修改和评估。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;因为马上去上海开会交流还要做PPT展示，所以先写篇文章总结下目前这个项目我能实现的技术和卡住的地方，也算是对入手这个项目一年多的技术总结。&lt;/p&gt;
&lt;p&gt;脑空间信息学是以脑连接的基本结构与功能单元为研究对象，揭示脑连接空间信息机制，引导脑疾病防治与智能技术发展的新兴交叉学科。脑空间信息知识库能够为研究认知和行为的神经活动机制等脑科学问题提供帮助。由于脑科学的研究范围涵盖面广，领域跨度大，研究人员很难具有跨自身专业的知识；此外脑科学领域的文献数目逐年剧增，了解并跟进前沿知识费时费力，催生了自动化获取文献信息的需求。项目目标是综合运用文本挖掘、自然语言处理和机器学习技术，建立一个服务脑科学研究人员，整合已有的知识库，能实现文献语义级别搜索的知识图谱。&lt;/p&gt;
&lt;p&gt;知识图谱的构建流程大致是知识抽取、知识融合、知识加工、知识存储和知识表示。我的工作主要是前面的知识抽取和知识融合中的技术细节，主要做了文献挖掘、实体抽取和消歧、关系/事件抽取、知识库和本体整合等内容。详细如下：&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>SemMedDB2Biolink：PubMed语义数据的规范和展示</title>
    <link href="http://yoursite.com/2019/04/20/SemMedDB2Biolink%EF%BC%9APubMed%E8%AF%AD%E4%B9%89%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A7%84%E8%8C%83%E5%92%8C%E5%B1%95%E7%A4%BA/"/>
    <id>http://yoursite.com/2019/04/20/SemMedDB2Biolink%EF%BC%9APubMed%E8%AF%AD%E4%B9%89%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A7%84%E8%8C%83%E5%92%8C%E5%B1%95%E7%A4%BA/</id>
    <published>2019-04-20T01:39:18.000Z</published>
    <updated>2019-07-30T07:58:44.660Z</updated>
    
    <content type="html"><![CDATA[<p>这个月的工作是对SemMedDB与Biolink Model的初探和尝试。SemMedDB(The Semantic MEDLINE Database)是一个以SPO三元组存储了PubMed中文本语义关系的数据库，大概有9400万条预测关系。而Biolink Model是一个高级别的生物医学实体和关系框架。通过把SemMedDB的关系型数据用Biolink Model规范与展示，可以实现更广泛的生物医学知识推理和运用。转换过程中还用到了一体化医学语言系统UMLS的术语映射。正文如下：</p> <a id="more"></a><p>生物医学领域文献繁多，隐藏的语义信息庞大而繁杂，如何通过文献挖掘为生物医学研究人员提取一些常识性的论断，还有如何高效地在文献中找到自己所需要的关键信息是知识库构建的初衷。PubMed提供了NLM的MEDLINE数据库千万篇文献摘要和索引信息，而SemMedDB是NLM用SemRep系统抽取PubMed语义信息得到的数据库，核心是近1亿条以主语-谓语-宾语的形式存储的生物医学关系表，存储在MySQL数据库里，模式scheme如下：</p><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/1.png" title="PREDICATION table of SemMedDB"><p>主语信息以SUBJECT_NAME, SUBJECT_CUI（概念标识符）, SUBJECT_SEMTYPE和SUBJECT_NOVELTY管控，谓语信息是PREDICATE表示的，宾语信息同主语信息，并提供了出现该语义关系的PubMed文献的PMID值及出现的句子位置。</p><p>SemMedDB的实体概念是以UMLS管控的，UMLS全称统一医学语言系统，它的元叙事表是由各种受控词表和术语以及它们之间的关系所构成的集合，包括医学主题词MeSH等，是生物医学信息的规范。</p><p>Biolink模型是生物医学实体和关系的本体层架构，它以节点、边和槽定义模式，节点代表实体；边就是实体间的关系；槽分为节点属性、边属性和关系类型。如图是用本体软件protege展示的节点层：</p><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/2.png" title="Entity (Node) Types"><p>它是一个更高层管理数据的方式，类似于用RDF或OWL描述的本体层，如图：</p><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/3.jpg" title="PREDICATION table of SemMedDB"><p>我的思路是将SemMedDB提供的生物医学关系与Biolink模型的模式建立映射关系，从而可以用SparQL实现语义级别的查询，还有用图数据库Neo4j展示。</p><p>分为如下几部实现：</p><ol><li>原始数据清洗</li><li>使用biolink对实体类型规范化</li><li>依实体类型过滤关系类型</li><li>限定领域范围，依照本体修改mapping</li><li>关联外部数据库</li><li>用Neo4j图数据库展示</li></ol><p>下面依次介绍：</p><ol><li><p>原始数据清洗：</p><p>首先提取SemMedDB数据库的生物医学关系，其中’SUBJECT_CUI’, ‘PREDICATE’, ‘OBJECT_CUI’, ‘PMID’这几项内容是我需要的。然后将含有同一SPO三元组的PMID值合并；加入NEG一列指示关系类型为positive或negative，处理后将其保存为关系数据表。</p><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/4.png" title="SemMedDB ——> 关系表：22,280,924条关系"><p>实体数据表则是由UMLS的受控词表MRCONSO_ENG.RRF清洗得到。其中的ID值对应SemMedDB的SUBJECT_CUI或OBJECT_CUI，label是ID对应的实体名称。</p><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/5.png" title="UMLS ——> 实体表：259,227个实体"></li><li><p>使用biolink对实体类型规范化：</p><p>这一步按照biolink模型的框架描述过滤了实体表。首先在实体表中加入实体的类型值umls_type，这是从UMLS的另一张受控词表MRSTY.RRF得到的。然后将umls_type映射到biolink本体的node_type，实现实体类型的规范化。剔除了不含有node_type的节点。</p><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/6.png" title="映射后的实体表"><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/7.png" title="用biolink的node_type过滤后的实体类型排序"></li><li><p>过滤实体类型和关系类型：</p><p>这一步用上一步过滤好的实体类型和biolink模型自身的关系类型过滤第一步存储的边表。移除了不含有UMLS类型的主语或宾语构成的SPO三元组关系，移除了[‘compared_with’, ‘higher_than’, ‘lower_than’, ‘different_from’, ‘different_than’, ‘same_as’,’OCCURS_IN’, ‘PROCESS_OF’, ‘DIAGNOSES’, ‘METHOD_OF’, ‘USES’,’AUGMENTS’, ‘ADMINISTERED_TO’, ‘COMPLICATES’]这些biolink模型不含有的关系，再用筛选后的关系表反过来过滤实体表。这一步后剩余165,765个实体和14,066,229条关系。</p><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/8.png" title="过滤后的关系类型数目排序"></li><li><p>限定领域范围，依照本体修改mapping：</p><p>先在关系表中加入关系的领域domain和范围range，如图：</p><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/9.png" title="修改后的关系表"><p>然后依照领域和范围，用自定义的知识库对预测领域范围做限定，根据自己本体修改mapping文件，这一步实现了本体层和数据层的融合，即用本体模式实现了对数据的管控，便于之后的查询和展示。</p><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/10.png" title="最终得到的关系表"></li><li><p>关联外部数据库：</p><p>Chemical and Drugs：链接到FDA</p><p>Anatomy：链接到uberon</p><p>Disease：链接到Disease Ontology</p><p>Proteins：UMLS自带的MESH条款管控</p><p>biological_process_or_activity/activity_and_behavior：UMLS自带的GO(gene ontology)</p><p>Gene：链接到HGNC（人类基因组数据库） and OMIM（人类遗传学数据库）</p><p>结果展示：</p><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/11.png" title="关联外部数据库的:实体表"></li><li><p>用Neo4j图数据库展示：</p><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/12.png"><img src="/2019/04/20/SemMedDB2Biolink：PubMed语义数据的规范和展示/13.png"></li></ol><p>整个清理流程的结果：</p><p>Start:<br>20,620,113 edges<br>268,918 nodes<br>32 predicates<br>15 node types</p><p>End:<br>14,033,126 edges<br>165,658 nodes<br>18 predicates<br>13 node types</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这个月的工作是对SemMedDB与Biolink Model的初探和尝试。SemMedDB(The Semantic MEDLINE Database)是一个以SPO三元组存储了PubMed中文本语义关系的数据库，大概有9400万条预测关系。而Biolink Model是一个高级别的生物医学实体和关系框架。通过把SemMedDB的关系型数据用Biolink Model规范与展示，可以实现更广泛的生物医学知识推理和运用。转换过程中还用到了一体化医学语言系统UMLS的术语映射。正文如下：&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
</feed>
